>* Working with strings in Rust è¯‘æ–‡
>* åŸæ–‡é“¾æ¥ https://fasterthanli.me/blog/2020/working-with-strings-in-rust/
>* è¯‘æ–‡æ¥è‡ªï¼šhttps://github.com/suhanyujie/article-transfer-rs/
>* è¯‘è€…ï¼š[suhanyujie](https://github.com/suhanyujie)
>* è¯‘è€…åšå®¢ï¼š[suhanyujie](https://ishenghuo.cnblogs.com/)

# ã€è¯‘ã€‘Rust ä¸­ String æ˜¯å¦‚ä½•å·¥ä½œçš„
There's a question that always comes up when people pick up the [Rust](https://www.rust-lang.org/) programming language: why are there two string types? Why is there String, and `&str`?
å½“æˆ‘ä»¬å­¦ä¹  [Rust](https://www.rust-lang.org/) ç¼–ç¨‹è¯­è¨€æ—¶ï¼Œæ€»ä¼šæœ‰è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šä¸ºä»€ä¹ˆä¼šæœ‰ä¸¤ç§å­—ç¬¦ä¸²ç±»å‹ï¼Œä¸ºä»€ä¹ˆä¼šæœ‰ `String` å’Œ `&str`ï¼Ÿ

My [Declarative Memory Management](https://fasterthanli.me/blog/2019/declarative-memory-management) article answers the question partially, but there is a lot more to say about it, so let's run a few experiments and see if we can conjure up a thorough defense of Rust's approach over, say, C's.
æˆ‘çš„[å£°æ˜å¼å†…å­˜ç®¡ç†](https://fasterthanli.me/blog/2019/declarative-memory-management)ç³»åˆ—çš„æ–‡ç« å›ç­”äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†å…³äºè¿™ä¸ªè¯é¢˜è¿˜æœ‰å¾ˆå¤šä¸œè¥¿è¦è§£é‡Šï¼Œæ‰€ä»¥æˆ‘å‡†å¤‡äº†ä¸€äº›ç¤ºä¾‹ï¼Œæ¥çœ‹çœ‹èƒ½å¦å¯¹ Rust çš„è¿™ç§ç°è±¡ï¼ˆæ¯”å¦‚ c è¯­è¨€ï¼‰è¿›è¡Œæ›´æ·±ä¸€æ­¥çš„è¾©è§£å’Œè¯´æ˜ã€‚

## Clear, simple, and wrong
## å¹²å‡€ï¼Œç®€å•ï¼Œå’Œå¼‚å¸¸
Let's start with a simple C program that prints its arguments.
æˆ‘ä»¬å…ˆä»ä¸€ä¸ªç®€å•çš„ C ç¨‹åºå¼€å§‹ï¼Œæ‰“å°å‚æ•°ï¼š

```
// in `print.c`

#include <stdio.h> // for printf

int main(int argc, char **argv) {
    for (int i = 0; i < argc; i++) {
        char *arg = argv[i];
        printf("%s\n", arg);
    }

    return 0;
}
```

```
$ gcc print.c -o print
$ ./print "ready" "set" "go"
./print
ready
set
go
```

Okay! Simple enough.

We're using the standard `C11` main function signature, which takes the number of argument (`argc`, for argument count) as an `int`, and an â€œarrayâ€ of â€œstringsâ€ (`argv`, for argument vector) as a `char**`, or `char *[]`.

Then we use the printf format specifier `%s` to print each argument as a string - followed by `\n`, a newline. And sure enough, it prints each argument on its own line.

Before proceeding, let's make sure we have a proper understanding of what's going on.

```c
// in `print.c`

int main(int argc, char **argv) {
    printf("argv = %p\n", argv); // new!
    for (int i = 0; i < argc; i++) {
        char *arg = argv[i];
        printf("argv[%d] = %p\n", i, argv[i]); // new!
        printf("%s\n", arg);
    }

    return 0;
}
```

Now we're using the `%p` format specifier, which prints.. pointers!

```
$ gcc print.c -o print
$ ./print "ready" "set" "go"
argv = 0x7ffcc35d84a8
argv[0] = 0x7ffcc35d9039
./print
argv[1] = 0x7ffcc35d9041
ready
argv[2] = 0x7ffcc35d9047
set
argv[3] = 0x7ffcc35d904b
go
```

Okay, so, `argv` is an array of addresses, and at those addresses, there is.. string data. Something like that:

![](https://fasterthanli.me/img/working-with-strings-in-rust/argv1.png)

Mhh. How does `printf`'s `%s` specifier know when to stop printing? Since it just gets a single address, not a start and end address, or a start address and a length?

Let's try printing each argument ourselves:

```c
// in `print.c`

#include <stdio.h> // printf

int main(int argc, char **argv) {
    for (int i = 0; i < argc; i++) {
        char *arg = argv[i];
        // we don't know where to stop, so let's just print 15 characters.
        for (int j = 0; j < 15; j++) {
            char character = arg[j];
            // the %c specifier is for characters
            printf("%c", character);
        }
        printf("\n");
    }

    return 0;
}
```

```
$ gcc print.c -o print
$ ./print "ready" "set" "go"
./printreadys
readysetgoCD
setgoCDPATH=.
goCDPATH=.:/ho
```

Uh oh. Our command-line arguments are bleeding into each other. It looks like theyâ€¦ all follow each other?

Let's try piping our program into a hexadecimal dumper like `xxd`, to see exactly what's going on:

```
$ # note: "-g 1" means "show groups of one byte",
$ # xxd defaults to "-g 2".
$ ./print "ready" "set" "go" | xxd -g 1
00000000: 2e 2f 70 72 69 6e 74 00 72 65 61 64 79 00 73 0a  ./print.ready.s.
00000010: 72 65 61 64 79 00 73 65 74 00 67 6f 00 43 44 0a  ready.set.go.CD.
00000020: 73 65 74 00 67 6f 00 43 44 50 41 54 48 3d 2e 0a  set.go.CDPATH=..
00000030: 67 6f 00 43 44 50 41 54 48 3d 2e 3a 2f 68 6f 0a  go.CDPATH=.:/ho.
```

AhAH! They do follow each other, but there's something in between - here's the same output, annotated with `^^` where the separators are:

```
00000000: 2e 2f 70 72 69 6e 74 00 72 65 61 64 79 00 73 0a  ./print.ready.s.
          .  /  p  r  i  n  t  ^^ r  e  a  d  y  ^^ 
```

It looks like every argument is terminated by the value `0`. Indeed, C has [null-terminated strings](https://en.wikipedia.org/wiki/Null-terminated_string).

So we can â€œfixâ€ our printing program:

```c
#include <stdio.h> // printf

int main(int argc, char **argv) {
    for (int i = 0; i < argc; i++) {
        char *arg = argv[i];
        // note: the loop condition is gone, we just loop forever.
        // well, until a 'break' at least.
        for (int j = 0;; j++) {
            char character = arg[j];

            // technically, we ought to use '\0' rather than just 0,
            // but even `gcc -Wall -Wextra -Wpedantic` doesn't chastise
            // us, so let's just go with it.
            if (character == 0) {
                break;
            }
            printf("%c", character);
        }
        printf("\n");
    }

    return 0;
}
```

```
$ gcc print.c -o print
$ ./print "ready" "set" "go"
./print
ready
set
go
```

All better! Although, we need to fix our diagram, too:

![](https://fasterthanli.me/img/working-with-strings-in-rust/argv2.png)

---
**Cool bear's hot tip**
You may have noticed that when our print program went beyond the end of our arguments, it showed `CDPATH=.:/ho` too.

That was (part of) an environment variable! Those are stored right next to the program's arguments in glibc, the GNU C library.

But the specifics are out of scope for this article, you may want to check out the [Making our own executable packer](https://fasterthanli.me/blog/2020/whats-in-a-linux-executable/) series instead.
---

Okay! Now that we fully understand what's going on, let's do something a little more interesting: printing our arguments converted to upper-case.

So if we run `./print hello`, it should print `HELLO`.

We'll also skip the first argument, because it's the name of the program, and that's not really interesting to us right now.

```c
#include <stdio.h> // printf
#include <ctype.h> // toupper

int main(int argc, char **argv) {
    // start from 1, skips program name
    for (int i = 1; i < argc; i++) {
        char *arg = argv[i];
        for (int j = 0;; j++) {
            char character = arg[j];
            if (character == 0) {
                break;
            }
            printf("%c", toupper(character));
        }
        printf("\n");
    }

    return 0;
}
```

```
$ gcc print.c -o print
$ ./print "hello"
HELLO
```

Alright! Nice going! Looks feature-complete to me, ready to be shipped.

Out of an abundance of caution, let's run one last test:

```
$ gcc print.c -o print
$ ./print "Ã©lÃ©ment"
Ã©LÃ©MENT
```

Oh, uh, woops. What we really wanted was â€œÃ‰LÃ‰MENTâ€ but clearly, we haven't yet figured out everything that's going on.

Okay, maybe upper-casing is too complicated for now, let's do something simpler: print each character separated by a space.

```c
// in `print.c`

#include <stdio.h> // printf

int main(int argc, char **argv) {
    for (int i = 1; i < argc; i++) {
        char *arg = argv[i];
        for (int j = 0;; j++) {
            char character = arg[j];
            if (character == 0) {
                break;
            }
            // notice the space following `%c`
            printf("%c ", character);
        }
        printf("\n");
    }

    return 0;
}
```

```
$ gcc print.c -o print
$ ./print "Ã©lÃ©ment"
  l   m e n t 
```

Oh no. This won't do - it won't do at all.

Let's go back to our last well-behaved version, the one that just printed each character, without spaces in between, and see what the output actually was

```c
// in main
// in for
// in second for
            printf("%c", character); // notice the lack of space after `%c`
```

```
$ gcc print.c -o print
$ ./print "Ã©lÃ©ment" | xxd -g 1
00000000: c3 a9 6c c3 a9 6d 65 6e 74 0a                    ..l..ment.
          ^^^^^    ^^^^^
```

If I'm, uh, reading this correctly, â€œÃ©â€ is not a `char`, it's actually two `chars` in a trenchcoat.

That seemsâ€¦ strange.

Let's write a quick JavaScript program and run it with [Node.js](https://nodejs.org/en/):

```c
// in `print.js`

const { argv, stdout } = process;

// we have to skip *two* arguments: the path to node,
// and the path to our script
for (const arg of argv.slice(2)) {
    for (const character of arg) {
        stdout.write(character);
        stdout.write(" ");
    }
    stdout.write("\n");
}
```

```
$ node print.js "Ã©lÃ©ment"
Ã© l Ã© m e n t
```

Ah! Much better! Can Node.js also convert to upper-case properly?

```
// in `print.js`

const { argv, stdout } = process;

for (const arg of argv.slice(2)) {
    stdout.write(arg.toUpperCase());
    stdout.write("\n");
}


```

```
$ node print.js "Ã©lÃ©ment"
Ã‰LÃ‰MENT
```

It can. Let's look at a hexadecimal dump:

```
$ node print.js "Ã©lÃ©ment" | xxd -g 1
00000000: c3 89 4c c3 89 4d 45 4e 54 0a                    ..L..MENT.
          ^^^^^    ^^^^^
```

Although our Node.js program behaves as expected, we can see that `Ã‰` is also different from the other letters, and that the upper-case counterpart *of â€œc3 a9â€ is â€œc3 89â€.

Our C program didn't work - it couldn't work, because it was only seeing â€œc3â€ and â€œa9â€ individually, when it should have considered it as a single, uh, â€œUnicode scalar valueâ€.

Why is â€œÃ©â€ encoded as â€œc3 a9â€? It's time for a _very_ quick UTF-8 encoding course.

## A very quick UTF-8 primer
So, characters like â€œabcdefghijklmnopqrstuvwxyzâ€, â€œABCDEFGHIJKLMNOPQRSTUVWXYZâ€ and â€œ123456789â€, and â€œ!@#$%^&*()", etc., all have numbers.

For example, the number for â€œAâ€ is 65. Why is that so? It's a convention! All a computer knows about is numbers, and we often use bytes as the smallest unit, so, a long time ago, someone just decided that if a byte has the value 65, then it refers to the letter â€œAâ€.

Since ASCII is a 7-bit encoding, it has 128 possible values: from 0 to 127 (inclusive). But, on modern machines at least, a byte is 8 bits, so there's another 128 possible values.

Great! Everyone thought. We can just stuff â€œspecial charactersâ€ in there:

![](https://fasterthanli.me/img/working-with-strings-in-rust/cp437.png)

It's notâ€¦ just ASCII, it's ASCII plus 128 characters of our choice. Of course, there's a lot of languages out there, so not every language's non-ASCII character can fit in those additional 128 values, so there were several alternative interpretations of those any value that was greater than 127.

Those interpretations were named â€œcodepagesâ€. The picture above is [Codepage 437](https://en.wikipedia.org/wiki/Code_page_437), also known as CP437, OEM-US, OEM 437, PC-8, or DOS Latin US.

It's _sorta adequate_ for languages like French, if you don't care about capital letters. It's not adequate at all for Eastern european languages, and doesn't even begin to cover Asian languages.

So, Japan came up with [its own thing](https://en.wikipedia.org/wiki/Shift_JIS), where they replaced ASCII's backslash with a yen sign, the tilde with an overline (sure, why not), and introduced _double-byte_ characters, because 128 extra characters sure wasn't enough for them.

---
**Cool bear's hot tip**
Wait, replacing backslash? Does that meanâ€¦ in file pathsâ€¦ ?

![](https://fasterthanli.me/img/working-with-strings-in-rust/yens.png)

..yep.
---

And for the languages with smaller alphabets, people used other code pages like [Windows-1252](https://en.wikipedia.org/wiki/Windows-1252) for years, and most text in the Western world was still sorta kinda ASCII, also known as â€œextended ASCIIâ€.

But eventually, the world collectively started to put their affairs in order and settled on UTF-8, which:
    - Looks like ASCII (not extended) for ASCII characters, and uses the same space.
    - Allows for a lot more characters - like, billions of them with multi-byte sequences.

Of course, before that happened, people asked, [isn't two bytes enough](https://en.wikipedia.org/wiki/UTF-16)? (Or sequences of two two-byte characters?), and [surely four bytes is okay](https://en.wikipedia.org/wiki/UTF-32), but eventually, for important reasons like compactness, and keeping most C programs half-broken instead of completely broken, everyone adopted UTF-8.

Except [Microsoft](https://docs.microsoft.com/en-us/cpp/text/unicode-and-mbcs?view=vs-2019).

Well, okay, they [kinda did](https://docs.microsoft.com/en-us/windows/uwp/design/globalizing/use-utf8-code-page), although it feels like too little, too late. Everything is still UTF-16 internally. RIP.

---
**Cool bear's hot tip**
Speaking of, the [Bush hid the facts](https://en.wikipedia.org/wiki/Bush_hid_the_facts) saga is hilarious.
---

So, yeah, ASCII _plus_ multi-byte character sequences, how does it even work? Well, it's the same basic principle, each character has a value, so in Unicode, the number for â€œÃ©â€ is â€œe9â€ - we usually write codepoints like so: â€œU+00E9â€.

And `0xE9` is 233 in decimal, which is greater than 127, so, it's not ASCII, and we need to do multi-byte encoding.

How does UTF-8 to multi-byte encoding? With bit sequences!
    - If a byte starts with `110` it means we'll need two bytes
    - If a byte starts with `1110` it means we'll need three bytes
    - If a byte starts with `11110` it means we'll need four bytes
    - If a byte starts with `10`, it means it's a continuation of a multi-byte character sequence.

So, for â€œÃ©â€, which has codepoint U+00E9, its binary representation is â€œ11101001â€, and we know we're going to need two bytes, so we should have something like this:

![](https://fasterthanli.me/img/working-with-strings-in-rust/encoding1.png)

We can see in the lower part that two-byte UTF-8 sequences give us 11 bits of storage: 5 bits in the first byte, and 6 bits in the second byte. We only need to fit 8 bits, so we fill them from right to left, first the last 6 bits:

![](https://fasterthanli.me/img/working-with-strings-in-rust/encoding2.png)

Then the remaining 2 bits:

![](https://fasterthanli.me/img/working-with-strings-in-rust/encoding3.png)

The rest is padding, filled with zeroes:

![](https://fasterthanli.me/img/working-with-strings-in-rust/encoding4.png)

We're done! `0b11000011` is `0xC3`, and `0b10101001` is `0xA9`.

Which corresponds to what we've seen earlier - â€œÃ©â€ is â€œc3 a9â€.

## Back to C
So, uh, our C program. If we want to really separate characters, we have to do some UTF-8 decoding.

We can do that ourselves - no, really! Well, we can try anyway.

```c
// in `print.c`

#include <stdio.h> // printf
#include <stdint.h> // uint8_t

void print_spaced(char *s) {
    // start at the beginning
    int i = 0;

    while (1) {
        // we're going to be shifting bytes around,
        // so treat them like unsigned 8-bit values
        uint8_t c = s[i];
        if (c == 0) {
            // reached null terminator, stop printing
            break;
        }

        // length of the sequence, ie., number of bytes
        // that encode a single Unicode scalar value
        int len = 1;
        if (c >> 5 == 0b110) {
            len = 2;
        } else if (c >> 4 == 0b1110) {
            len = 3;
        } else if (c >> 3 == 0b11110) {
            len = 4;
        }

        // print the entire UTF-8-encoded Unicode scalar value
        for (; len > 0; len--) {
            printf("%c", s[i]);
            i++;
        }
        // print space separator
        printf(" ");
    }
}

int main(int argc, char **argv) {
    for (int i = 1; i < argc; i++) {
        print_spaced(argv[i]);
        printf("\n");
    }

    return 0;
}
```

There! Simple! None of that `String` and `&str` business. In fact, there's a remarkable lack of Rust code for an article about Rust string handling, and we're about ten minutes in already!

---
**Cool bear's hot tip**
Binary literals, e.g. `0b100101010` are not standard C, they're a GNU extension. Normally you'd see hexadecimal literals, e.g. `0xDEADBEEF`, but it's much harder to see what's going on since UTF-8 deals with individual bits.
---

Does our program work?

```
$ gcc print.c -o print
$ ./print "eat the rich"
e a t   t h e   r i c h 
```

So far so good!

```
$ ./print "platÃ©e de rÃ¶sti"
p l a t Ã© e   d e   r Ã¶ s t i 
```

Nice!

```
$ ./print "23â‚¬ â‰ˆ Â¥2731"
2 3 â‚¬   â‰ˆ   Â¥ 2 7 3 1 
```

Cool!

```
$ ./print "text ğŸ¤· encoding"
t e x t   ğŸ¤·   e n c o d i n g 
```

Alright!

Well I don't know what everyone is complaining about, UTF-8 is super easy to implement, it only took us a few minutes and it is 100% correct and accurate and standards-compliant and it will work forever on all inputs and always do the right thing

â€¦or will it?

Here comes the counter-exampleâ€¦ I can feel it in my bones.

Consider the following string:

```
$ echo "noe\\u0308l"
noeÌˆl
```

It's just Christmas in French! Surely our program can handle that, no sweat:

```
$ ./print $(echo "noe\\u0308l")
n o e Ìˆ l 
```

Uh oh.

Turns out U+0308 is a â€œcombining diaeresisâ€, which is fancy talk for â€œjust slap two dots on the previous characterâ€.

In fact, we can slap more of them if we want (for extra Christmas cheer):

![](https://fasterthanli.me/img/working-with-strings-in-rust/two-diaereses.png)

---
**Cool bear's hot tip**
The combination of multiple scalar values that end up showing a single â€œshapeâ€ are called â€œgrapheme clustersâ€, and you should read Henri Sivonen's [Itâ€™s Not Wrong that â€œğŸ¤¦ğŸ¼â€â™‚ï¸â€.length == 7](https://hsivonen.fi/string-length/) if you want to learn more about them.

Also, since I'm French, I'm writing this whole article with a Latin-1 bias, I haven't even talked about right-to-left scripts, vowel modifiers, syllable blocks, etc. - luckily, Manish Goregaokar has a great piece on that, [Breaking Our Latin-1 Assumptions](https://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/).
---

Okay. OKAY. So maybe our program doesn't implement _all_ the subtleties of UTF-8 encoding, but, you know, we came pretty close.

We haven't tried converting things to upper-case in a while though.

Can we do that? Is that legal?

Let's find out.

So we'll disregard combining characters for now, and focus on Unicode scalar values. What we want is to:

    - Decode our input, ie. transform it from UTF-8 to a series of Unicode scalar values (we'll pick `uint32_t`)
    - Transform said scalar values to their upper-case counterparts
    - Re-encode as UTF-8
    - Print to the console

So let's start with a `decode_utf8` function. We'll only handle 2-byte sequences:

```c
// in `upper.c`

#include <stdio.h> // printf
#include <stdint.h> // uint8_t, uint32_t
#include <stdlib.h> // exit

void decode_utf8(char *src, uint32_t *dst) {
    int i = 0;
    int j = 0;

    while (1) {
        uint8_t c = src[i];
        if (c == 0) {
            dst[j] = 0;
            break; // null terminator
        }

        uint32_t scalar;
        int len;

        if (c >> 3 == 0b11110) {
            fprintf(stderr, "decode_utf8: 4-byte sequences are not supported!\n");
            exit(1);
        } if (c >> 4 == 0b1110) {
            fprintf(stderr, "decode_utf8: 3-byte sequences are not supported!\n");
            exit(1);
        } else if (c >> 5 == 0b110) {
            // 2-byte sequence
            uint32_t b1 = (uint32_t) src[i];
            uint32_t b2 = (uint32_t) src[i + 1];
            uint32_t mask1 = 0b0000011111000000;
            uint32_t mask2 = 0b0000000000111111;

            scalar = ((b1 << 6) & mask1) | ((b2 << 0) & mask2);
            len = 2;
        } else {
            // 1-byte sequence
            scalar = (uint32_t) c;
            len = 1;
        }
        dst[j++] = scalar;
        i += len;
    }
}

int main(int argc, char **argv) {
    uint32_t scalars[1024]; // hopefully that's enough
    decode_utf8(argv[1], scalars);

    for (int i = 0;; i++) {
        if (scalars[i] == 0) {
            break;
        }
        printf("U+%04X ", scalars[i]);
    }
    printf("\n");

    return 0;
}
```

```
$ gcc upper.c -o upper
$ ./upper "noÃ«l"
U+006E U+006F U+00EB U+006C 
```

Logically, `U+00EB` should be the codepoint for â€œÃ«â€â€¦ and [it is!](https://unicode-table.com/en/00EB/)

![](https://fasterthanli.me/img/working-with-strings-in-rust/e-trema.png)

Its full name is â€œLatin Small Letter E with Diaeresisâ€. Okay.

So now we just have to do the reverse conversion - easy!

```c
// in `upper.c`

void encode_utf8(uint32_t *src, char *dst) {
    int i = 0;
    int j = 0;

    while (1) {
        uint32_t scalar = src[i];

        if (scalar == 0) {
            dst[j] = 0; // null terminator
            break;
        }

        if (scalar > 0b11111111111) {
            fprintf(stderr, "Can only encode codepoints <= 0x%x", 0b11111111111);
            exit(1);
        }

        if (scalar > 0b1111111) { // 7 bits
            // 2-byte sequence

            uint8_t b1 = 0b11000000 | ((uint8_t) ((scalar & 0b11111000000) >> 6));
            //           2-byte marker              first 5 of 11 bits

            uint8_t b2 = 0b10000000 | ((uint8_t) (scalar & 0b111111));
            //           continuation               last 6 of 11 bits  

            dst[j + 0] = b1;
            dst[j + 1] = b2;
            j += 2;
        } else {
            // 1-byte sequence
            dst[j] = (char) scalar;
            j++;
        }

        i++;
    }
}

// omitted: decode_utf8

int main(int argc, char **argv) {
    uint32_t scalars[1024]; // hopefully that's enough
    decode_utf8(argv[1], scalars);

    for (int i = 0;; i++) {
        if (scalars[i] == 0) {
            break;
        }
        printf("U+%04X ", scalars[i]);
    }
    printf("\n");

    uint8_t result[1024]; // yolo
    encode_utf8(scalars, result);

    printf("%s\n", result);

    return 0;
}
```

```
$ gcc upper.c -o upper
$ ./upper "noÃ«l"
U+006E U+006F U+00EB U+006C 
noÃ«l
```

Fantastic!

Now all we need is some sort of conversion table! From lower-case codepoints to their upper-case equivalents.

We'll fill in just enough to support French:

```c
#include <ctype.h> // toupper

int main(int argc, char **argv) {
    uint32_t scalars[1024]; // hopefully that's enough
    decode_utf8(argv[1], scalars);

    for (int i = 0;; i++) {
        if (scalars[i] == 0) {
            break;
        }
        printf("U+%04X ", scalars[i]);
    }
    printf("\n");

    // this is the highest codepoint we can decode/encode successfully
    const size_t table_size = 0b11111111111;
    uint32_t lower_to_upper[table_size];
    // initialize the table to just return the codepoint unchanged
    for (uint32_t cp = 0; cp < table_size; cp++) {
        lower_to_upper[cp] = cp;
    }
    // set a-z => A-Z
    for (int c = 97; c <= 122; c++) { // ha.
        lower_to_upper[(uint32_t) c] = (uint32_t) toupper(c);
    }

    // note: nested functions is a GNU extension!
    void set(char *lower, char *upper) {
        uint32_t lower_s[1024];
        uint32_t upper_s[1024];
        decode_utf8(lower, lower_s);
        decode_utf8(upper, upper_s);
        for (int i = 0;; i++) {
            if (lower_s[i] == 0) {
                break;
            }
            lower_to_upper[lower_s[i]] = upper_s[i];
        }
    }
    // set a few more
    set(
        "Ã©ÃªÃ¨Ã Ã¢Ã«Ã¼Ã¶Ã¯Ã¿Ã´Ã®Ã§Ã¦Å“",
        "Ã‰ÃŠÃˆÃ€Ã‚Ã‹ÃœÃ–ÃÅ¸Ã”ÃÃ‡Ã†Å’"
    );

    // now convert our scalars to upper-case
    for (int i = 0;; i++) {
        if (scalars[i] == 0) {
            break;
        }
        scalars[i] = lower_to_upper[scalars[i]];
    }

    uint8_t result[1024]; // yolo
    encode_utf8(scalars, result);

    printf("%s\n", result);

    return 0;
}
```

Let's take it for a spin:

```
$ gcc upper.c -o upper
$ ./upper "Voix ambiguÃ« d'un cÅ“ur qui, au zÃ©phyr, prÃ©fÃ¨re les jattes de kiwis"
U+0056 U+006F U+0069 U+0078 U+0020 U+0061 U+006D U+0062 U+0069 U+0067 U+0075 U+00EB U+0020 U+0064 U+0027 U+0075 U+006E U+0020 U+0063 U+0153 U+0075 U+0072 U+0020 U+0071 U+0075 U+0069 U+002C U+0020 U+0061 U+0075 U+0020 U+007A U+00E9 U+0070 U+0068 U+0079 U+0072 U+002C U+0020 U+0070 U+0072 U+00E9 U+0066 U+00E8 U+0072 U+0065 U+0020 U+006C U+0065 U+0073 U+0020 U+006A U+0061 U+0074 U+0074 U+0065 U+0073 U+0020 U+0064 U+0065 U+0020 U+006B U+0069 U+0077 U+0069 U+0073 
VOIX AMBIGUÃ‹ D'UN CÅ’UR QUI, AU ZÃ‰PHYR, PRÃ‰FÃˆRE LES JATTES DE KIWIS
```

Wonderful!

## Now for some Rust
Okay, so that was about 140 lines of C (with GNU extensions) - [here's the gist](https://gist.github.com/fasterthanlime/6a20aeaeb0ce34abbcda42dc9fded955) if you want to mess with it.

Obviously, there's libraries to do all that for you, _correctly_. [ICU](http://site.icu-project.org/) is a popular choice, for its irritating completeness, but there's lighter alternatives that may suit your needs.

---
**Cool bear's hot tip**
Proper UTF-8 handling is not just about computer security - software impacts [actual human safety (CW: death)](https://gizmodo.com/a-cellphones-missing-dot-kills-two-people-puts-three-m-382026) all the time.
---

Let's see what a Rust program that does the _same thing_ would look like, though:

```
$ cargo new rustre
     Created binary (application) `rustre` package
$ cd rustre
```

```rust
fn main() {
    let arg = std::env::args()
        .skip(1)
        .next()
        .expect("should have one argument");
    println!("{}", arg.to_uppercase());
}
```

---
***Cool bear's hot tip**
Turbo explanation of the above: `std::env::args()` returns an `Iterator` of strings. `skip(1)` ignores the program name (which is usually the first argument), `next()` gets the next element in the iterator (the first â€œrealâ€) argument.

By that point we have an `Option<String>` - there might be a next argument, or there might not be. If there isn't, `.expect(msg)` stops the program by printing `msg`. If there is, we now have a `String`!
---

```
$ cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.01s
     Running `target/debug/rustre`
thread 'main' panicked at 'should have one argument', src/libcore/option.rs:1188:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
```

Okay! So when we don't pass an argument, it says so. Wonderful.

Let's pass a few test strings:

```
$ cargo run --quiet -- "noÃ«l"
NOÃ‹L
$ cargo run --quiet -- "trans rights"
TRANS RIGHTS
$ cargo run --quiet -- "voix ambiguÃ« d'un cÅ“ur qui, au zÃ©phyr, prÃ©fÃ¨re les jattes de kiwis"
VOIX AMBIGUÃ‹ D'UN CÅ’UR QUI, AU ZÃ‰PHYR, PRÃ‰FÃˆRE LES JATTES DE KIWIS
$ cargo run --quiet -- "heinz groÃŸe"
HEINZ GROSSE
```

Everything checks out!

That last one is particularly cool - in German, â€œÃŸâ€ (eszett) is indeed a ligature for â€œssâ€. Well, [it's complicated](https://en.wikipedia.org/wiki/%C3%9F), but that's the gist.

## Error handling
So, Rust definitely behaves as if strings were UTF-8, that means it must decode our command-line arguments at some point. And that meansâ€¦ this can fail.

But I only see error handling for when we have no arguments at all, not for when the arguments are invalid utf-8.

Speaking ofâ€¦ what is invalid utf-8? Well, we've seen that â€œÃ©â€ is encoded as â€œc3 e9â€, so this works:

```
$ cargo run --quiet -- $(printf "\\xC3\\xA9")
Ã‰
```

And we've seen that a two-byte UTF-8 sequence has:

    - An indication in the first byte that it was a two-byte sequence (the first three bits, `110`)
    - An indication in the second byte that it was a continuation of a multi-byte sequence (the first two bits, `10`)

So.. what if we start a two-byte sequence and then abruptly stop? What if we pass `C3`, but not `A9`?

```
$ cargo run --quiet -- $(printf "\\xC3")
thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: "\xC3"', src/libcore/result.rs:1188:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
```

AhAH! A panic. Let's look at the backtrace:

```
thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: "\xC3"', src/libcore/result.rs:1188:5                                                
stack backtrace:
(cut)
  13: core::result::unwrap_failed
             at src/libcore/result.rs:1188
  14: core::result::Result<T,E>::unwrap
             at /rustc/5e1a799842ba6ed4a57e91f7ab9435947482f7d8/src/libcore/result.rs:956
  15: <std::env::Args as core::iter::traits::iterator::Iterator>::next::{{closure}}
             at src/libstd/env.rs:789
  16: core::option::Option<T>::map
             at /rustc/5e1a799842ba6ed4a57e91f7ab9435947482f7d8/src/libcore/option.rs:450
  17: <std::env::Args as core::iter::traits::iterator::Iterator>::next
             at src/libstd/env.rs:789
  18: <&mut I as core::iter::traits::iterator::Iterator>::next
             at /rustc/5e1a799842ba6ed4a57e91f7ab9435947482f7d8/src/libcore/iter/traits/iterator.rs:2991
  19: core::iter::traits::iterator::Iterator::nth
             at /rustc/5e1a799842ba6ed4a57e91f7ab9435947482f7d8/src/libcore/iter/traits/iterator.rs:323
  20: <core::iter::adapters::Skip<I> as core::iter::traits::iterator::Iterator>::next
             at /rustc/5e1a799842ba6ed4a57e91f7ab9435947482f7d8/src/libcore/iter/adapters/mod.rs:1657
  21: rustre::main
             at src/main.rs:2
(cut)
```

Okay, so, even with most of the frames cut, it's still a mouthful but basically:

    - in `main()`
    - we called `.next()` on an `Iterator`
    - which eventually called `.unwrap()` on a `Result`
    - which panicked

This means it only panics _if we try to get the arguments as a String_.

If we get it as an `OsString`, for example, it doesn't panic:

```rust
fn main() {
    let arg = std::env::args_os()
        .skip(1)
        .next()
        .expect("should have one argument");
    println!("{:?}", arg)
}
```

```
$ cargo run --quiet -- hello
"hello"
$ cargo run --quiet $(printf "\\xC3")
"\xC3"
```

â€¦but then we don't have a `.to_uppercase()` method. Because it's not text. It's an `OsString`, ie. it's a a series of bytes which we might be able to interpret as text (given the encoding) â€” or not.

Speaking of, how does our C program handle our invalid utf-8 input?

```
$ ../upper $(printf "\\xC3")
U+00C0 U+0043 U+0044 U+0050 U+0041 U+0054 U+0048 U+003D U+002E U+003A U+002F U+0068 U+006F U+006D U+0065 U+002F U+0061 U+006D U+006F U+0073 U+002F U+0072 U+0075 U+0073 U+0074 U+003A U+002F U+0068 U+006F U+006D U+0065 U+002F U+0061 U+006D U+006F U+0073 U+002F U+0067 U+006F U+003A U+002F U+0068 U+006F U+006D U+0065 U+002F U+0061 U+006D U+006F U+0073 U+002F U+0066 U+0074 U+006C U+003A U+002F U+0068 U+006F U+006D U+0065 U+002F U+0061 U+006D U+006F U+0073 U+002F U+0070 U+0065 U+0072 U+0073 U+006F U+003A U+002F U+0068 U+006F U+006D U+0065 U+002F U+0061 U+006D U+006F U+0073 U+002F U+0077 U+006F U+0072 U+006B 
Ã€CDPATH=.:/HOME/AMOS/RUST:/HOME/AMOS/GO:/HOME/AMOS/FTL:/HOME/AMOS/PERSO:/HOME/AMOS/WORK
```

The answer is: not well. Not well at all, in fact.

Our naive UTF-8 decoder first read `C3` and was all like â€œneat, a 2-byte sequence!", and then it read the next byte (which happened to be the null terminator), and decided the result should be â€œÃ â€.

So, instead of stopping, it read past the end of the argument, right into the environment block, finding the first environment variable, and now you can see the places I `cd` to frequently (in upper-case).

Now, this seems pretty tame in this contextâ€¦ but what if it wasn't?

What if our C program was used as part of a web server, and its output was shown directly to the user? And what if the first environment variable wasn't `CDPATH`, but `SECRET_API_TOKEN`?

Then it would be a disaster. And it's not a hypothetical, it happens [all the time](https://cwe.mitre.org/data/definitions/125.html).

---
**Cool bear's hot tip**
By the way, our program is also vulnerable to buffer overflow attacks: if the input decodes to more than 1024 scalar values, it could overwrite other variables, potentially variables that are involved in verifying someone's credentialsâ€¦
---

So, our C program will happily do dangerous things (which is very on-brand), but our Rust program panics early if the command-line arguments are not valid utf-8.

What if we want to handle that case gracefully?

Then we can use `OsStr::to_str`, which returns an `Option` - a value that is either _something or nothing_.

```rust
fn main() {
    let arg = std::env::args_os()
        .skip(1)
        .next()
        .expect("should have one argument");

    match arg.to_str() {
        Some(arg) => println!("valid UTF-8: {}", arg),
        None => println!("not valid UTF-8: {:?}", arg),
    }
}
```

```
$ cargo run --quiet -- "Ã©"
valid UTF-8: Ã©
$ cargo run --quiet -- $(printf "\\xC3")
not valid UTF-8: "\xC3"
```

Wonderful.

---
**What did we learn?**
In Rust, provided you don't explicitly work around it with `unsafe`, values of type `String` are _always_ valid UTF-8.

If you try to build a String with invalid UTF-8, you won't get a String, you'll get an error instead. Some helpers, like std::env::args(), hide the error handling because the error case is very rare - but it still checks for it, and panics if it happens, because that's the safe thing to do.

By comparison, C has no string type. It doesn't even have a real character type. char is.. an ASCII character plus an additional bit - effectively, it's just a signed 8-bit integer: int8_t.

There is absolutely no guarantee that anything in a char* is valid UTF-8, or valid anything for that matter. There is no encoding associated to a char*, which is just an address in memory. There is no length associated to it either, so computing its length involves finding the null terminator.

Null-terminated strings are also a serious security concern. Not to mention that NUL is a valid Unicode character, so null-terminated strings cannot represent all valid UTF-8 strings.
---

## Iteration
How would we go about separating characters by spaces?

```rust
fn main() {
    let arg = std::env::args()
        .skip(1)
        .next()
        .expect("should have one argument");

    for c in arg.chars() {
        print!("{} ", c);
    }
    println!()
}
```

```
$ cargo run --quiet -- "cup of tea"
c u p   o f   t e a 
```

That was easy! Let's try it with non-ASCII characters:

```
$ cargo run --quiet -- "23â‚¬ â‰ˆ Â¥2731"
2 3 â‚¬   â‰ˆ   Â¥ 2 7 3 1 
```

```
$ cargo run --quiet -- "memory safety ğŸ¥º please ğŸ™"
m e m o r y   s a f e t y   ğŸ¥º   p l e a s e   ğŸ™ 
```

Everything seems fine.

What if we want to print the Unicode scalar values's numbers instead of their, uh, graphemes?

```rust
fn main() {
    let arg = std::env::args()
        .skip(1)
        .next()
        .expect("should have one argument");

    for c in arg.chars() {
        print!("{} (U+{:04X}) ", c, c as u32);
    }
    println!()
}
```

$ cargo run --quiet -- "aimÃ©e"
a (U+0061) i (U+0069) m (U+006D) Ã© (U+00E9) e (U+0065)

Cool!

What if we want to show how it's encoded as UTF-8? By which I mean, print the individual bytes?

```rust
fn main() {
    let arg = std::env::args()
        .skip(1)
        .next()
        .expect("should have one argument");

    for b in arg.bytes() {
        print!("{:02X} ", b);
    }
    println!()
}
```

```
$ cargo run --quiet -- "aimÃ©e"
61 69 6D C3 A9 65 
```

There's our c3 a9!

Easy enough. We didn't even have to worry about types - there hasn't been a single String or &str in any of our Rust programs so far.

So, let's go looking for trouble.

## Passing strings around
First, C.

C is easy! Just use char*! Don't worry about anything else.

```c
// in `woops.c`

#include <stdio.h>

int len(char *s) {
    int l = 0;
    while (s[l]) {
        l++;
    }
    return l;
}

int main(int argc, char **argv) {
    char *arg = argv[1];
    int l = len(arg);
    printf("length of \"%s\" = %d\n", arg, l);
}
```

```
$ # we're back into the parent of the "rustre" directory
$ # (in case you're following along)
$ gcc woops.c -o woops
$ ./woops "dog"
length of "dog" = 3
```

See? Easy! None of that String / &str nonsense. No lifetimes, no nothing.

Ah. deep breath. Simpler times.

Okay, back to reality. First of all, that's not really the length of a string. It's.. the number of bytes it takes to encode it using UTF-8.

So, for example:

```
$ ./woops "nÃ©e"
length of "nÃ©e" = 4
```

And also:

```
$ ./woops "ğŸˆ"
length of "ğŸˆ" = 4
```

But in all fairness, that was to be expected. We didn't spend half the article implementing a half-baked UTF-8 decoder and encoder just to be surprised that, without one, we can't count characters properly.

Also, that's not what's bothering me right now.

What's bothering me right now is that the compiler does nothing to prevent us from doing this:

```c
#include <stdio.h>

int len(char *s) {
    s[0] = '\0';
    return 0;
}

int main(int argc, char **argv) {
    char *arg = argv[1];
    int l = len(arg);
    printf("length of \"%s\" = %d\n", arg, l);
}
```

```
$ gcc woops.c -o woops
$ ./woops "some user input"
length of "" = 0
```

And, you know, len() is right. By the time it's doneâ€¦ the length of the string is zero. (It even â€œworksâ€ on non-ASCII inputs!).

This would pass unit tests. And if no one bothered to look at the len function itself - say, if it was in a third-party library, or worse, a proprietary third-party library, then it would beâ€¦ interestingâ€¦ to debug.

â€œBut Amos!â€ - you interject - â€œC has constâ€!

Okay, sure, C has const:

```c
int len(const char *s) {
    s[0] = '\0';
    return 0;
}
```

Now it doesn't compile:

```
woops.c: In function â€˜lenâ€™:
woops.c:4:10: error: assignment of read-only location â€˜*sâ€™
    4 |     s[0] = '\0';
      |  
```

But C also has unbounded leniency, and so:

```c
int len(const char *s) {
    char *S = (void *) s;
    S[0] = '\0';
    return 0;
}
```

Now it compiles again. And it runs. And it doesn't fail at runtime - it silently overwrites our input string, just the same.

Even -Wall, -Wextra and -Wpedantic don't warn us about this. They warn us about argc being unused. Which, fair enough, not passing an argument to ./woops definitely ends up reading from unmapped memory addresses and crashes right now.

And if this is in a proprietary library, you're lulled into a false sense of security, because you look at the header file and you see this:

```c
int len(const char *s);
```

But, granted - that's a contrived example. You'd have to be a pretty evil vendor to ship a len function that mutates its input. Unless you do it accidentally. Which you'd never do, right? Unless you do. In which case, well, you shouldn't have. Obviously.

Right?

Okay so let's go with a more realistic example: a function that turns a string uppercase:

```c
// in `woops.c`

#include <stdio.h>
#include <ctype.h>

void uppercase(char *s) {
    // this is peak C right there
    do {
        *s = toupper(*s);
    } while (*s++);
}

int main(int argc, char **argv) {
    char *arg = argv[1];

    char *upp = arg;
    uppercase(upp);

    printf("upp = %s\n", upp);
}
```

Sounds familiar right? But we're focused on a different aspect.

Anyway, it works:
        -- to be continued