>* Rust and CSV parsing 译文（用 Rust 实现 csv 解析-part4）
>* 原文链接：https://blog.burntsushi.net/csv/
>* 原文作者：[BurntSushi](https://github.com/BurntSushi)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust，csv

## Delimiters, quotes and variable length records
>分隔符，引号和可变长度的记录

In this section we’ll temporarily depart from our uspop.csv data set and show how to read some CSV data that is a little less clean. This CSV data uses ; as a delimiter, escapes quotes with \" (instead of "") and has records of varying length. Here’s the data, which contains a list of WWE wrestlers and the year they started, if it’s known:
>在这一节中，我们将暂时抛开 uspop.csv 数据，并展示如何读取一些不太正常的 CSV 数据。这个 CSV 数据使用 `;` 作为分隔符，带有转义的引号 `\"`（不是`""`）并且拥有可变长度的记录。下面是一些示例数据，如果你知道 WWE 的话，可以看出其中是一些 WWE 摔跤手及其出生年份的名单：

```
$ cat strange.csv
"\"Hacksaw\" Jim Duggan";1987
"Bret \"Hit Man\" Hart";1984
# We're not sure when Rafael started, so omit the year.
Rafael Halperin
"\"Big Cat\" Ernie Ladd";1964
"\"Macho Man\" Randy Savage";1985
"Jake \"The Snake\" Roberts";1986
```

To read this CSV data, we’ll want to do the following:
>要读取这些 CSV 数据，我们按照下面的思路来：

* 1.不读取 header，因为没有 header 部分
* 2.将分隔符由 `,` 改为 `;`。
* 3.将双引号（如 `""`）的后半部分转义（如`\"`）
* 4.支持灵活的可变长度记录，因为其中可能会有年份缺省。
* 5.忽略行首是 `#` 的行

All of this (and more!) can be configured with a [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html), as seen in the following example:
>所有这些（或者其他）都可以用 [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html) 来实现，如下方示例：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::ReaderBuilder::new()
        .has_headers(false)
        .delimiter(b';')
        .double_quote(false)
        .escape(Some(b'\\'))
        .flexible(true)
        .comment(Some(b'#'))
        .from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

Now re-compile your project and try running the program on `strange.csv`:
>现在重新编译项目并以 `strange.csv` 作为输入来运行它：

```
$ cargo build
$ ./target/debug/csvtutor < strange.csv
StringRecord(["\"Hacksaw\" Jim Duggan", "1987"])
StringRecord(["Bret \"Hit Man\" Hart", "1984"])
StringRecord(["Rafael Halperin"])
StringRecord(["\"Big Cat\" Ernie Ladd", "1964"])
StringRecord(["\"Macho Man\" Randy Savage", "1985"])
StringRecord(["Jake \"The Snake\" Roberts", "1986"])
```

You should feel encouraged to play around with the settings. Some interesting things you might try:
>你应该多多设置。可能会发生一些有趣的事：

* 1.If you remove the `escape` setting, notice that no CSV errors are reported. Instead, records are still parsed. This is a feature of the CSV parser. Even though it gets the data slightly wrong, it still provides a parse that you might be able to work with. This is a useful property given the messiness of real world CSV data.
* 2.If you remove the `delimiter` setting, parsing still succeeds, although every record has exactly one field.
* 3.If you remove the `flexible` setting, the reader will print the first two records (since they both have the same number of fields), but will return a parse error on the third record, since it has only one field.

This covers most of the things you might want to configure on your CSV reader, although there are a few other knobs. For example, you can change the record terminator from a new line to any other character. (By default, the terminator is `CRLF`, which treats each of `\r\n`, `\r` and `\n` as single record terminators.) For more details, see the documentation and examples for each of the methods on [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html).

## Reading with Serde

One of the most convenient features of this crate is its support for [Serde](https://serde.rs/). Serde is a framework for automatically serializing and deserializing data into Rust types. In simpler terms, that means instead of iterating over records as an array of string fields, we can iterate over records of a specific type of our choosing.

For example, let’s take a look at some data from our `uspop.csv` file:

```
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
```

While some of these fields make sense as strings (`City`, `State`), other fields look more like numbers. For example, Population looks like it contains integers while `Latitude` and `Longitude` appear to contain decimals. If we wanted to convert these fields to their “proper” types, then we need to do a lot of manual work. This next example shows how.

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;

        let city = &record[0];
        let state = &record[1];
        // Some records are missing population counts, so if we can't
        // parse a number, treat the population count as missing instead
        // of returning an error.
        let pop: Option<u64> = record[2].parse().ok();
        // Lucky us! Latitudes and longitudes are available for every record.
        // Therefore, if one couldn't be parsed, return an error.
        let latitude: f64 = record[3].parse()?;
        let longitude: f64 = record[4].parse()?;

        println!(
            "city: {:?}, state: {:?}, \
             pop: {:?}, latitude: {:?}, longitude: {:?}",
            city, state, pop, latitude, longitude);
    }
    Ok(())
}
```

The problem here is that we need to parse each individual field manually, which can be labor intensive and repetitive. Serde, however, makes this process automatic. For example, we can ask to deserialize every record into a tuple type: `(String, String, Option<u64>, f64, f64)`.

```rust
// This introduces a type alias so that we can conveniently reference our
// record type.
type Record = (String, String, Option<u64>, f64, f64);

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    // Instead of creating an iterator with the `records` method, we create
    // an iterator with the `deserialize` method.
    for result in rdr.deserialize() {
        // We must tell Serde what type we want to deserialize into.
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

Running this code should show similar output as previous examples:

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
("Davidsons Landing", "AK", None, 65.2419444, -165.2716667)
("Kenai", "AK", Some(7610), 60.5544444, -151.2583333)
("Oakman", "AL", None, 33.7133333, -87.3886111)
# ... and much more
```

One of the downsides of using Serde this way is that the type you use must match the order of fields as they appear in each record. This can be a pain if your CSV data has a header record, since you might tend to think about each field as a value of a particular named field rather than as a numbered field. One way we might achieve this is to deserialize our record into a map type like [HashMap](https://doc.rust-lang.org/std/collections/struct.HashMap.html) or [BTreeMap](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html). The next example shows how, and in particular, notice that the only thing that changed from the last example is the definition of the Record type alias and a new use statement that imports HashMap from the standard library:

```rust
use std::collections::HashMap;

// This introduces a type alias so that we can conveniently reference our
// record type.
type Record = HashMap<String, String>;

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

Running this program shows similar results as before, but each record is printed as a map:

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
{"City": "Davidsons Landing", "Latitude": "65.2419444", "State": "AK", "Population": "", "Longitude": "-165.2716667"}
{"City": "Kenai", "Population": "7610", "State": "AK", "Longitude": "-151.2583333", "Latitude": "60.5544444"}
{"State": "AL", "City": "Oakman", "Longitude": "-87.3886111", "Population": "", "Latitude": "33.7133333"}
```

This method works especially well if you need to read CSV data with header records, but whose exact structure isn’t known until your program runs. However, in our case, we know the structure of the data in `uspop.csv`. In particular, with the `HashMap` approach, we’ve lost the specific types we had for each field in the previous example when we deserialized each record into a `(String, String, Option<u64>, f64, f64)`. Is there a way to identify fields by their corresponding header name and assign each field its own unique type? The answer is yes, but we’ll need to bring in a new crate called serde_derive first. You can do that by adding this to the `[dependencies]` section of your `Cargo.toml` file:

```
serde = "1"
serde_derive = "1"
```

With these crates added to our project, we can now define our own custom struct that represents our record. We then ask Serde to automatically write the glue code required to populate our struct from a CSV record. The next example shows how. Don’t miss the new `extern crate` lines!

```rust
extern crate csv;
extern crate serde;
// This lets us write `#[derive(Deserialize)]`.
 #[macro_use]
extern crate serde_derive;

use std::error::Error;
use std::io;
use std::process;

// We don't need to derive `Debug` (which doesn't require Serde), but it's a
// good habit to do it for all your types.
//
// Notice that the field names in this struct are NOT in the same order as
// the fields in the CSV data!
 #[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    latitude: f64,
    longitude: f64,
    population: Option<u64>,
    city: String,
    state: String,
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
        // Try this if you don't like each record smushed on one line:
        // println!("{:#?}", record);
    }
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

Compile and run this program to see similar output as before:

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
Record { latitude: 65.2419444, longitude: -165.2716667, population: None, city: "Davidsons Landing", state: "AK" }
Record { latitude: 60.5544444, longitude: -151.2583333, population: Some(7610), city: "Kenai", state: "AK" }
Record { latitude: 33.7133333, longitude: -87.3886111, population: None, city: "Oakman", state: "AL" }
```

Once again, we didn’t need to change our `run` function at all: we’re still iterating over records using the `deserialize` iterator that we started with in the beginning of this section. The only thing that changed in this example was the definition of the `Record` type and a couple new `extern crate` statements. Our Record type is now a custom struct that we defined instead of a type alias, and as a result, Serde doesn’t know how to deserialize it by default. However, a special compiler plugin called `serde_derive` is available, which will read your struct definition at compile time and generate code that will deserialize a CSV record into a `Record` value. To see what happens if you leave out the automatic derive, change `#[derive(Debug, Deserialize)]` to `#[derive(Debug)]`.

One other thing worth mentioning in this example is the use of `#[serde(rename_all = "PascalCase")]`. This directive helps Serde map your struct’s field names to the header names in the CSV data. If you recall, our header record is:

```
City,State,Population,Latitude,Longitude
```

Notice that each name is capitalized, but the fields in our struct are not. The `#[serde(rename_all = "PascalCase")]` directive fixes that by interpreting each field in `PascalCase`, where the first letter of the field is capitalized. If we didn’t tell Serde about the name remapping, then the program will quit with an error:

```
$ ./target/debug/csvtutor < uspop.csv
CSV deserialize error: record 1 (line: 2, byte: 41): missing field `latitude`
```

We could have fixed this through other means. For example, we could have used capital letters in our field names:

```rust
#[derive(Debug, Deserialize)]
struct Record {
    Latitude: f64,
    Longitude: f64,
    Population: Option<u64>,
    City: String,
    State: String,
}
```

However, this violates Rust naming style. (In fact, the Rust compiler will even warn you that the names do not follow convention!)

Another way to fix this is to ask Serde to rename each field individually. This is useful when there is no consistent name mapping from fields to header names:

```rust
#[derive(Debug, Deserialize)]
struct Record {
    #[serde(rename = "Latitude")]
    latitude: f64,
    #[serde(rename = "Longitude")]
    longitude: f64,
    #[serde(rename = "Population")]
    population: Option<u64>,
    #[serde(rename = "City")]
    city: String,
    #[serde(rename = "State")]
    state: String,
}
```

To read more about renaming fields and about other Serde directives, please consult the [Serde documentation on attributes](https://serde.rs/attributes.html).
