>* Rust and CSV parsing 译文（用 Rust 实现 csv 解析-part4）
>* 原文链接：https://blog.burntsushi.net/csv/
>* 原文作者：[BurntSushi](https://github.com/BurntSushi)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust，csv

## Delimiters, quotes and variable length records
>分隔符，引号和可变长度的记录

In this section we’ll temporarily depart from our uspop.csv data set and show how to read some CSV data that is a little less clean. This CSV data uses ; as a delimiter, escapes quotes with \" (instead of "") and has records of varying length. Here’s the data, which contains a list of WWE wrestlers and the year they started, if it’s known:
>在这一节中，我们将暂时抛开 uspop.csv 数据，并展示如何读取一些不太正常的 CSV 数据。这个 CSV 数据使用 `;` 作为分隔符，带有转义的引号 `\"`（不是`""`）并且拥有可变长度的记录。下面是一些示例数据，如果你知道 WWE 的话，可以看出其中是一些 WWE 摔跤手及其出生年份的名单：

```
$ cat strange.csv
"\"Hacksaw\" Jim Duggan";1987
"Bret \"Hit Man\" Hart";1984
# We're not sure when Rafael started, so omit the year.
Rafael Halperin
"\"Big Cat\" Ernie Ladd";1964
"\"Macho Man\" Randy Savage";1985
"Jake \"The Snake\" Roberts";1986
```

To read this CSV data, we’ll want to do the following:
>要读取这些 CSV 数据，我们按照下面的思路来：

* 1.不读取 header，因为没有 header 部分
* 2.将分隔符由 `,` 改为 `;`。
* 3.将双引号（如 `""`）的后半部分转义（如`\"`）
* 4.支持灵活的可变长度记录，因为其中可能会有年份缺省。
* 5.忽略行首是 `#` 的行

All of this (and more!) can be configured with a [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html), as seen in the following example:
>所有这些（或者其他）都可以用 [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html) 来实现，如下方示例：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::ReaderBuilder::new()
        .has_headers(false)
        .delimiter(b';')
        .double_quote(false)
        .escape(Some(b'\\'))
        .flexible(true)
        .comment(Some(b'#'))
        .from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

Now re-compile your project and try running the program on `strange.csv`:
>现在重新编译项目并以 `strange.csv` 作为输入来运行它：

```
$ cargo build
$ ./target/debug/csvtutor < strange.csv
StringRecord(["\"Hacksaw\" Jim Duggan", "1987"])
StringRecord(["Bret \"Hit Man\" Hart", "1984"])
StringRecord(["Rafael Halperin"])
StringRecord(["\"Big Cat\" Ernie Ladd", "1964"])
StringRecord(["\"Macho Man\" Randy Savage", "1985"])
StringRecord(["Jake \"The Snake\" Roberts", "1986"])
```

You should feel encouraged to play around with the settings. Some interesting things you might try:
>你应该多尝试一些其他设置。可能会发生一些有趣的事：

* 1.If you remove the `escape` setting, notice that no CSV errors are reported. Instead, records are still parsed. This is a feature of the CSV parser. Even though it gets the data slightly wrong, it still provides a parse that you might be able to work with. This is a useful property given the messiness of real world CSV data.
* 1.如果你删除了 `escape` 的配置，解析时不会报 CSV 错误。相反，记录仍然被正常解析。这是 CSV 解析器的一个特性。即使它得到的数据有一点错误，它仍然能进行一定程度上的解析。因为考虑到实际使用时，CSV 数据可能有一定的错误。这是一个有用的特性。
* 2.如果删除了 `delimiter` 配置，解析仍然成功，尽管每个记录只有一个字段。
* 3.如果删掉 `flexible` 配置，reader 将会打印前两条记录（因为它们有相同数量的字段），但在第三条记录上返回解析错误，因为它只有一个字段。

This covers most of the things you might want to configure on your CSV reader, although there are a few other knobs. For example, you can change the record terminator from a new line to any other character. (By default, the terminator is `CRLF`, which treats each of `\r\n`, `\r` and `\n` as single record terminators.) For more details, see the documentation and examples for each of the methods on [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html).
>这涵盖了你希望在 CSV 读取器上的所有配置项，尽管还有一些其他的配置。如，你可以将记录终止符从换行改为其他字符。（默认情况下，终止符是 `CRLF`，它将 `\r\n`、`\r`和 `\n` 分别视为单个记录的终止符。）相关详情，可以参考 [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html)。

## Reading with Serde
>基于 Serde 读取

One of the most convenient features of this crate is its support for [Serde](https://serde.rs/). Serde is a framework for automatically serializing and deserializing data into Rust types. In simpler terms, that means instead of iterating over records as an array of string fields, we can iterate over records of a specific type of our choosing.
>我们实现的库最重要的特性之一是对 [Serde](https://serde.rs/) 的支持。Serde 是一个自动将数据序列化和反序列化的 Rust 框架。简单地说，通过它，我们不必将记录作为字符串数组来处理，而是遍历特定类型的数据。

For example, let’s take a look at some data from our `uspop.csv` file:
>我们看看 `uspop.csv` 中的示例数据：

```
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
```

While some of these fields make sense as strings (`City`, `State`), other fields look more like numbers. For example, Population looks like it contains integers while `Latitude` and `Longitude` appear to contain decimals. If we wanted to convert these fields to their “proper” types, then we need to do a lot of manual work. This next example shows how.
>数据记录中有些字段可以作为字符串处理，如 (`City`, `State`)，另一些则类似于数值。如，Population 那一列，看起来它包含整形值，同时 `Latitude` 和 `Longitude` 则看起来包含小数。如果我们想要将这些字段转换为“适当”的类型，那么我们需要做大量的工作。下面是一些相关操作的示例：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;

        let city = &record[0];
        let state = &record[1];
        // Some records are missing population counts, so if we can't
        // parse a number, treat the population count as missing instead
        // of returning an error.
        let pop: Option<u64> = record[2].parse().ok();
        // Lucky us! Latitudes and longitudes are available for every record.
        // Therefore, if one couldn't be parsed, return an error.
        let latitude: f64 = record[3].parse()?;
        let longitude: f64 = record[4].parse()?;

        println!(
            "city: {:?}, state: {:?}, \
             pop: {:?}, latitude: {:?}, longitude: {:?}",
            city, state, pop, latitude, longitude);
    }
    Ok(())
}
```

The problem here is that we need to parse each individual field manually, which can be labor intensive and repetitive. Serde, however, makes this process automatic. For example, we can ask to deserialize every record into a tuple type: `(String, String, Option<u64>, f64, f64)`.
>这里的问题是我们需要手动解析每一个字段的数据，这些算是劳动密集型和重复型的工作。而 Serde 可以让这个过程自动化。例如，我们将每一条记录反序列化为元组类型：`(String, String, Option<u64>, f64, f64)`。

```rust
// This introduces a type alias so that we can conveniently reference our
// record type.
type Record = (String, String, Option<u64>, f64, f64);

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    // Instead of creating an iterator with the `records` method, we create
    // an iterator with the `deserialize` method.
    for result in rdr.deserialize() {
        // We must tell Serde what type we want to deserialize into.
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

Running this code should show similar output as previous examples:
>运行代码，可以看到下面的输出：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
("Davidsons Landing", "AK", None, 65.2419444, -165.2716667)
("Kenai", "AK", Some(7610), 60.5544444, -151.2583333)
("Oakman", "AL", None, 33.7133333, -87.3886111)
# ... and much more
```

One of the downsides of using Serde this way is that the type you use must match the order of fields as they appear in each record. This can be a pain if your CSV data has a header record, since you might tend to think about each field as a value of a particular named field rather than as a numbered field. One way we might achieve this is to deserialize our record into a map type like [HashMap](https://doc.rust-lang.org/std/collections/struct.HashMap.html) or [BTreeMap](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html). The next example shows how, and in particular, notice that the only thing that changed from the last example is the definition of the Record type alias and a new use statement that imports HashMap from the standard library:
>以这种方式使用 Serde 有个切点缺点，那就是必须按顺序精确匹配记录中的每一个字段。如果 CSV 数据中有头记录，这可能是一个问题，因为你可能倾向于将每个值存在一个命名了的地方，而不是一个数值编号字段。实现这一点的一种方法是将记录反序列化为 [HashMap](https://doc.rust-lang.org/std/collections/struct.HashMap.html) 或 [BTreeMap](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html)。

```rust
use std::collections::HashMap;

// This introduces a type alias so that we can conveniently reference our
// record type.
type Record = HashMap<String, String>;

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

Running this program shows similar results as before, but each record is printed as a map:
>运行这个程序后显示的结果和之前类似，不同的是每条记录会以 map 的方式打印：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
{"City": "Davidsons Landing", "Latitude": "65.2419444", "State": "AK", "Population": "", "Longitude": "-165.2716667"}
{"City": "Kenai", "Population": "7610", "State": "AK", "Longitude": "-151.2583333", "Latitude": "60.5544444"}
{"State": "AL", "City": "Oakman", "Longitude": "-87.3886111", "Population": "", "Latitude": "33.7133333"}
```

This method works especially well if you need to read CSV data with header records, but whose exact structure isn’t known until your program runs. However, in our case, we know the structure of the data in `uspop.csv`. In particular, with the `HashMap` approach, we’ve lost the specific types we had for each field in the previous example when we deserialized each record into a `(String, String, Option<u64>, f64, f64)`. Is there a way to identify fields by their corresponding header name and assign each field its own unique type? The answer is yes, but we’ll need to bring in a new crate called serde_derive first. You can do that by adding this to the `[dependencies]` section of your `Cargo.toml` file:
>如果你需要读取带有头记录的 CSV 数据，但确切的结构需要运行时才确定，那么下面这个方法更有效。然而，在我们的例子中，我们已知 `uspop.csv` 中的数据结构。特别地，使用 `HashMap` 方法，当我们将每条记录反序列化为 `(String, String, Option<u64>, f64, f64)` 时，我们丢失了前面示例中每个字段的类型说明。能否有一种方法来识别字段对应的头名称，并分配每个字段一个确定的类型呢？答案是肯定的，但是首先我们要引入一个名为 `serde_derive` 的 crate。你可以通过将它添加到你的依赖声明 `Cargo.toml` 文件的`[dependencies]` 中：

```
serde = "1"
serde_derive = "1"
```

With these crates added to our project, we can now define our own custom struct that represents our record. We then ask Serde to automatically write the glue code required to populate our struct from a CSV record. The next example shows how. Don’t miss the new `extern crate` lines!
>将这些 crate 添加到我们的项目后，我们现在可以定义记录的结构体。然后，我们要求 Serde 自动实现从 CSV 记录填充数据到结构体实例中的粘合代码。下一个示例将展示具体操作。不要错过 `extern crate` 行！

```rust
extern crate csv;
extern crate serde;
// 这可以让我们可以编写 `#[derive(Deserialize)]` 声明。
 #[macro_use]
extern crate serde_derive;

use std::error::Error;
use std::io;
use std::process;

// We don't need to derive `Debug` (which doesn't require Serde), but it's a
// good habit to do it for all your types.
//
// Notice that the field names in this struct are NOT in the same order as
// the fields in the CSV data!
 #[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    latitude: f64,
    longitude: f64,
    population: Option<u64>,
    city: String,
    state: String,
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
        // Try this if you don't like each record smushed on one line:
        // println!("{:#?}", record);
    }
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

Compile and run this program to see similar output as before:
>编译并运行这个程序，可以看到跟之前类似的输出：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
Record { latitude: 65.2419444, longitude: -165.2716667, population: None, city: "Davidsons Landing", state: "AK" }
Record { latitude: 60.5544444, longitude: -151.2583333, population: Some(7610), city: "Kenai", state: "AK" }
Record { latitude: 33.7133333, longitude: -87.3886111, population: None, city: "Oakman", state: "AL" }
```

Once again, we didn’t need to change our `run` function at all: we’re still iterating over records using the `deserialize` iterator that we started with in the beginning of this section. The only thing that changed in this example was the definition of the `Record` type and a couple new `extern crate` statements. Our Record type is now a custom struct that we defined instead of a type alias, and as a result, Serde doesn’t know how to deserialize it by default. However, a special compiler plugin called `serde_derive` is available, which will read your struct definition at compile time and generate code that will deserialize a CSV record into a `Record` value. To see what happens if you leave out the automatic derive, change `#[derive(Debug, Deserialize)]` to `#[derive(Debug)]`.
>同样，我们根本不需要改变 `run` 函数，我们仍然使用 `deserialize` 迭代器遍历记录，这是我们在本节开始时用到的迭代器。在这个例子中唯一变化的是 `Record` 类型和两个新的 `extern crate` 语句。我们的记录的类型现在是我们定义的自定义类型，而不是类型别名，因此，Serde 默认情况下不知道如何对它反序列化。但是有一个特殊的编译器插件 `serde_derive`，它可以在编译时读取你声明的结构体，并生成代码，将 CSV 记录反序列化为 `Record` 值。若要查看自动派生会发生什么，请将 `#[derive(Debug, Deserialize)]` 改为 `#[derive(Debug)]`。

One other thing worth mentioning in this example is the use of `#[serde(rename_all = "PascalCase")]`. This directive helps Serde map your struct’s field names to the header names in the CSV data. If you recall, our header record is:
>在这个例子中，还有一点需要注意，那就是使用 `#[serde(rename_all = "PascalCase")]`。这个指令将帮助 Serde 把你的结构体的字段映射到 CSV 数据的头部名称。如果你还记得，我们的头记录如下：

```
City,State,Population,Latitude,Longitude
```

Notice that each name is capitalized, but the fields in our struct are not. The `#[serde(rename_all = "PascalCase")]` directive fixes that by interpreting each field in `PascalCase`, where the first letter of the field is capitalized. If we didn’t tell Serde about the name remapping, then the program will quit with an error:
>注意，每个名称都是大写的，但结构体中的字段没有。`#[serde(rename_all = "PascalCase")]` 注解指令通过解析 `PascalCase` 中的每个字段来解决该问题，其中字段的第一个字母是大写的。如果我们没有告诉 Serde 关于名称重映射的信息，那么程序将会退出，并报异常： 

```
$ ./target/debug/csvtutor < uspop.csv
CSV deserialize error: record 1 (line: 2, byte: 41): missing field `latitude`
```

We could have fixed this through other means. For example, we could have used capital letters in our field names:
>我们本可以通过其他方法解决这个问题。如，我们可以使用大写字母作为字段名：

```rust
#[derive(Debug, Deserialize)]
struct Record {
    Latitude: f64,
    Longitude: f64,
    Population: Option<u64>,
    City: String,
    State: String,
}
```

However, this violates Rust naming style. (In fact, the Rust compiler will even warn you that the names do not follow convention!)
>然而，这违反了 Rust 的命名风格。（事实上，Rust 编译器甚至会给你警告，你的命名符合约定！）

Another way to fix this is to ask Serde to rename each field individually. This is useful when there is no consistent name mapping from fields to header names:
>解决这个问题的另一个方法是要求 Serde 单独重命名每个字段。当字段到头部没有明确的映射时，这个方法很有用：

```rust
#[derive(Debug, Deserialize)]
struct Record {
    #[serde(rename = "Latitude")]
    latitude: f64,
    #[serde(rename = "Longitude")]
    longitude: f64,
    #[serde(rename = "Population")]
    population: Option<u64>,
    #[serde(rename = "City")]
    city: String,
    #[serde(rename = "State")]
    state: String,
}
```

To read more about renaming fields and about other Serde directives, please consult the [Serde documentation on attributes](https://serde.rs/attributes.html).
>要阅读更多关于重命名字段和 Serde 的指令信息，可以参考 [Serde 属性文档](https://serde.rs/attributes.html)。
