>* Rust and CSV parsing 译文（用 Rust 实现 csv 解析-完整篇）
>* 原文链接：https://blog.burntsushi.net/csv/
>* 原文作者：[BurntSushi](https://github.com/BurntSushi)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，如有不当之处，欢迎指正
>* 标签：Rust，csv，Parser

随着 csv 1.0 刚刚发布，关于使用 Rust 读取和写入 csv 数据的教程是时候发布了。本教程针对的是刚入门的 Rust 程序员，因此有相当多的示例，并花了一些时间在基础的概念解释上。你可能会发现，其中部分内容很有用，但对有经验的 Rust 程序员来说，快速浏览会更有利。

有关 Rust 的介绍，请参考[官方权威指南](https://doc.rust-lang.org/book/second-edition/)。如果你还没有写过一行 Rust 代码，但有其他编程语言的经验，那么你可能不需要看权威指南就能读懂本教程。

CSV 库在 [Github](https://github.com/BurntSushi/rust-csv) 上是可用的，并且有相应的[文档]((https://docs.rs/csv))。

最后，这个博客的文章会作为一个[教程](https://docs.rs/csv/1.0.0/csv/tutorial/index.html)被包含在 API 文档中，并且后续会有所更新。

目标读者：Rust 初学者。

## CSV 1.0 发布
在开始学习本教程之前，我想简要介绍 1.0 的方向。rust-csv 仓库的第一次提交是 2014.3.22，这比 Rust 1.0 发行版要早了一年多。对于那些从 1.0 之前就开始接触 Rust 的人来说，肯定还记得该语言发生了多大的变化。当然，我也改变了，因为我变得更熟练和习惯于它。然而，从最初的版本开始，csv 库的 API 基本保持不变。这使得提高性能和修复 bug 变得更加困难，最糟糕的是，使用了旧版的序列化架构。

CSV1.0 版本标志着这是一个更快的库，拥有更好的 API，并支持 Rust 序列化框架 [Serde](https://serde.rs/)。

新的 CSV 库附带一个 [`csv-core`](https://docs.rs/csv-core) crate，它可以在没有 Rust 标准库的情况下解析 CSV 数据，并且主要负责性能改进。特别地，旧版的 CSV 库使用了一种有限状态机，它有很大的开销。而 csv-core crate 将其解析为一个基于 DFA 的表，该表在堆栈上只占用几百个字节。结果，我们得到超过 2 倍的性能改进：

```
count_game_deserialize_owned_bytes  30,404,805 (85 MB/s)   23,878,089 (108 MB/s)    -6,526,716  -21.47%   x 1.27
count_game_deserialize_owned_str    30,431,169 (85 MB/s)   22,861,276 (113 MB/s)    -7,569,893  -24.88%   x 1.33
count_game_iter_bytes               21,751,711 (119 MB/s)  11,873,257 (218 MB/s)    -9,878,454  -45.41%   x 1.83
count_game_iter_str                 25,609,184 (101 MB/s)  13,769,390 (188 MB/s)   -11,839,794  -46.23%   x 1.86
count_game_read_bytes               12,110,082 (214 MB/s)  6,686,121 (388 MB/s)     -5,423,961  -44.79%   x 1.81
count_game_read_str                 15,497,249 (167 MB/s)  8,269,207 (314 MB/s)     -7,228,042  -46.64%   x 1.87
count_mbta_deserialize_owned_bytes  5,779,138 (125 MB/s)   3,775,874 (191 MB/s)     -2,003,264  -34.66%   x 1.53
count_mbta_deserialize_owned_str    5,777,055 (125 MB/s)   4,353,921 (166 MB/s)     -1,423,134  -24.63%   x 1.33
count_mbta_iter_bytes               3,991,047 (181 MB/s)   1,805,387 (400 MB/s)     -2,185,660  -54.76%   x 2.21
count_mbta_iter_str                 4,726,647 (153 MB/s)   2,354,842 (307 MB/s)     -2,371,805  -50.18%   x 2.01
count_mbta_read_bytes               2,690,641 (268 MB/s)   1,253,111 (577 MB/s)     -1,437,530  -53.43%   x 2.15
count_mbta_read_str                 3,399,631 (212 MB/s)   1,743,035 (415 MB/s)     -1,656,596  -48.73%   x 1.95
count_nfl_deserialize_owned_bytes   10,608,513 (128 MB/s)  5,828,747 (234 MB/s)     -4,779,766  -45.06%   x 1.82
count_nfl_deserialize_owned_str     10,612,366 (128 MB/s)  6,814,770 (200 MB/s)     -3,797,596  -35.78%   x 1.56
count_nfl_iter_bytes                6,798,767 (200 MB/s)   2,564,448 (532 MB/s)     -4,234,319  -62.28%   x 2.65
count_nfl_iter_str                  7,888,662 (172 MB/s)   3,579,865 (381 MB/s)     -4,308,797  -54.62%   x 2.20
count_nfl_read_bytes                4,588,369 (297 MB/s)   1,911,120 (714 MB/s)     -2,677,249  -58.35%   x 2.40
count_nfl_read_str                  5,755,926 (237 MB/s)   2,847,833 (479 MB/s)     -2,908,093  -50.52%   x 2.02
count_pop_deserialize_owned_bytes   11,052,436 (86 MB/s)   8,848,364 (108 MB/s)     -2,204,072  -19.94%   x 1.25
count_pop_deserialize_owned_str     11,054,638 (86 MB/s)   9,184,678 (104 MB/s)     -1,869,960  -16.92%   x 1.20
count_pop_iter_bytes                6,190,345 (154 MB/s)   3,110,704 (307 MB/s)     -3,079,641  -49.75%   x 1.99
count_pop_iter_str                  7,679,804 (124 MB/s)   4,274,842 (223 MB/s)     -3,404,962  -44.34%   x 1.80
count_pop_read_bytes                3,898,119 (245 MB/s)   2,218,535 (430 MB/s)     -1,679,584  -43.09%   x 1.76
count_pop_read_str                  5,195,237 (183 MB/s)   3,209,998 (297 MB/s)     -1,985,239  -38.21%   x 1.62
```

以上就是所有的介绍了，我们可以开始了！


## Setup
在这一节中，我们会编写一个简单的程序来读取 CSV 数据并以 debug 的方式打印每条记录。这是基于你已经安装了 [Rust 工具链](https://www.rust-lang.org/install.html)，工具链中包含了 Rust 编译器和 Cargo（包管理工具）。

我们以创建一个新的 Cargo 项目作为开始：

```
$ cargo new --bin csvtutor
$ cd csvtutor
```

进入 `csvtutor` 目录，使用你最喜欢的文本编辑器打开 `Cargo.toml` 文件，向其中新增 `csv = "1"` 到你的依赖配置块中。此时，你的 `Cargo.toml` 文件内容应该如下方所示：

```toml
[package]
name = "csvtutor"
version = "0.1.0"
authors = ["Your Name"]

[dependencies]
csv = "1"
```

接下来，我们构建项目。由于你新增了 csv crate 作为依赖，Cargo 会自动下载并编译它。构建项目使用 Cargo 命令：

```
$ cargo build
```

在你的 `target/debug` 目录下，会产生一个新的二进制文件，`csvtutor`。这一点上这个命令不会做太多，但你可以执行这个二进制文件：

```
$ ./target/debug/csvtutor
Hello, world!
```

我们可以让程序做一些有用的事情。程序可以从标准输入读取 csv 数据并在标准输出打印每一条记录。要完成这个程序，先用你喜欢的编辑器打开 `src/main.rs`，然后用下面的内容替换其中的内容：

```rust
// 这可以让你的程序能访问 csv crate
extern crate csv;

// 导入标准库中的 I/O 模块，这样我们可以从标准输入读取内容
use std::io;

// `main` 函数是程序开始执行的地方
fn main() {
    // 从标准输入读取数据并创建一个 CSV 解析器
    let mut rdr = csv::Reader::from_reader(io::stdin());
    // 遍历每一条记录
    for result in rdr.records() {
        // 一旦发生错误，程序将会以不太友好的方式终止
        // 我们后面会优化这里
        let record = result.expect("a CSV record");
        // 以 debug 的方式打印
        println!("{:?}", record);
    }
}
```

别太担心读不懂代码的意思；我们会在下一节详细说明。现在，重新构建一下项目：

```
$ cargo build
```

如果成功了，我们可以尝试运行一下它。但在此之前，我们需要一些示例 CSV 数据！为此，我们将选择随机的 100 个美国城市，以及它们的人口规模和地理坐标。（我们将在整个教程中使用一样的 CSV 数据。）要获取数据，请从 GitHub 下载：

```
$ curl -LO 'https://raw.githubusercontent.com/BurntSushi/rust-csv/master/examples/data/uspop.csv'
```

现在，使用 uspop.csv 作为输入，来运行你的程序：

```
$ ./target/debug/csvtutor < uspop.csv
StringRecord(["Davidsons Landing", "AK", "", "65.2419444", "-165.2716667"])
StringRecord(["Kenai", "AK", "7610", "60.5544444", "-151.2583333"])
StringRecord(["Oakman", "AL", "", "33.7133333", "-87.3886111"])
# ... and much more
```

## 基础的异常处理

由于读取 CSV 数据可能会得到异常结果，因此本教程中的示例中是普遍存在的。因此，我们将花一点时间来学习基本的错误处理，特别是修复我们前面的一些示例，以便更友好地显示错误。**如果你已经习惯在 Rust 中使用 `Result` 和 `try!/?`，那么你可以安全地跳过这个部分**

请注意 [Rust 权威指南](https://doc.rust-lang.org/book/second-edition/)中包含了一些[通用的异常处理的介绍](https://doc.rust-lang.org/book/second-edition/ch09-00-error-handling.html)。如果要更深入的了解，可以看我的 [Rust 中的错误处理](http://blog.burntsushi.net/rust-error-handling/)。如果你打算构建 Rust 库，那么这篇文章尤其重要。

这样一来，Rust 中的错误处理就有两种不同的形式：不可恢复的错误和可恢复的错误。

不可恢复的异常通常是程序中的异常，这些异常可能发生在规则被破坏的时候。此时，你的程序的状态是不可预测的，除了 panic 之外，通常也没有什么其他办法。在 Rust 中，panic 类似于简单地终止程序，但是它会在程序退出之前展开堆栈并清理资源。

另一方面，可恢复异常通常应用于可预测的错误。不存在的文件或者无效的 CSV 数据是可恢复错误的例子。在 Rust 中，可恢复异常是通过 `Result` 处理的。一个 `Result` 表示计算成功或者失败的状态。它的定义如下：

```rust
enum Result<T, E> {
    Ok(T),
    Err(E),
}
```

也就是说，`Result` 在计算成功时包含类型为 `T` 的值，或者在计算失败时包含 `E` 类型的值。

不可恢复异常和可恢复异常之间的关系很重要。特别地，**强烈建议**将可恢复异常当做不可恢复异常。例如，在找不到文件或者 CSV 数据不合法时，使用 panic 不是一个好的实践。相反，可预测的异常应该使用 Rust 的 `Result` 类型来处理。

有了新了解的知识，让我们重新检查前面的示例并分析它的错误处理。

```rust
extern crate csv;

use std::io;

fn main() {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        let record = result.expect("a CSV record");
        println!("{:?}", record);
    }
}
```

在这个程序中有两个地方可能发生错误。第一个地方是从标准输入读取记录是否有问题。第二个是写入到标准输出是否有问题。一般来说，在本教程中我们将忽略后一个问题，尽管健壮的命令行应用程序应该对它进行处理（例如，当管道坏掉时）。然而，前面那个问题更值得详细研究。例如，如果这个程序的用户提供了无效的 CSV 数据，那么程序会发生 panic：

```
$ cat invalid
header1,header2
foo,bar
quux,baz,foobar
$ ./target/debug/csvtutor < invalid
StringRecord { position: Some(Position { byte: 16, line: 2, record: 1 }), fields: ["foo", "bar"] }
thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: UnequalLengths { pos: Some(Position { byte: 24, line: 3, record: 2 }), expected_len: 2, len: 3 }', /checkout/src/libcore/result.rs:859
note: Run with `RUST_BACKTRACE=1` for a backtrace.
```

这里发生了什么？首先，我们应该讨论为什么 CSV 数据是无效的。CSV 数据由三条记录组成：一个头部和两条数据记录。头部和第一个数据记录有两个字段，但是第二个数据记录有三个字段。默认情况下， csv crate 将把不一致长度的记录视为错误。（此行为可以使用 [ReaderBuilder::flexible](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html#method.flexible)配置来切换。）这解释了为什么在本例中只打印了第一个数据记录，因为它的字段数量与头部记录数相同。也就是说，在解析第二个数据记录之前，我们实际没有碰到错误。

（请注意，CSV reader 会自动将第一个记录看做头部。这可以通过 [ReaderBuilder::has_headers](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html#method.has_headers) 配置切换。）

那么究竟是什么导致了我们程序中的 panic 呢？应该是是循环中的第一行代码了：

```rust
for result in rdr.records() {
    let record = result.expect("a CSV record"); // 这里会发生 panic
    println!("{:?}", record);
}
```
这里要理解的关键一点是，`rdr.records()` 返回一个迭代器，这个迭代器会返回 `Result` 值。也就是说，它生成的不是记录，而是包含记录或错误的 `Result`。在 `Result` 上定义的 `expect` 方法在 `Result` 中拿出成功的值。由于 `Result` 可能包含错误，所以当它包装的是错误时，`expect` 就会产生 panic。

这里可能会帮助你查看 `expect` 的具体实现：

```rust
use std::fmt;

// This says, "for all types T and E, where E can be turned into a human
// readable debug message, define the `expect` method."
impl<T, E: fmt::Debug> Result<T, E> {
    fn expect(self, msg: &str) -> T {
        match self {
            Ok(t) => t,
            Err(e) => panic!("{}: {:?}", msg, e),
        }
    }
}
```

由于这导致 panic，如果 CSV 数据是无效的，那么这就是一个完全可预测的错误，我们已经把本应该是可恢复的错误转变成 _不可恢复_ 错误。我们这样做是因为使用不可恢复的错误有时候是有利的。由于这是一种糟糕的实践，所以在本教程的其余部分，我们会尽量避免使用不可恢复错误。

## 转换成使用可恢复错误

我们将通过 3 个步骤将不可恢复错误转换为可恢复错误。首先，我们先摆脱 panic，手动打印一个错误消息：

```rust
extern crate csv;

use std::io;
use std::process;

fn main() {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        // Examine our Result.
        // If there was no problem, print the record.
        // Otherwise, print the error message and quit the program.
        match result {
            Ok(record) => println!("{:?}", record),
            Err(err) => {
                println!("error reading CSV from <stdin>: {}", err);
                process::exit(1);
            }
        }
    }
}
```

如果我们再次运行程序，我们将会看到一个错误消息，但不再是一个 panic 的消息：

```
$ cat invalid
header1,header2
foo,bar
quux,baz,foobar
$ ./target/debug/csvtutor < invalid
StringRecord { position: Some(Position { byte: 16, line: 2, record: 1 }), fields: ["foo", "bar"] }
error reading CSV from <stdin>: CSV error: record 2 (line: 3, byte: 24): found record with 3 fields, but the previous record has 2 fields
```

转换成可恢复错误的第 2 步是将我们的 CSV 记录循环放入一个单独的函数中。然后这个函数可以选择返回遇到的第一个错误，然后我们的 main 函数可以检查并决定如何处理这个错误。

```rust
extern crate csv;

use std::error::Error;
use std::io;
use std::process;

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        // Examine our Result.
        // If there was no problem, print the record.
        // Otherwise, convert our error to a Box<Error> and return it.
        match result {
            Err(err) => return Err(From::from(err)),
            Ok(record) => {
              println!("{:?}", record);
            }
        }
    }
    Ok(())
}
```

我们的新函数 —— `run`，其返回值类型是 `Result<(), Box<Error>>`。简单地说，这表示 run 在成功时不返回任何内容，或者发生错误时，它返回 `Box<Error>`，它表示“任意类型的错误”。如果我们只关心发生的某一些具体错误，检查 `Box<Error>` 是比较难的。但出于我们的目的，我们需要做的就是优雅地打印错误消息并退出程序。

第 3 步也是最后一步，使用 Rust 语言的一个特殊特性：问号标记符。

```rust
extern crate csv;

use std::error::Error;
use std::io;
use std::process;

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        // This is effectively the same code as our `match` in the
        // previous example. In other words, `?` is syntactic sugar.
        let record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

最后一步是展示如何使用 `?` 自动将错误转发给我们的调用者，而不需要显示地进行 `match` 匹配处理。我们在使用 `?` 时，在本教程中非常重要的一点是，它**只能在返回值为 `Result` 类型的函数**中使用。

在结束本节时，我们要提醒一句：使用 `Box<Error>` 作为错误类型是我们在这里所能接受的最低限度。也就是说，虽然它能让我们的程序优雅地处理错误，但它使调用者很难检查发生的具体错误。然而，由于这是一个关于编写命令行 CSV 解析的教程，因此我们优先考虑自己的需求，使自己满意就行。如果你想了解更多，或者对编写处理 CSV 数据的库感兴趣，那么你可以查阅我的[错误处理的博客文章](http://blog.burntsushi.net/rust-error-handling/)。

话虽如此，如果你所做的只是编写一个一次性的程序来执行 CSV 转换，那么在错误发生时使用 expect 和 panic 之类的方法是非常合理的。不过本教程将努力展示平常使用的正常代码。


## 读取 CSV
现在我们介绍并学会了基本的错误处理，这下我们可以做我们真正要做的事情：处理 CSV 数据。我们前面已经了解了如何从 stdin 中读取 CSV 数据，但本节将介绍如何从文件中读取 CSV 数据，以及如何将 CSV reader 配置为支持读取不同的分隔符或格式策略的数据。

首先，我们修改前面那个示例，以使其接受文件路径参数而不是从 stdin 中读取。

```rust
extern crate csv;

use std::env;
use std::error::Error;
use std::ffi::OsString;
use std::fs::File;
use std::process;

fn run() -> Result<(), Box<Error>> {
    let file_path = get_first_arg()?;
    let file = File::open(file_path)?;
    let mut rdr = csv::Reader::from_reader(file);
    for result in rdr.records() {
        let record = result?;
        println!("{:?}", record);
    }
    Ok(())
}

/// 返回发送给此进程的第一个参数。如果没有，则返回一个错误。
fn get_first_arg() -> Result<OsString, Box<Error>> {
    match env::args_os().nth(1) {
        None => Err(From::from("expected 1 argument, but got none")),
        Some(file_path) => Ok(file_path),
    }
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

如果你用上面的代码替换了 src/main.rs 文件的内容，你应该能够重新构建你的项目，尝试运行它：

```
$ cargo build
$ ./target/debug/csvtutor uspop.csv
StringRecord(["Davidsons Landing", "AK", "", "65.2419444", "-165.2716667"])
StringRecord(["Kenai", "AK", "7610", "60.5544444", "-151.2583333"])
StringRecord(["Oakman", "AL", "", "33.7133333", "-87.3886111"])
# ... and much more
```

这个示例代码包含两部分：

* 查询程序当前的命令行位置参数。我们将这段代码放入新的函数调用 get_first_arg 中。在函数中，期望第一个参数是文件路径（索引为 1；索引 0 的参数是是可执行文件的名称），因此，如果不存在， get_first_arg 将返回一个错误。
* 打开文件的代码。在运行时，我们使用 file:open 打开一个文件。如果在打开文件时出现问题，我们将错误返回给其调用者（在这个程序中就是 main）。注意，我们没有将文件内容包装在缓冲区中。CSV reader 在内部会有缓冲区，因此不需要调用者再声明一个缓冲区。

现在是介绍另一个 CSV reader 构造函数的好时机。它使打开 CSV 文件更加便利。而不是使用下面这个：

```rust
let file_path = get_first_arg()?;
let file = File::open(file_path)?;
let mut rdr = csv::Reader::from_reader(file);
```

你可以使用：

```rust
let file_path = get_first_arg()?;
let mut rdr = csv::Reader::from_path(file_path)?;
```

`csv::Reader::from_path` 会打开文件，并在异常时返回错误。

## 读取 headers

如果有时间可以看一下 uspop.csv 的内部数据，你会注意到，它的头部记录看起来像下面这样：

```
City,State,Population,Latitude,Longitude
```

现在，如果你看看目前所有的示例程序的命令行输出，你会注意到，头部记录从未打印出来，这是为何呢？，默认情况下，CSV reader 将读取 CSV 数据中的第一条记录作为头部，第一行记录通常不作为实际数据。因此，每当你尝试读取或迭代 CSV 数据时，头记录会被跳过。

CSV reader 不会智能地处理头记录，也不会使用任何高深莫测的方法来自动检测第一个记录是否为头记录。相反，如果你不想将第一个记录作为头记录，那么你需要告诉 CSV reader，没有头记录。

要配置 CSV reader 来实现这一点，我们需要使用一个 ReaderBuilder 来构建 CSV reader。这里有个示例。（注意，代码中回到了从 stdin 中读取数据，因为这样的示例更简洁。）

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::ReaderBuilder::new()
        .has_headers(false)
        .from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

如果你用我们的 uspop.csv 作为输入构建程序，那么你会看到头记录将被打印出来：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
StringRecord(["City", "State", "Population", "Latitude", "Longitude"])
StringRecord(["Davidsons Landing", "AK", "", "65.2419444", "-165.2716667"])
StringRecord(["Kenai", "AK", "7610", "60.5544444", "-151.2583333"])
StringRecord(["Oakman", "AL", "", "33.7133333", "-87.3886111"])
```

如果你需要直接访问头记录，那么你可以使用 Reader::headers 方法，示例如下：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    {
        // 由于生命周期的原因，我们将此调用嵌套在一个新的词法作用域中。
        let headers = rdr.headers()?;
        println!("{:?}", headers);
    }
    for result in rdr.records() {
        let record = result?;
        println!("{:?}", record);
    }
    // 我们可以任意的获取 header。没有必要建立新的作用域进行调用，因为我们再也不需要借用 reader 中的数据。
    let headers = rdr.headers()?;
    println!("{:?}", headers);
    Ok(())
}
```

在本例中要注意一件有趣的事是，我们对 rdr.headers() 的调用会放在一个独立的作用域中。之所以这样做，是因为 rdr.headers() 返回 reader 内部的 header 借用。此代码中的大括号嵌套的作用域可以让在我们遍历数据之前结束借用。如果我们没有将 rdr.headers() 的调用放在新的作用域中，那么代码将无法通过编译，因为我们不能在尝试借用它头部的同时，又借用 reader 来迭代数据记录。

解决这个问题的另一个方法是克隆 header 记录：

```rust
let headers = rdr.headers()?.clone();
```

这将原本使用来自 CSV reader 的 header 借用转变为拥有一个新值的所有权。这使代码更易懂，但代价是需要新的内存分配存放头记录。


## 分隔符，引号和可变长度的记录

在这一节中，我们将暂时抛开 uspop.csv 数据集，而是展示如何读取一些不太“干净”的 CSV 数据。这个 CSV 数据使用 `;` 作为分隔符，带有转义的引号 `\"`（不是`""`）并且拥有可变长度的记录。下面是一些示例数据，如果你知道 WWE 的话，可以看出其中是一些 WWE 摔跤手及其出生年份的名单：

```
$ cat strange.csv
"\"Hacksaw\" Jim Duggan";1987
"Bret \"Hit Man\" Hart";1984
# We're not sure when Rafael started, so omit the year.
Rafael Halperin
"\"Big Cat\" Ernie Ladd";1964
"\"Macho Man\" Randy Savage";1985
"Jake \"The Snake\" Roberts";1986
```

要读取这些 CSV 数据，我们按照下面的思路来：

* 1.不读取 header，因为没有 header 部分
* 2.将分隔符由 `,` 改为 `;`。
* 3.将双引号（如 `""`）的后半部分转义（如`\"`）
* 4.支持灵活的可变长度记录，因为其中可能会有年份缺省。
* 5.忽略行首是 `#` 的行

所有这些（也许有更多其它的）都可以通过配置 [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html) 来实现，如下方示例：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::ReaderBuilder::new()
        .has_headers(false)
        .delimiter(b';')
        .double_quote(false)
        .escape(Some(b'\\'))
        .flexible(true)
        .comment(Some(b'#'))
        .from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

现在重新编译项目并以 `strange.csv` 作为输入参数来运行它：

```
$ cargo build
$ ./target/debug/csvtutor < strange.csv
StringRecord(["\"Hacksaw\" Jim Duggan", "1987"])
StringRecord(["Bret \"Hit Man\" Hart", "1984"])
StringRecord(["Rafael Halperin"])
StringRecord(["\"Big Cat\" Ernie Ladd", "1964"])
StringRecord(["\"Macho Man\" Randy Savage", "1985"])
StringRecord(["Jake \"The Snake\" Roberts", "1986"])
```

你应该多尝试一些其他设置。可能会发生一些有趣的事：

* 1.如果你删除了 `escape` 设置，解析时不会报 CSV 错误。相反，记录仍然被正常解析。这是 CSV 解析器的一个特性。即使它得到的数据有一点错误，它仍然能进行一定程度上的解析。因为考虑到实际使用时，CSV 数据可能有一定的错误。这是一个有用的特性。
* 2.如果删除了 `delimiter` 设置，解析仍然成功，尽管每个记录只有一个字段。
* 3.如果删掉 `flexible` 设置，读取器将会打印前两条记录（因为它们有相同数量的字段），但在第三条记录上返回解析错误，因为它只有一个字段。

这涵盖了你希望在 CSV 读取器上的所有配置项，尽管还有一些其他的配置。如，你可以将记录终止符从换行改为其他字符。（默认情况下，终止符是 `CRLF`，它将 `\r\n`、`\r`和 `\n` 分别视为单个记录的终止符。）相关详情，可以参考 [ReaderBuilder](https://docs.rs/csv/1.0.0/csv/struct.ReaderBuilder.html)。

## 基于 Serde 读取

我们的库最重要的特性之一是对 [Serde](https://serde.rs/) 的支持。Serde 是一个自动将数据序列化和反序列化的 Rust 框架。简单地说，通过它，我们不是将记录作为字符串数组来处理，而是特定类型数据的数组。

我们看看 `uspop.csv` 中的示例数据：

```
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
```

数据记录中有些字段可以作为字符串处理，如 (`City`, `State`)，另一些则类似于数值。如，Population 那一列，看起来它包含整形值，同时 `Latitude` 和 `Longitude` 则看起来包含小数。如果我们想要将这些字段转换为“适当”的类型，那么我们需要做大量的工作。下面是一些相关操作的示例：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.records() {
        let record = result?;

        let city = &record[0];
        let state = &record[1];
        // 一些记录会丢失 population 的计数，所以如果我们无法解析一个数值，则视 population 列的统计为丢失，而不是返回一个错误。
        let pop: Option<u64> = record[2].parse().ok();
        // 我们太幸运了！所有记录中的 Latitudes 和 longitudes 列都是正常的。因此，如果有一条记录不能解析，则犯规返回错误。
        let latitude: f64 = record[3].parse()?;
        let longitude: f64 = record[4].parse()?;

        println!(
            "city: {:?}, state: {:?}, \
             pop: {:?}, latitude: {:?}, longitude: {:?}",
            city, state, pop, latitude, longitude);
    }
    Ok(())
}
```

这里的问题是我们需要手动解析每一个字段的数据，这些算是劳动密集型和重复型的工作。而 Serde 可以让这个过程自动化。例如，我们可以将每一条记录反序列化为元组类型：`(String, String, Option<u64>, f64, f64)`。

```rust
// 这里引入了一些类型别名，这样我们可以便利地使用我们的记录类型。
type Record = (String, String, Option<u64>, f64, f64);

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    // 这里不再是一个 `records` 方法的迭代器，而是 `deserialize` 方法的迭代器。
    for result in rdr.deserialize() {
        // 我们必须告诉 Serde 我们想要的反序列化后的目标类型。
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

运行代码，可以看到形如下面的输出：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
("Davidsons Landing", "AK", None, 65.2419444, -165.2716667)
("Kenai", "AK", Some(7610), 60.5544444, -151.2583333)
("Oakman", "AL", None, 33.7133333, -87.3886111)
# ... and much more
```

以这种方式使用 Serde 有个缺点，那就是必须按顺序精确匹配记录中的每一个字段。如果 CSV 数据中有头记录，这可能是一个问题，因为你可能倾向于将每个值存在一个命名了的字段中，而不是一个数值编号的字段中。实现这一点的一种方法是将记录反序列化为 [HashMap](https://doc.rust-lang.org/std/collections/struct.HashMap.html) 或 [BTreeMap](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html)。特别地，下一个例子所展示的，与之前示例有所不同，那就是使用类型别名的定义和使用关键字 use 从标准库中导入的 HashMap：

```rust
use std::collections::HashMap;

// 这里使用类型别名，以便于我们引用记录的类型。
type Record = HashMap<String, String>;

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

运行这个程序后显示的结果和之前类似，不同的是每条记录会以 map 的方式打印：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
{"City": "Davidsons Landing", "Latitude": "65.2419444", "State": "AK", "Population": "", "Longitude": "-165.2716667"}
{"City": "Kenai", "Population": "7610", "State": "AK", "Longitude": "-151.2583333", "Latitude": "60.5544444"}
{"State": "AL", "City": "Oakman", "Longitude": "-87.3886111", "Population": "", "Latitude": "33.7133333"}
```

如果你需要读取带有头记录的 CSV 数据，但确切的结构需要运行时才确定，那么下面这个方法更有效。然而，在我们的例子中，我们已知 `uspop.csv` 中的数据结构。特别地，使用 `HashMap` 方法，当我们将每条记录反序列化为 `(String, String, Option<u64>, f64, f64)` 时，我们丢失了前面示例中每个字段的类型说明。能否有一种方法来识别字段对应的头名称，并分配每个字段一个确定的类型呢？答案是肯定的，但是首先我们要引入一个名为 `serde_derive` 的 crate。你可以通过将它添加到你的依赖声明 `Cargo.toml` 文件的`[dependencies]` 中：

```
serde = "1"
serde_derive = "1"
```

将这些 crate 添加到我们的项目后，我们现在可以定义记录的结构体。然后，我们让 Serde 自动实现从 CSV 记录填充数据到结构体实例中的粘合代码。下一个示例将展示具体操作。注意不要忽视 `extern crate` 行！

```rust
extern crate csv;
extern crate serde;
// 这可以让我们可以编写 `#[derive(Deserialize)]` 声明。
 #[macro_use]
extern crate serde_derive;

use std::error::Error;
use std::io;
use std::process;

// 我们无需 derive `Debug`（它无需 Serde），但对于所有类型来说，把它加上是一个不错的习惯。
//
// 注意结构体中的字段名不是按照 CSV 数据中的顺序！
 #[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    latitude: f64,
    longitude: f64,
    population: Option<u64>,
    city: String,
    state: String,
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
        // 如果你不喜欢所有的内容缩卷到一行，可以试试下面这个打印：
        // println!("{:#?}", record);
    }
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

编译并运行这个程序，可以看到跟之前类似的输出：

```
$ cargo build
$ ./target/debug/csvtutor < uspop.csv
Record { latitude: 65.2419444, longitude: -165.2716667, population: None, city: "Davidsons Landing", state: "AK" }
Record { latitude: 60.5544444, longitude: -151.2583333, population: Some(7610), city: "Kenai", state: "AK" }
Record { latitude: 33.7133333, longitude: -87.3886111, population: None, city: "Oakman", state: "AL" }
```

同样，我们根本不需要改变 `run` 函数，我们仍然使用 `deserialize` 迭代器遍历记录，这是我们在本节开始时用到的迭代器。在这个例子中唯一变化的是 新定义的`Record` 类型和两个新的 `extern crate` 语句。我们的记录的类型现在是我们定义的自定义类型，而不是类型别名，因此，Serde 默认情况下不知道如何对它反序列化。但是有一个特殊的编译器插件 `serde_derive`，它可以在编译时读取你声明的结构体，并生成代码，将 CSV 记录反序列化为 `Record` 值。若要查看没有自动派生会发生什么，请将 `#[derive(Debug, Deserialize)]` 改为 `#[derive(Debug)]`。

在这个例子中，还有一点需要注意，那就是使用 `#[serde(rename_all = "PascalCase")]`。这个指令将帮助 Serde 把你的结构体的字段映射到 CSV 数据的头部名称。如果你还记得，我们的头记录如下：

```
City,State,Population,Latitude,Longitude
```

注意，每个名称首字母是大写的，但结构体中的字段没有。`#[serde(rename_all = "PascalCase")]` 注解指令通过解析 `PascalCase` 中的每个字段来解决该问题，其中字段的第一个字母是大写的。如果我们没有告诉 Serde 关于名称重映射的信息，那么程序将会退出，并报异常： 

```
$ ./target/debug/csvtutor < uspop.csv
CSV deserialize error: record 1 (line: 2, byte: 41): missing field `latitude`
```

我们本可以通过其他方法解决这个问题。如，我们可以使用首大写字母的标识符作为字段名：

```rust
#[derive(Debug, Deserialize)]
struct Record {
    Latitude: f64,
    Longitude: f64,
    Population: Option<u64>,
    City: String,
    State: String,
}
```

然而，这违反了 Rust 的命名风格。（事实上，Rust 编译器甚至会给你警告，你的命名不符合约定！）

解决这个问题的另一个方法是要求 Serde 单独重命名每个字段。当字段到头部的映射不一致时，这个方法很有用：

```rust
#[derive(Debug, Deserialize)]
struct Record {
    #[serde(rename = "Latitude")]
    latitude: f64,
    #[serde(rename = "Longitude")]
    longitude: f64,
    #[serde(rename = "Population")]
    population: Option<u64>,
    #[serde(rename = "City")]
    city: String,
    #[serde(rename = "State")]
    state: String,
}
```

要阅读更多关于重命名字段和 Serde 的指令信息，可以参考 [Serde 属性相关文档](https://serde.rs/attributes.html)。

## 使用 Serde 处理非法数据
在本节中，我们将看到一个关于如何处理非正常数据的简单示例。为了完成这个练习，我们将使用前面一直使用的美国人口数据的调整版。这个版本的数据比之前要混乱一些。你可以下载它：

```
$ curl -LO 'https://raw.githubusercontent.com/BurntSushi/rust-csv/master/examples/data/uspop-null.csv'
```

我们基于上一节的示例程序，继续开发：

```rust
#[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    latitude: f64,
    longitude: f64,
    population: Option<u64>,
    city: String,
    state: String,
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

编译并用我们的不整洁数据运行它：

```
$ cargo build
$ ./target/debug/csvtutor < uspop-null.csv
Record { latitude: 65.2419444, longitude: -165.2716667, population: None, city: "Davidsons Landing", state: "AK" }
Record { latitude: 60.5544444, longitude: -151.2583333, population: Some(7610), city: "Kenai", state: "AK" }
Record { latitude: 33.7133333, longitude: -87.3886111, population: None, city: "Oakman", state: "AL" }
# ... more records
CSV deserialize error: record 42 (line: 43, byte: 1710): field 2: invalid digit found in string
```

哇！发生什么了？程序打印了几条记录，但是当它反序列化时遇到问题时停止了。错误消息显示，它在第 43 行第 2 个字段（即 `Population` 字段）中发现了一个无效的数字。第 43 行是什么？

```
$ head -n 43 uspop-null.csv | tail -n1
Flint Springs,KY,NULL,37.3433333,-86.7136111
```

啊！第三个字段（索引为 2）应该要么是空的，要么是人口计数。但是，在这里，似乎值就是 `NULL`，作者可能是为了表明这里没有计数。

我们程序当前的问题是，它无法读取这个记录，因为它不知道如何将 `NULL` 反序列化为 `Option<u64>` 类型。也就是说，`Option<u64>` 要么对应一个空值。要么对应一个整数。

为了修复这个问题，我们需要让 Serde 在这个字段上支持将任意反序列化时的错误转换为一个 `None` 值，如下方示例所示：

```rust
#[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    latitude: f64,
    longitude: f64,
    #[serde(deserialize_with = "csv::invalid_option")]
    population: Option<u64>,
    city: String,
    state: String,
}

fn run() -> Result<(), Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    for result in rdr.deserialize() {
        let record: Record = result?;
        println!("{:?}", record);
    }
    Ok(())
}
```

如果你编译并运行这个示例，它能像其他示例一样执行完成：

```
$ cargo build
$ ./target/debug/csvtutor < uspop-null.csv
Record { latitude: 65.2419444, longitude: -165.2716667, population: None, city: "Davidsons Landing", state: "AK" }
Record { latitude: 60.5544444, longitude: -151.2583333, population: Some(7610), city: "Kenai", state: "AK" }
Record { latitude: 33.7133333, longitude: -87.3886111, population: None, city: "Oakman", state: "AL" }
# ... and more
```

这个示例中唯一改变的是向记录中 population 字段增加了这个属性：

```rust
#[serde(deserialize_with = "csv::invalid_option")]
```

[invalid_option](https://docs.rs/csv/1.0.0/csv/fn.invalid_option.html) 函数是一个通用的辅助函数，它做了一件非常简单的事情：当其作用于字段时，它把任何反序列化错误转换为 None 值。当你需要处理混乱的 CSV 数据时，这非常好用。

## 写入 CSV 数据
在这一节中，我们会展示一些写 CSV 数据的示例。写入 CSV 数据往往比读取 CSV 数据更直接一些，因为你需要控制输出格式。

我们先从最基本的例子开始：写一些 CSV 数据记录到标准输出。


```rust
extern crate csv;

use std::error::Error;
use std::io;
use std::process;

fn run() -> Result<(), Box<Error>> {
    let mut wtr = csv::Writer::from_writer(io::stdout());
    // Since we're writing records manually, we must explicitly write our
    // header record. A header record is written the same way that other
    // records are written.
    wtr.write_record(&["City", "State", "Population", "Latitude", "Longitude"])?;
    wtr.write_record(&["Davidsons Landing", "AK", "", "65.2419444", "-165.2716667"])?;
    wtr.write_record(&["Kenai", "AK", "7610", "60.5544444", "-151.2583333"])?;
    wtr.write_record(&["Oakman", "AL", "", "33.7133333", "-87.3886111"])?;

    // A CSV writer maintains an internal buffer, so it's important
    // to flush the buffer when you're done.
    wtr.flush()?;
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

编译并运行这个示例，程序会将数据打印出来：

```
$ cargo build
$ ./target/debug/csvtutor
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
Oakman,AL,,33.7133333,-87.3886111
```

在继续学习之前，有必要仔细研究一下 `write_record` 方法。在这个例子中，它看起来相当简单，但是如果你是 Rust 新手，可能会不太明白它的类型签名：

```rust
pub fn write_record<I, T>(&mut self, record: I) -> csv::Result<()>
    where I: IntoIterator<Item=T>, T: AsRef<[u8]>
{
    // 省略
}
```

为了搞懂这个类型签名，我们可以对其进行逐步分解。

* 1.这个方法有两个参数 `self` 和 `record`。
* 2.`self` 是一个特殊的参数，它对应于 `Writer` 本身。
* 3.`record` 是我们即将要写入的 CSV 记录。它的类型是 `I`，是一个泛型。
* 4.在方法的 `where` 子句中，I 类型由 `IntoIterator<Item=T>` bound 约束着。这意味着 `I` 必须满足 `IntoIterator` trait。如果你阅读 [`IntoIterator` trait](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html) 文档，那么就能看到它描述了构建迭代器的类型。在这个例子中，我们需要一个迭代器，它生成另一个泛型 T，其中 T 是我们写入 CSV 数据的字段类型。
* 5.`T` 也出现在 `where` 字句中了，但它受 `AsRef<[u8]>` bound 约束。`AsRef` trait 是 Rust 中零成本抽象类型描述的一种方式。在本例中，`AsRef<[u8]>` 中的 `[u8]` 就是我们想要从 `T` 中借用的字节切片。CSV writer 将接受这些字节并将其作为单个字段的值写入。`AsRef<[u8]>` 绑定非常有用，因为像 `String`，`&str`，`Vec<u8>` 和 `&[u8]` 等类型都满足它的约束。
* 6.最终，方法返回 `csv::Result<()>`，这是 `Result<(), csv::Error>` 的简写。该类型意味着 `write_record` 要么成功时不返回任何值，要么失败了，返回 `csv::Error`。

现在，可以应用我们已经理解了的 `write_record` 的函数签名了。如果还记得，在我们之前的例子中，我们是这样使用的：

```rust
wtr.write_record(&["field 1", "field 2", "etc"])?;
```

这些类型是如何匹配的呢？好了，这个记录中的字段的类型是 `&'static str`（这是 Rust 中字符串字面量的类型）。因为我们将其放在一个切片文本中，所以我们的参数类型是 `&'static [&'static str]`，或者更简洁地写成没有生命周期注释的形式 `&[&str]`。因为切片满足 `IntoIterator` 绑定，字符串满足 `AsRef<[u8]>` 绑定，这将会是一个合法的调用。

这里是一些调用 `write_record` 的示例：

```rust
// A slice of byte strings.
wtr.write_record(&[b"a", b"b", b"c"]);
// A vector.
wtr.write_record(vec!["a", "b", "c"]);
// A string record.
wtr.write_record(&csv::StringRecord::from(vec!["a", "b", "c"]));
// A byte record.
wtr.write_record(&csv::ByteRecord::from(vec!["a", "b", "c"]));
```

最终，上面的例子可以很容易地修改成写入文件而非 `stdout`：

```rust
extern crate csv;

use std::env;
use std::error::Error;
use std::ffi::OsString;
use std::process;

fn run() -> Result<(), Box<Error>> {
    let file_path = get_first_arg()?;
    let mut wtr = csv::Writer::from_path(file_path)?;

    wtr.write_record(&["City", "State", "Population", "Latitude", "Longitude"])?;
    wtr.write_record(&["Davidsons Landing", "AK", "", "65.2419444", "-165.2716667"])?;
    wtr.write_record(&["Kenai", "AK", "7610", "60.5544444", "-151.2583333"])?;
    wtr.write_record(&["Oakman", "AL", "", "33.7133333", "-87.3886111"])?;

    wtr.flush()?;
    Ok(())
}

/// Returns the first positional argument sent to this process. If there are no
/// positional arguments, then this returns an error.
fn get_first_arg() -> Result<OsString, Box<Error>> {
    match env::args_os().nth(1) {
        None => Err(From::from("expected 1 argument, but got none")),
        Some(file_path) => Ok(file_path),
    }
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

## 写入 tab 分隔符的值
在前面的章节中，我们了解了如何将 CSV 数据输出到标准输出中，如下：

```
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
Oakman,AL,,33.7133333,-87.3886111
```

你可能会想：如果都是这么简单地数据，那使用 CSV writer 还有什么意义？CSV writer 的好处是，它能处理所有类型的数据，而不会牺牲数据的完整性。也就是说，它知道何时引用包含特殊 CSV 字符的字段（如逗号或者换行），或在数据中出现的转义字面量引号。CSV writer 还可以方便地配置使用不同地分隔符或引用策略。

在这一节中，我们将看看如何调整 CSV writer 上的设置。特别地，我们将使用 TSV（“制表符分割值”）来替代 CSV，并且我们要求 CSV writer 引用所有非数字字段。这里有一个例子：

```rust
fn run() -> Result<(), Box<Error>> {
    let mut wtr = csv::WriterBuilder::new()
        .delimiter(b'\t')
        .quote_style(csv::QuoteStyle::NonNumeric)
        .from_writer(io::stdout());

    wtr.write_record(&["City", "State", "Population", "Latitude", "Longitude"])?;
    wtr.write_record(&["Davidsons Landing", "AK", "", "65.2419444", "-165.2716667"])?;
    wtr.write_record(&["Kenai", "AK", "7610", "60.5544444", "-151.2583333"])?;
    wtr.write_record(&["Oakman", "AL", "", "33.7133333", "-87.3886111"])?;

    wtr.flush()?;
    Ok(())
}
```

编译并运行这个例子：

```shell
$ cargo build
$ ./target/debug/csvtutor
"City"  "State" "Population"    "Latitude"      "Longitude"
"Davidsons Landing"     "AK"    ""      65.2419444      -165.2716667
"Kenai" "AK"    7610    60.5544444      -151.2583333
"Oakman"        "AL"    ""      33.7133333      -87.3886111
```

在本例中，我们使用了一个新类型 [QuoteStyle](https://docs.rs/csv/1.0.0/csv/enum.QuoteStyle.html) 。`QuoteStyle` 类型表示你可以使用不同的引用策略。默认情况下，只在必要时才向字段值周围添加引号。这可能适用于大多数例子，但你也可以一直在字段两边添加引号，或不添加引号，或者只在非数字两边加引号。

## 使用 Serde 写入

正如 CSV reader 支持将数据自动反序列化为 Rust 类型数据一样，CSV writer 也支持那样使用 Serde 将 Rust 类型数据序列化为 CSV 记录数据。在本节中，我们就学习怎么使用它。

与读一样，我们先看看如何序列化一个 Rust 元组。

```rust
fn run() -> Result<(), Box<Error>> {
    let mut wtr = csv::Writer::from_writer(io::stdout());

    // 我们仍然需要手动地写入头部
    wtr.write_record(&["City", "State", "Population", "Latitude", "Longitude"])?;

    // 但现在我们可以通过提供的常用的 Rust 值，写入记录。
    //
    // 注意，奇数列的 `None::<u64>` 预发是必须的，因为 `None` 本身没有具体的类型，但 Serde 需要一个具体的类型以便进行序列化。也就是说，`None` 的类型 `Option<T>`，而 `None::<u64>` 的类型是 `Option<u64>`。
    wtr.serialize(("Davidsons Landing", "AK", None::<u64>, 65.2419444, -165.2716667))?;
    wtr.serialize(("Kenai", "AK", Some(7610), 60.5544444, -151.2583333))?;
    wtr.serialize(("Oakman", "AL", None::<u64>, 33.7133333, -87.3886111))?;

    wtr.flush()?;
    Ok(())
}
```

编译并运行这个程序，期望的输出如下：

```shell
$ cargo build
$ ./target/debug/csvtutor
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
Oakman,AL,,33.7133333,-87.3886111
```

在上面的例子中，需要注意的关键点是，使用 `serialize` 而不是 `write_record` 进行写入数据。特别地，`write_record` 在写入仅包含字符串数据的简单记录时使用。另一方面，当数据包含更复杂的值时，如数字、浮点数、可选值时，则使用 `serialize`。当然，你总是可以将复杂的值转为字符串，然后再使用 `write_record` 统一写入，但 Serde 可以为你自动的完成上面那些繁琐的工作。

和读一样，我们也可以将自定义结构序列化为 CSV 记录。这样的好处是，结构体中的字段将被识别为头记录。

要将自定义结构写入 CSV 记录，我们需要再次使用 `serde_derive` crate。正如前面章节的[使用 Serde 读取数据](https://blog.burntsushi.net/csv/#reading-with-serde) 所述，我们需要在我们的 Cargo.toml 中的 `[dependencies]` 区块下加上两个 crate 依赖声明（如果没有就加上）。

```
serde = "1"
serde_derive = "1"
```

我们还需要在代码中加上两行外部库的引入代码 `extern crate` ，如下方所示：

```rust
extern crate csv;
extern crate serde;
 #[macro_use]
extern crate serde_derive;

use std::error::Error;
use std::io;
use std::process;

// 记住结构体可以派生两个 trait：Serialize 和 Deserialize！
 #[derive(Debug, Serialize)]
 #[serde(rename_all = "PascalCase")]
struct Record<'a> {
    city: &'a str,
    state: &'a str,
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}

fn run() -> Result<(), Box<Error>> {
    let mut wtr = csv::Writer::from_writer(io::stdout());

    wtr.serialize(Record {
        city: "Davidsons Landing",
        state: "AK",
        population: None,
        latitude: 65.2419444,
        longitude: -165.2716667,
    })?;
    wtr.serialize(Record {
        city: "Kenai",
        state: "AK",
        population: Some(7610),
        latitude: 60.5544444,
        longitude: -151.2583333,
    })?;
    wtr.serialize(Record {
        city: "Oakman",
        state: "AL",
        population: None,
        latitude: 33.7133333,
        longitude: -87.3886111,
    })?;

    wtr.flush()?;
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

编译并运行这个示例，虽然我们没有显式地写入头部，但输出和上次是一样的。

```shell
$ cargo build
$ ./target/debug/csvtutor
City,State,Population,Latitude,Longitude
Davidsons Landing,AK,,65.2419444,-165.2716667
Kenai,AK,7610,60.5544444,-151.2583333
Oakman,AL,,33.7133333,-87.3886111
```

在这个例子中，可以看到，`serialize` 方法上被标记上了一个结构体字段名。这样做的话，`serialize` 将自动写入一个头部（只要其他记录尚未写入），该记录的结构体的字段是按照他们定义的顺序组成。请注意，可以通过 [`WriterBuilder::has_headers`](https://docs.rs/csv/1.0.0/csv/struct.WriterBuilder.html#method.has_headers) 方法将此行为禁用。

同样值得指出的是，在 `Record` 结构体中使用了一个生命周期参数：

```rust
struct Record<'a> {
    city: &'a str,
    state: &'a str,
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}
```

`'a` 生命周期参数对应于 `city` 和 `state` 字符串切片的生命周期。这表示 `Record` 结构体包含了 _借用_ 的数据。我们本可以在不借用任何数据的情况下编写结构体，这时也就不需要生命周期参数了：

```rust
struct Record {
    city: String,
    state: String,
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}
```

然而，由于我们使用 `String` 类型替换 `&str` 类型，我们现在被迫为我们所写的每条记录中的 `city` 和 `state` 分配一个新的 `String` 值。这样做本身没有问题，但会有点性能浪费。

关于序列化的更多示例和详细信息，可以参考 [`Writer::serialize`](https://docs.rs/csv/1.0.0/csv/struct.Writer.html#method.serialize) 方法。


## 管道操作
在这一节中，我们将介绍几个示例，这些示例把 CSV 数据作为输入，并对其进行转换或过滤等操作，再将结果输出。这是一个能有效读写 CSV 数据的完整程序。Rust 很适合做这个，因为你可以利用高级地 CSV 库的优势来获得出色的性能。

### 搜索过滤
我们把看到的 CSV 管道操作示例视为一个简单的过滤器。它把 stdin 中的一些 CSV 数据和单个字符查询作为位置参数，并且它将返回与查询相匹配的字段对应的 CSV 数据记录作为输出。

```rust
extern crate csv;

use std::env;
use std::error::Error;
use std::io;
use std::process;

fn run() -> Result<(), Box<Error>> {
    // 从位置参数获取查询
    // 如果没有参数，则返回错误
    let query = match env::args().nth(1) {
        None => return Err(From::from("expected 1 argument, but got none")),
        Some(query) => query,
    };

   // 构建 CSV reader 和 writer，分别从 stdin 进行 CSV 读取和写入到 stdout。
    let mut rdr = csv::Reader::from_reader(io::stdin());
    let mut wtr = csv::Writer::from_writer(io::stdout());

   // 读取记录之前，我们应该写入头部记录
    wtr.write_record(rdr.headers()?)?;

    // 迭代 `rdr` 中的所有记录，只写入匹配的记录
    // 从 `query` 到 `wtr`.
    for result in rdr.records() {
        let record = result?;
        if record.iter().any(|field| field == &query) {
            wtr.write_record(&record)?;
        }
    }

    // CSV writer 使用内部的 buffer，所以当完成的时候，将其刷新。
    wtr.flush()?;
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

如果编译这段程序，并用它查询 `uspop.csv` 中 MA 相关的数据，可以看到结果中仅有一条符合：

```shell
$ cargo build
$ ./csvtutor MA < uspop.csv
City,State,Population,Latitude,Longitude
Reading,MA,23441,42.5255556,-71.0958333
```

这个示例实际上并没有引入新的东西。它只是结合了前面几节中介绍到的 CSV reader 和 writer 知识点。

让我们在这个例子中添加一个分支。在实际使用中，你可能会遇到没有正确编码的混乱数据。你可能会遇到使用 [Latin-1](https://e讲的例子都是基于 UTF-8 编码的数据。由于我们处理的所有数据都是 ASCII（它是 Latin-1 和 UTF-8 的子集），所以没有出现问题。但下面我们试试一个稍微修改过的 uspop.csv 文件，它包含一个无效的 Latin-1 编码的非法 UTF-8 字符。你可以下载它：

```shell
$ curl -LO 'https://raw.githubusercontent.com/BurntSushi/rust-csv/master/examples/data/uspop-latin1.csv'
```

尽管我提出了这个问题，但还是让我们看看，当我们在新数据上运行我们之前的例子会发生什么：

```shell
$ ./csvtutor MA < uspop-latin1.csv
City,State,Population,Latitude,Longitude
CSV parse error: record 3 (line 4, field: 0, byte: 125): invalid utf-8: invalid UTF-8 in field 0 near byte index 0
```

错误消息表示有异常发生。我们看一下第 4 行是如何处理的：

```shell
$ head -n4 uspop-latin1.csv | tail -n1
Õakman,AL,,33.7133333,-87.3886111
```

在上面的例子中，第一个字符是 Latin-1 字符 Õ，它被编码为字节 0xD5，这是一个无效的 UTF-8。现在 CSV 解析器被阻碍在异常数据这边，我们该怎么办？有两个办法。第一种是修复 CSV 数据，使其变为有效的 UTF-8 数据。无论如何，这是一个不错的方法，比如像 `iconv` 这种库可以帮助完成数据编码的转换任务。但是，如果你不能或者不想这样做，你可以换一种方法，以一种与编码无关的方式读取 CSV 数据（只要 ASCII 是合法的字符子集）。方法的关键就是使用字节记录，而非 _字符串记录_。 

到目前为止，我们实际上还没有深入地讨论过代码中的记录类型，但是现在是时候介绍它们了。有两种方式，[StringRecord](https://docs.rs/csv/1.0.0/csv/struct.StringRecord.html) 和 [ByteRecord](https://docs.rs/csv/1.0.0/csv/struct.ByteRecord.html)。这两者中的任意一个都可以表示一条记录，一条记录由若干个字段序列组成。`StringRecord` 和 `ByteRecord` 的唯一区别是 `StringRecord` 必须是有效的 UTF-8 数据，而 `ByteRecord` 则包含任意的字节。需要明确的是，这两种类型在内存结构上的表示是一样的。

有了这些知识，我们现在就可以开始理解为什么在运行上面关于不合法的 UTF-8 数据的示例时，我们遇到报错了。也就是说，当我们调用 `records` 时，我们会得到一个 `StringRecord` 的迭代器。由于 `StringRecord` 需要数据是有效的 UTF-8，因此当我们使用不合法的 UTF-8 数据去构建 `StringRecord` 时，则会导致我们看到那些错误。

要使我们的示例代码能运行，我们需要做的就是从 `StringRecord` 转换到 `ByteRecord`。这意味着使用 `byte_records` 来创建迭代器，而非 `records`，类似的，头部数据也可能是非法 UTF-8，因此也要使用 `byte_headers` 替代 `headers`。变化如下：

```rust
fn run() -> Result<(), Box<Error>> {
    let query = match env::args().nth(1) {
        None => return Err(From::from("expected 1 argument, but got none")),
        Some(query) => query,
    };

    let mut rdr = csv::Reader::from_reader(io::stdin());
    let mut wtr = csv::Writer::from_writer(io::stdout());

    wtr.write_record(rdr.byte_headers()?)?;

    for result in rdr.byte_records() {
        let record = result?;
        // `query` 是 `String`，field 现在是 `&[u8]`，所以我们在比较之前，需要将`query` 转换为 `&[u8]`。
        if record.iter().any(|field| field == query.as_bytes()) {
            wtr.write_record(&record)?;
        }
    }

    wtr.flush()?;
    Ok(())
}
```

编译并运行，现在迭代的结果和我们的首个示例一样，但这次是基于非法 UTF-8 数据运行的。

```shell
$ cargo build
$ ./csvtutor MA < uspop-latin1.csv
City,State,Population,Latitude,Longitude
Reading,MA,23441,42.5255556,-71.0958333
```

### 对 population 计数进行过滤

在本节中，我们将展示另一个示例程序，它可以读写 CSV 数据，除此之外，不再是处理任意的记录，而是使用 Serde 对具有特殊标记的记录进行序列化和反序列化。

对于这个程序，我们希望能够根据 population 统计的数量来过滤掉一些记录。具体来说，我们像看看哪些记录符合特定的人口阈值。除了使用一个简单的不等式外，我们还需考虑哪些记录缺少人口统计。这时，像 `Option<T>` 这样的类型就派上用场了，因为编译器会“强迫”我们考虑人口计数缺失的异常情况。

在这个示例中，因为我们使用 Serde，因此如果你没有声明依赖，不要忘记增加 Serde 依赖到 `Cargo.toml` 文件的 `[dependencies]` 区块下：

```toml
serde = "1"
serde_derive = "1"
```

现在，代码如下所示：

```rust
extern crate csv;
extern crate serde;
 #[macro_use]
extern crate serde_derive;

use std::env;
use std::error::Error;
use std::io;
use std::process;

// Unlike previous examples, we derive both Deserialize and Serialize. This
// means we'll be able to automatically deserialize and serialize this type.
 #[derive(Debug, Deserialize, Serialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    city: String,
    state: String,
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}

fn run() -> Result<(), Box<Error>> {
    // Get the query from the positional arguments.
    // If one doesn't exist or isn't an integer, return an error.
    let minimum_pop: u64 = match env::args().nth(1) {
        None => return Err(From::from("expected 1 argument, but got none")),
        Some(arg) => arg.parse()?,
    };

    // Build CSV readers and writers to stdin and stdout, respectively.
    // Note that we don't need to write headers explicitly. Since we're
    // serializing a custom struct, that's done for us automatically.
    let mut rdr = csv::Reader::from_reader(io::stdin());
    let mut wtr = csv::Writer::from_writer(io::stdout());

    // Iterate over all the records in `rdr`, and write only records containing
    // a population that is greater than or equal to `minimum_pop`.
    for result in rdr.deserialize() {
        // Remember that when deserializing, we must use a type hint to
        // indicate which type we want to deserialize our record into.
        let record: Record = result?;

        // `map_or` is a combinator on `Option`. It take two parameters:
        // a value to use when the `Option` is `None` (i.e., the record has
        // no population count) and a closure that returns another value of
        // the same type when the `Option` is `Some`. In this case, we test it
        // against our minimum population count that we got from the command
        // line.
        if record.population.map_or(false, |pop| pop >= minimum_pop) {
            wtr.serialize(record)?;
        }
    }

    // CSV writers use an internal buffer, so we should always flush when done.
    wtr.flush()?;
    Ok(())
}

fn main() {
    if let Err(err) = run() {
        println!("{}", err);
        process::exit(1);
    }
}
```

如果我们以最小阈值 `100000` 参数运行这个程序，我们可以看到 3 条匹配的结果。注意，我们可从未显式地写过头部声明，但头部却能够被准确地显示出来。

```shell
$ cargo build
$ ./target/debug/csvtutor 100000 < uspop.csv
City,State,Population,Latitude,Longitude
Fontana,CA,169160,34.0922222,-117.4341667
Bridgeport,CT,139090,41.1669444,-73.2052778
Indianapolis,IN,773283,39.7683333,-86.1580556
```


## 性能（Performance）
在本节中，我们将讨论如何最大限度地利用 CSV reader。实际上，到目前为止，我们所看到的大多数 api 在设计时都考虑到了高度的易用性，而这通常需要付出一些代价。大多数情况下，这些代价就包含一些不必要的分配。因此，本节的大部分内容将展示如何使用尽可能少的分配来进行 CSV 解析。

有两个必须涉及且比较关键的先决条件。

首先，当你关心性能时，你应该使用 `cargo build --release` 而不是 `cargo build` 来编译代码。`--release` 标志表示编译器花一些时间优化你的代码。当使用 `--release` 标志编译时，你会发现编译后的程序在 `target/release/csvtutor` 而不是 `target/debug/csvtutor` 。在本教程中，我们使用 `cargo build` 构建，因为我们的数据集很小，我们不关注速度。crate 构建时使用 `--release` 的缺点是，花费更长的编译时间。

其次，我们前面使用的数据集只有 100 条记录。我们必须非常努力地，即使在没有 `--release` 标志的情况下编译，使程序在 100 条记录上运行地慢一些。因此，为了真正见证性能差异，我们需要更大的数据集。为了获得这样的数据集，我们将使用 uspop.csv 的原始源。**警告:下载 41MB 解压后将有 145MB**

```shell
$ curl -LO https://burntsushi.net/stuff/worldcitiespop.csv.gz
$ gunzip worldcitiespop.csv.gz
$ wc worldcitiespop.csv
  3173959   5681543 151492068 worldcitiespop.csv
$ md5sum worldcitiespop.csv
6198bd180b6d6586626ecbf044c1cca5  worldcitiespop.csvshell
```

最后，需要指出的是，本节并不是要提供一套严格的基准。我们将不会很严格地分析，而更多地依靠钟表时间和直觉。

## 摊销分配（Amortizing allocations）

为了衡量性能，我们必须关注我们所衡量的指标是什么。在改进代码时，我们还必须注意变量和不变量。出于这个原因，我们将重点测量需要多长时间来统计与马萨诸塞州城市人口统计相对应的记录数量。这表示需要我们访问每条记录的工作量非常小，因此这是衡量执行 CSV 解析所需时间的一种不错的方法。

在开始我们的第一个优化之前，让我们从一个基础开始，通过调整之前的基础示例来计算 `worldcitiespop.csv` 中的记录数量：

```rust
extern crate csv;

use std::error::Error;
use std::io;
use std::process;

fn run() -> Result<u64, Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());

    let mut count = 0;
    for result in rdr.records() {
        let record = result?;
        if &record[0] == "us" && &record[3] == "MA" {
            count += 1;
        }
    }
    Ok(count)
}

fn main() {
    match run() {
        Ok(count) => {
            println!("{}", count);
        }
        Err(err) => {
            println!("{}", err);
            process::exit(1);
        }
    }
}
```

现在，我们编译并运行它，看看我们使用了多少时间。不要忘记使用 `--release` 标志进行编译。（嘿嘿，尝试编译不带 `--release` 标志，看看运行程序需要多长时间！）

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m0.645s
user    0m0.627s
sys     0m0.017s
```

好了，我们要怎么做才能加快速度呢？本节承诺通过摊销分配来加快速度，但我们可以先做一些更简单的事情：迭代 `ByteRecords` 而非 `StringRecords`。如果您还记得上一节，`StringRecord` 保证是有效的 UTF-8，因此必须校验它的内容是否是 UTF-8。（如果验证失败，那么CSV读取器将返回一个错误。）如果我们从我们的程序中移除校验代码，那么我们可以实现一个很好的性能提升，如下面的例子所示:

```rust
fn run() -> Result<u64, Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());

    let mut count = 0;
    for result in rdr.byte_records() {
        let record = result?;
        if &record[0] == b"us" && &record[3] == b"MA" {
            count += 1;
        }
    }
    Ok(count)
}
```

编译并运行：

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m0.429s
user    0m0.403s
sys     0m0.023s
```

我们的程序现在大约快了 30%，这都是因为我们删除了 UTF-8 验证。但是，删除 UTF-8 验证真的可以吗？我们失去了什么？在这种情况下，删除 UTF-8 校验并使用 `ByteRecord` 是完全可以接受的，因为我们对记录所做的只是将其两个字段与原始字节进行比较：

```rust
if &record[0] == b"us" && &record[3] == b"MA" {
    count += 1;
}
```

特别是，记录是否是有效的 UTF-8 并不重要，因为我们只是检查它和特定原始字节是否相等。

通过 `StringRecord` 进行 UTF-8 校验很有用，因为它提供了对 `&str` 类型字段的访问，而 `ByteRecord` 提供了 `&[u8]` 类型字段。`&str` 是 Rust 中借用的字符串类型，它提供了对字符串便捷访问的 api，比如子字符串搜索。 String 也经常用于其他领域，因此它很有用。因此，坚持使用 `StringRecord` 是一个很好的默认方式，但是如果您需要额外的速度并且可以处理任意字节，那么切换到 `ByteRecord` 可能会更好。

接下来，让我们通过摊销分配（amortizing allocation）来提高速度。摊销分配是一种技术，它只需一次(或很少)分配，然后复用它，而不是创建额外的分配。在前面的例子中，我们使用了由 CSV reader 上的 records 和 byte_records 方法创建的迭代器。这些迭代器为它迭代的每一项分配新的空间，一条记录对应于一次分配。之所以这样做，是因为迭代过程中不能对迭代器中的项进行借用，此外，创建新的分配往往更方便。

如果我们愿意放弃使用迭代器，那么可以通过创建单个 ByteRecord 并要求 CSV reader 读入它来摊销分配。我们通过使用 [`Reader::read_byte_record`](https://docs.rs/csv/1.0.0/csv/struct.Reader.html#method.read_byte_record) 方法来实现这一点。

```rust
fn run() -> Result<u64, Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    let mut record = csv::ByteRecord::new();

    let mut count = 0;
    while rdr.read_byte_record(&mut record)? {
        if &record[0] == b"us" && &record[3] == b"MA" {
            count += 1;
        }
    }
    Ok(count)
}
```

编译并运行：

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m0.308s
user    0m0.283s
sys     0m0.023s
```

哦吼！这比前一个例子又提升了 30%，比第一个例子提升了 50%。

让我们通过查看 read_byte_record 方法签名来分析这段代码：

```rust
fn read_byte_record(&mut self, record: &mut ByteRecord) -> csv::Result<bool>;
```

该方法接受一个 CSV reader(self 参数)和一个可变的 ByteRecord 借用作为入参，并返回 `csv::Result<bool>`。（当且仅当读取记录，返回值为 true 时 `csv::Result<bool>` 等价于 `Result<bool, csv::Error>`）。当它为 false 时，这意味着 reader 已经耗尽了输入。该方法通过将下一条记录的内容复制到提供的 ByteRecord 中来处理。由于使用同一个 ByteRecord 读取每条记录，因此它已经为数据分配了空间。当调用 read_byte_record 时，它将用新记录覆盖原来存在的空间，这意味着它可以复用已分配的空间。因此，我们平摊了分配。

你可以考虑使用 StringRecord 而不是 ByteRecord，因此 [`Reader::read_record`](https://docs.rs/csv/1.0.0/csv/struct.Reader.html#method.read_record) 而不是 read_byte_record。这将使您以校验 UTF-8 的代价轻松访问 Rust 字符串，但不需要为每条记录分配一个新的 StringRecord。

## Serde 和零拷贝
在这一节中，我们将简要研究如何使用 Serde 以及如何提高它的速度。我们要做的关键优化是，你猜对了，是摊销分配。

和上一节一样，让我们从一个基于上一节中使用 Serde 的简单基础例子开始:

```rust
extern crate csv;
extern crate serde;
 #[macro_use]
extern crate serde_derive;

use std::error::Error;
use std::io;
use std::process;

 #[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record {
    country: String,
    city: String,
    accent_city: String,
    region: String,
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}

fn run() -> Result<u64, Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());

    let mut count = 0;
    for result in rdr.deserialize() {
        let record: Record = result?;
        if record.country == "us" && record.region == "MA" {
            count += 1;
        }
    }
    Ok(count)
}

fn main() {
    match run() {
        Ok(count) => {
            println!("{}", count);
        }
        Err(err) => {
            println!("{}", err);
            process::exit(1);
        }
    }
}
```

编译并运行：

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m1.381s
user    0m1.367s
sys     0m0.013s
```

你可能会注意到的第一件事是，这比我们在前一节中的程序要慢得多。这是因为反序列化每条记录都有一定的开销。特别是，一些字段需要被解析为整数或浮点数，这些都有开销。然而，还有希望，因为我们可以优化!

我们加快程序的第一个尝试将是摊销分配。使用 Serde 完成这个操作比以前要复杂一些，因为我们需要更改我们的 Record 类型并使用手动反序列化 API。让我们看看它是什么样的：

```rust
#[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record<'a> {
    country: &'a str,
    city: &'a str,
    accent_city: &'a str,
    region: &'a str,
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}

fn run() -> Result<u64, Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    let mut raw_record = csv::StringRecord::new();
    let headers = rdr.headers()?.clone();

    let mut count = 0;
    while rdr.read_record(&mut raw_record)? {
        let record: Record = raw_record.deserialize(Some(&headers))?;
        if record.country == "us" && record.region == "MA" {
            count += 1;
        }
    }
    Ok(count)
}
```

编译并运行：

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m1.055s
user    0m1.040s
sys     0m0.013s
```

这相当于性能提高了大约 24%。为了实现这一点，我们必须做两个重大的改变。

第一个是让我们的 Record 类型包含 `&str` 字段，而不是 String 字段。如果你还记得上一节，`&str` 是一个字符串借用，而 String 是一个字符串。借用的字符串指向一个已经存在的分配，而 String 则意味着新的内存分配。在本例中，我们的 `&str` 借用了 CSV 记录本身。

我们必须做的第二个更改是停止使用 [`Reader::deserialize`](https://docs.rs/csv/1.0.0/csv/struct.Reader.html#method.deserialize) 迭代器，而是显式地将我们的记录反序列化为 StringRecord，然后使用[`StringRecord::deserialize`](https://docs.rs/csv/1.0.0/csv/struct.StringRecord.html#method.deserialize) 方法来反序列化单个记录。

第二个更改有点棘手，因为为了让它工作，我们的 Record 类型需要借用 StringRecord 内部的数据。这意味着我们的 Record 生命周期不能超过创建它的 StringRecord 的生命周期。由于我们在每次迭代中覆盖相同的 StringRecord (为了摊销分配)，这意味着我们的 Record 值必须在下一次循环迭代之前被覆盖。事实上，编译器会强制执行！

我们还可以进行一项优化：删除 UTF-8 验证。通常，这意味着使用 `&[u8]` 而非 `&str`，并使用 ByteRecord 而不是 StringRecord：

```rust
#[derive(Debug, Deserialize)]
 #[serde(rename_all = "PascalCase")]
struct Record<'a> {
    country: &'a [u8],
    city: &'a [u8],
    accent_city: &'a [u8],
    region: &'a [u8],
    population: Option<u64>,
    latitude: f64,
    longitude: f64,
}

fn run() -> Result<u64, Box<Error>> {
    let mut rdr = csv::Reader::from_reader(io::stdin());
    let mut raw_record = csv::ByteRecord::new();
    let headers = rdr.byte_headers()?.clone();

    let mut count = 0;
    while rdr.read_byte_record(&mut raw_record)? {
        let record: Record = raw_record.deserialize(Some(&headers))?;
        if record.country == b"us" && record.region == b"MA" {
            count += 1;
        }
    }
    Ok(count)
}
```

编译并执行：

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m0.873s
user    0m0.850s
sys     0m0.023s
```

这相当于比前一个示例提升了 17%，比第一个示例增加了 37%。

总之，Serde 解析仍然非常快，但通常不是解析 CSV 的最快方法，因为它需要执行很多其它逻辑。

## 不使用标准库的方式进行 CSV 解析
在本节中，我们将探索一个特殊的用例：在不使用标准库的情况下解析 CSV。虽然 csv 板条箱本身需要标准库，但底层解析器实际上是 [`csv-core`](https://docs.rs/csv-core) crate 的一部分，它不依赖于标准库。不依赖标准库的缺点是 CSV 解析变得非常不方便。

csv-core 板条箱（crate）的结构与 csv 板条箱类似。有 [`Reader`](https://docs.rs/csv-core/0.1.0/csv_core/struct.Reader.html) 和 [`Writer`](https://docs.rs/csv-core/0.1.0/csv_core/struct.Writer.html)，以及相应的构建器 [`ReaderBuilder`](https://docs.rs/csv-core/0.1.0/csv_core/struct.ReaderBuilder.html) 和 [`WriterBuilder`](https://docs.rs/csv-core/0.1.0/csv_core/struct.WriterBuilder.html)。csv-core 板条箱没有记录类型或迭代器。相反，CSV 数据可以一次读取一个字段，也可以一次读取一条记录。在本节中，我们将专注于一次读取一个字段，因为这样更简单，但一次读取一条记录通常更快，因为每次函数调用都要执行一些额外逻辑。

为了与这一节的介绍保持一致，让我们只使用 csv-core 编写一个程序，它计算马萨诸塞州的记录数量。

(请注意，不幸的是，我们在本例中使用了标准库，尽管 csv-core 在技术上并不需要它。我们这样做是为了方便访问I/O，如果没有标准库，这会比较困难。)

```rust
extern crate csv_core;

use std::io::{self, Read};
use std::process;

use csv_core::{Reader, ReadFieldResult};

fn run(mut data: &[u8]) -> Option<u64> {
    let mut rdr = Reader::new();

    // 计算 Massachusetts 州的记录数
    let mut count = 0;
    // 当前字段索引。在每条记录开始时重置为 0。
    let mut fieldidx = 0;
    // True when the current record is in the United States.
    // 当前记录是在美国。
    let mut inus = false;
    // Buffer for field data. Must be big enough to hold the largest field.
    // 字段数据的缓冲区。必须足够大才能容纳最大的字段。
    let mut field = [0; 1024];
    loop {
        // 尝试递增地去读取下一条 csv 字段
        let (result, nread, nwrite) = rdr.read_field(data, &mut field);
        // nread 是从输入中读取的字节数。我们再也不需要将这些字节传递给 read_field。
        data = &data[nread..];
        // nwrite 是写入输出缓冲区 `field` 的字节数。此后，缓冲区内容就是未定义的了。
        let field = &field[..nwrite];

        match result {
            // 无需处理这个 case，因为预先读取了所有的数据。如果我们增量地读取数据，这就代表要读取更多数据。
            ReadFieldResult::InputEmpty => {}
            // 这种情况中，意味着一个字段超过 1024 字节了。可以简单处理，返回读取失败。
            ReadFieldResult::OutputFull => {
                return None;
            }
            // 成功读取字段。如果该字段是记录中的最后一个字段，则 `record_end` 为 true。
            ReadFieldResult::Field { record_end } => {
                if fieldidx == 0 && field == b"us" {
                    inus = true;
                } else if inus && fieldidx == 3 && field == b"MA" {
                    count += 1;
                }
                if record_end {
                    fieldidx = 0;
                    inus = false;
                } else {
                    fieldidx += 1;
                }
            }
            // CSV reader 成功读取完所有的输入时。
            ReadFieldResult::End => {
                break;
            }
        }
    }
    Some(count)
}

fn main() {
    // 预先读入 stdin 的所有内容
    let mut data = vec![];
    if let Err(err) = io::stdin().read_to_end(&mut data) {
        println!("{}", err);
        process::exit(1);
    }
    match run(&data) {
        None => {
            println!("error: could not count records, buffer too small");
            process::exit(1);
        }
        Some(count) => {
            println!("{}", count);
        }
    }
}
```

编译并运行：

```shell
$ cargo build --release
$ time ./target/release/csvtutor < worldcitiespop.csv
2176

real    0m0.572s
user    0m0.513s
sys     0m0.057s
```

这不如我们之前用 csv 板条箱读入 StringRecord 或 ByteRecord 的例子性能高。这主要是因为本例每次只读取一个字段，这比每次读取一条记录带来的开销更大。要解决这个问题，你需要使用 `Reader::read_record` 方法，它是在 `csv_core::Reader` 中定义的。

这里需要注意的另一件事是，这个示例比其他示例花了更多精力。这是因为我们需要做更多的记录工作来跟踪我们正在读取的字段，以及我们已经向 reader 提供了多少数据。使用 `csv_core` 板条箱主要有两个原因:

* 在一个标准库不可用的环境中。
* 你想构建自己的类 csv 库，也可以基于 csv-core 之上构建。

## 展望
恭喜你走到最后!一个人能在 “CSV 解析”这样基本的东西上写这么多字，这似乎令人难以置信。我希望这个指南不仅能让 Rust 的初学者使用，也能让没有经验的程序员使用。我希望大量的例子将帮助你朝着正确的方向前进。

话虽如此，这里还有一些你可能想看看的资料:

* [csv 板条箱的 API 文档](https://docs.rs/csv/1.0.0/csv/index.html)记录了该库的所有方面，而且本身还夹杂着更多的示例。
* [csv-index crate](https://docs.rs/csv-index) 提供了数据结构，可以索引易于写入磁盘的 CSV 数据。（这个库仍在开发中。）
* [xsv 命令行工具](https://github.com/BurntSushi/xsv)是一款高性能的 CSV 瑞士军刀。它可以对任意 CSV 数据进行切片、选择、搜索、排序、连接、索引、格式化和统计计算。可以试一试！

_完_