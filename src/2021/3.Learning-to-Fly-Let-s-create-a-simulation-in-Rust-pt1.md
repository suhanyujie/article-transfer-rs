>* Learning to Fly: Let's create a simulation in Rust! (pt 1) 译文（学习飞行：用 Rust 创建一个模拟器 part1）
>* 原文链接：https://pwy.io/en/posts/learning-to-fly-pt1/
>* 原文作者：[Patryk27](https://github.com/Patryk27)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust, simulation,  genetic-algorithm, neural-network, rust, webassembly

系列文章：
* [Learning to Fly: Let's create a simulation in Rust! (pt 1)](https://pwy.io/en/posts/learning-to-fly-pt1/)
* [Learning to Fly: Let's create a simulation in Rust! (pt 2)](https://pwy.io/en/posts/learning-to-fly-pt2/)

In this series we’ll create a simulation of **evolution** using **neural network & genetic algorithm**.
>在这个系列中，我们将使用 **神经网络和遗传算法** 创建一个 **进化** 模拟器。

I’m going to introduce you to how a basic neural network and genetic algorithm works, then we’ll implement both in Rust and compile our application to **WebAssembly** to ultimately end up with:
>我会向你介绍一个基础的神经网络和遗传算法是如何工作的，然后使用 Rust 实现它们，并将应用编译到 **WebAssembly**，最后实现如下所示：

![Figure 1. https://pwy.io/en/projects/shorelark/](https://pwy.io/resources/learning-to-fly-pt1/intro-outcome.png)

>* This series is intended for **Rust beginners** - I’m assuming you know a thing or two about Rust and I’ll introduce you to rest of the concepts (such as neural networks) as we go.
>* 这个系列的文章主要面向 **Rust 初学者** - 我假定你已初步了解 Rust，之后我会向你介绍其他概念（如神经网络）。
>* No fancy mathematics or IT background is required.
>* 不需要熟练掌握花哨的数学和雄厚的 IT 背景。

This series will be divided into a few posts, roughly:
>这个系列将会分为若干篇文章，大概如下：

* 1.Introduction to the domain (what are we going to simulate, how does a neural network & genetic algorithm work),
* 1.领域说明（我们模拟什么，神经网络和遗传算法如何工作），
* 2.Implementing a neural network,
* 2.实现一个神经网络
* 3.Implementing a genetic algorithm,
* 3.实现一个遗传算法
* 4.Implementing eyes, brain, and the simulation itself.
* 4.实现眼睛、大脑和模拟器本身。

Due diligence: I’ll do my best to explain all the concepts, but if at any point you feel lost, feel free to take a look at this article’s last section - it contains links to external (mostly popular science) sources that might prove to be helpful in understanding the domain.
>尽职调查：我会尽我所能解释所有的概念，但如果你在任意时候有疑惑，可以看这篇文章的最后一节 —— 它包含了外部资源（主流科学）的一些链接，可能会帮助你理解对应的领域知识。

Curious? Hop on the bus, Gus, and onto the first chapter: [Design](https://pwy.io/en/posts/learning-to-fly-pt1/#design).
>好奇吗？快上车吧，Gus，我们进入第一章：[设计](https://pwy.io/en/posts/learning-to-fly-pt1/#design).

## [Design](https://pwy.io/en/posts/learning-to-fly-pt1/#design)

Let’s start by clearly defining our objective: what are we going to simulate, actually?
>我们先明确我们的目标：我们到底要模拟什么？

The overall idea is that we have a two-dimensional board representing a **world**:
>总体设想是我们有一个二维的**世界**：

![](https://pwy.io/resources/learning-to-fly-pt1/design-1.png)

This world consists of **birds** (hence the project’s original code name - _Shorelark_):
>这个世界由**鸟**构成（因此项目的仓库名用 —— _Shorelark_）：

![](https://pwy.io/resources/learning-to-fly-pt1/design-2.png)

... and **foods** (of an abstract kind, rich in protein & fiber):
>... 以及**食物**（抽象类实体，富含蛋白质和纤维）：

![](https://pwy.io/resources/learning-to-fly-pt1/design-3.png)

Each bird has their own **vision**, allowing them to locate the food:
>每只鸟有它们的**视界**，它们可以自己寻找食物：

![](https://pwy.io/resources/learning-to-fly-pt1/design-4.png)

... and a **brain** that controls bird’s body (i.e. speed and rotation).
>... 并且由**大脑**控制鸟的身体（比如速度和旋转）。

Our magic touch will lay in the fact that instead of hard-coding our birds to some specific behavior (e.g. "go to the nearest food in your eyesight"), we’ll take a more intriguing route:
>我们的神奇之处在于，我们没有将鸟类硬编码为具有特定的行为的实体（例如：去定位你视线范围内最近的食物），我们会走一条更有趣的路线：

We’ll make our birds able to **learn** and **evolve**.
>我们要确保鸟实体能够**学习**和**进化**。

## 大脑

If you squint your eyes hard enough, you’ll see that a brain is nothing but a **function** of some inputs to some outputs, e.g.:
>如果你把眼睛眯得足够紧，你会发现大脑只不过是一个具备输入和输出的**函数**，例如：

![](https://pwy.io/resources/learning-to-fly-pt1/brain-1.png)

>You’re a precious mathematical formula, remember that.
>你是一个珍贵的数学公式，记住这点：

Since our birds will have only one sensory input, their brains can be then approximated as:
>由于鸟类只有一种感觉输入，它们的大脑可以视为：

![](https://pwy.io/resources/learning-to-fly-pt1/brain-2.png)

Mathematically, we can represent this function’s input (i.e. biological eye) as a list of numbers, with each number (i.e. biological _photoreceptor_) describing _how close_ the nearest object (i.e. food) is:
>数学角度看，我们可以将这个函数的输入（如生物的眼睛）表示为一组数，每个数字（生物感光器）描述周围的物体（如食物）与其之间的距离：

![](https://pwy.io/resources/learning-to-fly-pt1/brain-3.png)

_(0.0 - 视线范围内没有物体, 1.0 - 在我们的右侧有一个对象.)_

>Our birds won’t see color, but that’s just for simplicity - you could use e.g. [raytracing](https://raytracing.github.io/books/RayTracingInOneWeekend.html) to make the eyes more realistic.
>我们的鸟不能识别颜色，但这是为了简化 —— 你可以使用 [raytracing](https://raytracing.github.io/books/RayTracingInOneWeekend.html) 之类的库使眼睛的实现更接近真实。

As for the output, we’ll make our function return a tuple of `(Δspeed, Δrotation)`.
>至于输出，我们使函数返回一个元组 `(Δspeed, Δrotation)`。

For instance, a brain telling us `(0.1, 45)` will mean "body, please increase our speed by `0.1` units and rotate us `45` degrees clockwise", while `(0.0, 0)` will mean "body, please keep our course steady".
>例如，大脑告诉我们 `(0.1, 45)` 意味着“身体，请给我们的速度增加 `0.1` 个单位，并顺时针旋转 45 度”，而如果大脑接收到的是 `(0.0, 0)`，则意味着“身体，请保持我们的航向一直向前”。 

>* It’s important that we use relative values (so `delta speed` and `delta rotation`), as our brain won’t be aware of its own location & rotation respective to the world - passing that information would increase our brain’s complexity for no real benefit.
>* 重要的是我们要使用相对值（即 `delta speed` 和 `delta rotation`），因为我们的大脑不会意识到自己的位置和旋转的角度 —— 传递这些信息只会增加大脑的复杂度而没有其他益处。

Finally, let’s address the elephant in the room: so a brain is basically `f(eyes)`, right? But how do we find out what actually follows the equals sign?
>最终，让我们来谈谈[“房间里的大象”](https://www.jianshu.com/p/981ad4a6fdc6)：所以大脑基本上可以表示为 `f(eyes)`，对吧？但我们如何知道下方的等式中等号后到底是什么？

```
f(eyes) = what?
```

## 神经网络：简介

As a fellow human, you are might be aware that brains are made of neurons connected via synapses:
>作为一个人类同胞，你可能知道大脑由神经元通过突触连接而成：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-1.png)

_Figure 2. 我没有按比例绘制神经元_

Synapses carry electric and chemical signals between neurons, while neurons "decide" whether given signal should be propagated further or stopped; eventually this allows for people to recognize letters, eat brussels sprouts, and write mean comments on Twitter.
>突触在神经元之间传递电信号和化学信号，而神经元“决定”已知的信号是应该继续传递还是停止传递；最终，人们可以识别字母，吃球芽甘蓝，以及在 Twitter 发表评论。

Due to their [inherent complexity](https://en.wikipedia.org/wiki/Biological_neuron_model), biological neural networks are not among the easiest to simulate (one could argue that neurons are thus not [Web Scale](https://www.youtube.com/watch?v=b2F-DItXtZs)), which made some smart people invent a class of mathematical structures called artificial neural networks, which allow to approximate - with a pinch of salt - brain-like behavior using math.
>由于其固有的[复杂性](https://en.wikipedia.org/wiki/Biological_neuron_model)，我们不太容易去模拟生物神经网络的神经元（可以说没有达到[网络规模](https://www.youtube.com/watch?v=b2F-DItXtZs)），这使得一些聪明的人发明了一种人工神经网络的数学结构，使得可以用数学来近似地表示大脑的行为。

Artificial neural networks (which I’m going to call just neural networks) are prominent at **generalizing** over datasets (e.g. learning how a cat looks like), so they found their use in face recognition (e.g. for cameras), language translation (e.g. for [GNMT](https://en.wikipedia.org/wiki/Google_Neural_Machine_Translation)), and - in our case - to steer colorful pixels for a handful of reddit karma.
>人工神经网络（我称之为神经网络）以**归纳**数据集（如学习一只猫是什么样子）著称，所以它可用于面部识别（如相机），语言翻译（如 [GNMT](https://en.wikipedia.org/wiki/Google_Neural_Machine_Translation)），而在我们的场景中，就是给一些 reddit 社区成员引导彩色像素。

The particular kind of network we’ll be focusing on is called `feedforward neural network` (FFNN)…​
>我们将上面所描述的特殊网络称之为“前馈神经网络”（FFNN）…​

>Cool bear’s hot tip: FFNNs are sometimes called [multilayer perceptrons](https://en.wikipedia.org/wiki/Multilayer_perceptron) and they are one of the building [blocks of convolutional neural networks](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53), such as [DeepDream](https://en.wikipedia.org/wiki/DeepDream).
>酷熊的温馨提示：FFNNs 有时被称为[多层感知器](https://en.wikipedia.org/wiki/Multilayer_perceptron)，并且它也是一种[卷积神经网络模块](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)，例如 [DeepDream](https://en.wikipedia.org/wiki/DeepDream)。

... 它看起来类似于这样:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-2.png)

_Figure 3. 多层感知器（MLP），也称 FFNN _

This is a layout of an FFNN with **five synapses** and **three neurons**, all organized in **two layers**: the **input layer** (on the left side) and the **output layer** (on the right side).
>这是一个多层感知器的布局结构，又**五个突出**和**三个神经元**，**两层**的所有组织：**输入层**（在左侧）和**输出层**（在右侧）。

There may also exist layers in-between, in which case they are called hidden layers - they improve the network’s ability to understand the input data (think: the bigger the brain, the "more abstraction" it might understand, to a certain degree).
>也有可能存在中间层，在这种情况下，它被称为隐藏层 —— 它可以提高网络输入数据的能力（可以想象一下：大脑越大，在一定程度上，理解抽象的能力更强）。

>A [similar process](https://www.youtube.com/watch?v=rA5qnZUXcqo) happens inside your own [visual cortex](https://en.wikipedia.org/wiki/Visual_cortex), too.
>[类似的过程](https://www.youtube.com/watch?v=rA5qnZUXcqo)也发生在你的[视觉皮层](https://en.wikipedia.org/wiki/Visual_cortex)中。

Contrary to biological neural networks (which piggyback on electric signals), FFNNs work by accepting some **numbers** at their input and propagating (_feedforwarding_) those numbers layer-by-layer across the entire network; numbers that appear at the last layer determine network’s answer.
>与生物神经网络（基于电信号）相反，FFNNs 的工作原理是在输入时接受一些**数字**，然后再整个网络中一层一层地传播这些数字；当它们到达最后一层时，就达成了整个神经网络的目的。

For instance, if you fed your network with raw pixels of a picture, you might’ve got a response saying:
>例如，如果你将一张图片的原始像素输入你的网络，你可能得到这样的结果：

* `0.0` - this picture does not contain an orange cat eating lasagna,
* `0.0` - 这张照片里没有在吃千层面的橙色猫，
* `0.5` - this picture might contain an orange cat eating lasagna,
* `0.5` - 这张照片可能会有一只在吃千层面的橙色猫，
* `1.0` - this picture certainly contains an orange cat eating lasagna.
* `1.0` - 这张照片里肯定有一只在吃千层面的橙色猫。

It’s also possible for a network to return _many values_ (the number of output values is equal to the number of neurons in the output layer):
>网络也有可能返回 _多个结果值_（输出的值的数量等同于输出层神经元的数量）：

* `(0.0, 0.5)` - this picture _does not_ contain an orange cat, but _might_ contain a lasagna,
* `(0.0, 0.5)` - 这张照片 _没有_ 橙色的猫，但 _可能_ 有一个千层面，
* `(0.5, 0.0)` - this picture _might_ contain an orange cat, but _does not_ contain a lasagna.
* `(0.5, 0.0)` - 这张照片 _可能_ 有橙色的猫，但 _没有_ 千层面。

The meaning of input and output numbers is up to you - in this case we’ve simply imagined that there exists some neural network behaving this way, but in reality it’s on you to prepare so-called **training dataset** ("given this picture, you should return 1.0", "given that picture, you should return 0.0").
>输入数值和输出数值的意义因你而定 —— 在这种情况下我们只能简单地想象，在现实中，存在一种神经网络的行为方式，它依赖于你准备的**训练数据集**（“给定一张照片，返回 1.0”，“给定另一张照片，你应该返回 0.0”）。

>You might’ve as well created a network that, say, [identifies mature apples](https://www.researchgate.net/publication/320662740_Identification_and_counting_of_mature_apple_fruit_based_on_BP_feed_forward_neural_network) - sky’s the limit.
>你也可以创建一个网络，比如，[识别成熟的苹果](https://www.researchgate.net/publication/320662740_Identification_and_counting_of_mature_apple_fruit_based_on_BP_feed_forward_neural_network) - sky’s the limit

Having the general overview of FFNNs in mind, let’s now take the next major step and learn about the magic allowing for all of this to happen.
>大体上对 FFNNs 有了了解，现在我们进入下一个关键步骤，去理解让这些可能性得以发生的魔法。

## 神经网络：深入

FFNNs lean on two building blocks: neurons and **synapses**.
>FFNNs 依赖于两个模块：神经元和**突触**。

A **neuron** (usually represented with a circle) accepts some input values, processes them, and returns some output value; each neuron has at least one input and at most one output:
>一个**神经元**（通常用圆表示）接受一些输入，处理他们，并返回一些输出值；每个神经元至少一个输入，并且最多一个输出：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-3.png)

_Figure 4. 有三个突触的单个神经元_

Additionally, each neuron has a **bias**:
>另外，每个神经元都有一个**偏差**：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-4.png)

_Figure 5. A single neuron with three synapses and annotated bias value_
_Figure 5. 一个具有三个突触和一个已经标注出来的偏差值的单个神经元_

Bias is like a neuron’s `if` statement - it allows for a neuron to stay inactive (return an output of zero) unless the input is strong (high) enough. Formally we’d say that bias allows to regulate neuron’s **activation threshold**.
>偏差类似于神经元的 `if` 语句 —— 它允许神经元保持非活动状态（返回 0 的输出）除非输入足够强（高）。确切地说，偏差可以调节神经元的**激活阈值**。

Imagine you’ve got a neuron with three inputs, with each input determining whether it sees a lasagna (`1.0`) or not (`0.0`) - now, if you wanted to create a neuron that’s activated when it sees at least two lasagnas, you’d simply create a neuron with a bias of `-1.0`; this way your neuron’s "natural" state would be `-1.0` (inactive), with one lasagna - `0.0` (still inactive), and with two - `1.0` (active, voilà).
假如你有一个神经元，它有三个输入，每个输入都能决定它看到的是千层面（`1.0`）还是看不到（`0.0`） —— 现在，假如你创建了一个神经元，当它看到两个以上的千层面时就会被激活，你只需创建一个偏差为 `-1.0` 的神经元，这样一来，神经元的“自然”状态就会是 `-1.0`（不活动），看到一个千层面时 `0.0`（仍然是不活动），当看到两个时 —— `1.0`（活跃，voilà）。

>If my lasagna metaphor doesn’t appeal to you, you might find [this math-oriented explanation](https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks) more helpful.
>如果我的千层面的比喻还不能让你理解，你可以看看这个[面向数学的解释](https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks)，也许对你有帮助。

Apart from neurons, we’ve got synapses - a **synapse** is like a wire that connects one neuron’s output to another neuron’s input; each synapse is of certain **weight**:
>除了神经元，我们还有突触 —— 突触就像一根电线，连接一个神经元的输出和另一个神经元的输入；每个突触都有一定的**权重**：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-5.png)

_Figure 6. A single neuron with three synapses with annotated weights_
_Figure 6. _有三个突触的神经元，突触上已注明权重_

A weight is a factor (hence the `x` before each number, to emphasize its multiplicative nature), so a weight of:
>权重是一种因子（因此每个数字都有 `x`，用于与其相乘）因此权重可以表示为：

* `0.0` means that a synapse is effectively dead (it doesn’t pass any information from one neuron into the another),
* `0.0` 意味着突触实际上已经死亡（它不会将任何信息从一个神经元传递到另一个神经元），
* `0.3` means that if neuron A returns `0.7`, neuron B will receive `0.7 * 0.3 ~= 0.2`,
* `0.3` 意味着如果神经元 A 返回 `0.7`，那么神经元 B 将接收到 `0.7 * 0.3 ~= 0.2`，
* `1.0` means that a synapse is effectively passthrough - if neuron A returns `0.7`, neuron B will receive `0.7 * 1.0 = 0.7`.
* `1.0` 表示神经元高效地传递 —— 如果神经元 A 输出 `0.7`，那么神经元 B 将接收到 `0.7 * 1.0 = 0.7`。

Having all this knowledge in mind, let’s go back to our network and fill-in missing weights & biases with some random numbers:
>有了这谢谢知识，我们回到前面说到的网络，用一些随机数来填补缺失的权重和偏差：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-6.png)

What a beauty, isn’t it?
>很漂亮，对吧？

Let’s see what it thinks of, say, `(0.5, 0.8)`:
>我们看看它是怎么“思考”的，比如 `(0.5, 0.8)`：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-7.png)

To reiterate, we’re interested in the output value of the rightmost neuron (that’s our output layer) - since it depends on two previous neurons (the ones from the input layer), we’re going to start with them.
>重申一下，我们的重点是最右边的神经元（即输出层） —— 因为它依赖于前面两个神经元（输入层的神经元），我们将从它们开始。

Let’s focus on the top-left neuron first - to calculate its output, we start by computing a **weighted sum** of all its inputs:
>我们先关注左上角的神经元 —— 为了计算它的输出，我们首先计算它所有输入的加权和：

```
0.5 * 0.2 = 0.1
```

... then, we add the bias:
>... 然后，将偏差相加：

```
0.1 - 0.3 = -0.2
```

... and clamp this value through so-called activation function; activation function limits neuron’s output to a predefined range, simulating the `if`-like behavior.
>... 通过所谓的激活功能来控制这个值；激活函数将神经元的输出限制在一个预先所设定的范围内，模拟类似于“假设”的行为。

The simplest activation function is rectified linear unit (`ReLU`), which is basically `f32::max`:
>最简单的激活函数就是矫正线性单元（`ReLU`），基本上就是 `f32::max`：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-8.png)

>* Another popular activation function is `tanh` - its graph looks slightly different (like an `s`) and it’s got [different properties](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks).
>* 另一个流行的激活函数是 `tanh` —— 它的图形看起来有点不同（类似于 `s`），它有[不同的属性](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks)。

>* **Activation function affects network’s input and output** - e.g. `tanh` forces a network to work on numbers from range `<-1.0, 1.0>` instead of `<0.0, +inf>`, as compared to `ReLU`.
>* **激活函数影响网络的输入和输出** —— 比如，与 `ReLU` 相比，`tanh` 强制网络工作在 `<0.0, +inf>` 范围内，而非 `<0.0, +inf>`。

As you can see, when our weighted-sum-with-a-bias is lower than zero, the neuron’s output will be `0.0` - and that’s exactly what happens to our current output:
>如你所见，当加权偏差和小于 0 时，神经元的输出将是 `0.0` —— 这正是当前输出的实际情况：

```
max(-0.2, 0.0) = 0.0
```

Nice; now let’s do the bottom-left one:
>太好了；现在让我们来做左下角的那个：

```
# 权重和：
0.8 * 1.0 = 0.8

# 偏差：
0.8 + 0.0 = 0.8

# 激活函数：
max(0.8, 0.0) = 0.8
```

At this point we’ve got the input layer completed:
>现在我们已经完成了输入层：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-9.png)

... which heads us towards the last neuron:
>... 现在转向最后一个神经元：

```
# 权重和：
(0.0 * 0.6) + (0.8 * 0.5) = 0.4

# 偏差：
0.4 + 0.2 = 0.6

# 激活函数：
max(0.6, 0.0) = 0.6
```

... and the network’s output itself:
>... 该网络输出还是它本身的值：

```
0.6 * 1.0 = 0.6
```

Voilà - for the input of `(0.5, 0.8)`, our network responded `0.6`.
> Voilà - 也就是说输入是 `(0.5, 0.8)` 时，我们的网络就会响应 `0.6`。

_(since it’s just an exercise on a totally made-up network, this number doesn’t mean anything - it’s just some output value.)_

_（因为它只是一个完全虚构的网络练习，数字本身没有任何意义 —— 只是一些输出值）_

Overall, that’s one of the simplest FFNNs possible - given appropriate weights, it’s able to solve [the XOR problem](https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b), but probably lacks computational capacity to steer a bird.
>总的来说，这可能是一种最简单的 FFNNs —— 给定适当的权重，它能够解决 [XOR 问题](https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b)，但缺乏控制鸟的计算能力。

More complex FFNNs, such as this one:
>复杂一些的 FFNNs，如下所示：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-10.png)

... work exactly the same way: you just go left-to-right, neuron-by-neuron, computing the outputs, until you squeeze all the numbers from the output layer.
... 工作原理上是类似的：你只需要从左到右，一个神经元接着一个神经元地进行计算输出，直到你从输出层得到所有的数字。

_(on that particular diagram some of the synapses overlap, but it doesn’t mean anything: it’s just that representing multidimensional graphs on a flat screen is unfortunate.)_
_（在上方的图中，一些突触重叠，但这并没有什么特别的含义：只是在平面上不太好绘制多维图形而已）_

At this point you might begin to wonder "wait, how do we know our network’s weights?", and for that I’ve got a simple answer:
>在这一点上，你可能会想到：“等等，我们如何知道网络的权重呢？”，对此，我有个简单的答案：

**we randomize them! ❤️️**
>**我们直接取随机值吧！❤️️**

If you’re accustomed to deterministic algorithms (bubble sort, anyone?), this might feel non-diegetic to you, but it’s the way things go for networks containing more than a few neurons: you cross your fingers, randomize the initial weights, and work with what you got.
>如果你已经习惯使用确定性的算法（冒泡算法等等），这可能对你不太直白，但这却是多个神经元网络的运行方式：将你的手指交叉，随机分配一些初始的权重值，并根据你的需要进行工作。

Notice I said initial weights - having some non-zero weights in place, there are certain algorithms that you can apply on your network to improve it (so, essentially, to teach it).
>注意我说的初始权重值 —— 有一些地方是非零权重值，有一些特定的算法，你可以应用到你的网络上改进它（所以，本质上就是你训练它）。

One of the most popular "teaching" algorithms for FFNNs is [backpropagation](https://www.youtube.com/watch?v=tIeHLnjs5U8):
>FFNNs 的最通用的“训练”方f法之一是[反馈传播 （backpropagation）](https://www.youtube.com/watch?v=tIeHLnjs5U8):

You show your network lots (think: hundredths of thousands) of examples in the form of "for this input, you should return that" (think: "for this picture of dakimakura, you should return pillow"), and backpropagation slowly adjusts your network’s weights until it gets the answers right.
>你以“这种输入，应该对应那个输出”的形式向你的网络展示大量（考虑一下成百上千个例子）的例子，（考虑：“输入 dakimakura 图片，你应该返回枕头”），然后 backpropagation 慢慢那调整你的网络权重值，直至得到正确答案。

>* Or not - a network might get stuck at a [local optimum](https://en.wikipedia.org/wiki/Local_optimum) and "just" stop learning.
>* 否则 —— 网络可能陷入[局部最优](https://en.wikipedia.org/wiki/Local_optimum)，然后“就”停止学习。
>* Also, if you ever find yourself doing a neural network crossword, remember that backpropagation is an example of [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning).
>* 此外，如果你发现自己在做神经网络的天子游戏，请记住 backpropagation 只是[监督学习](https://en.wikipedia.org/wiki/Supervised_learning)的 一个例子而已。

Backpropagation is a great tool if you have a rich set of labeled examples (such as photos or statistics), and that’s why it doesn’t fit our original assumption:
>如果你有一组丰富的标记示例（如照片或统计数据）， Backpropagation 是一个很棒的工具，这就是为什么它不符合我们最初的假设：

We ain’t no statisticians, the world is a cruel place, so we want for our birds to figure out all the learning on their own (contrary to being given concrete examples of "for this vision, go left", "for this vision, go right").
>我们不是统计学家，而世界是一个残酷的地方，所以我们向让我们的鸟类自己去学习所有的东西（相反地，给它们一些具体地例子，“为了这个远景，向左走”，“为了那个目标，向右走”）。

Solution?
>解决方法呢？

~~biology~~ genetic algorithms and the magic of [large numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers)

## Genetic algorithm: Introduction

To recap, from the mathematical point of view our underlying problem is that we have a function ([represented](https://en.wikipedia.org/wiki/Universal_approximation_theorem) using a neural network) that’s defined by a whole lot of **parameters**:

![](https://pwy.io/resources/learning-to-fly-pt1/ga-1.png)

_(I didn’t bother to draw all the weights, but I hope you get the point - there’s a lot of them.)_

Had we represented each parameter with a single-precision floating-point number, a network of mere 3 neurons and 5 synapses could be defined in so many different combinations…​

```
(3.402 * 10^38) ^ (3 + 5) ~= 1.8 * 10^308
```

_[(how-many-floating-point-numbers-are-there)](https://jameshoward.us/2015/09/09/how-many-floating-point-numbers-are-there/)_

... that the universe would sooner meet its [ultimate fate](https://en.wikipedia.org/wiki/Heat_death_of_the_universe) than we’d be done checking them all; we certainly need to be smarter!

>* All the possible sets of parameters are called a **search space**.

Since iterating through our search space looking for the single best answer is off the table, we can focus on a much simpler task of finding a list of _suboptimal_ answers.

And in order to do that, we must **dig deeper**.

## Genetic algorithm: Deep dive

This is a wild carrot together with its domesticated form:

![](https://pwy.io/resources/learning-to-fly-pt1/carrot.jpg)

This domesticated, widely known form didn’t appear out of blue - it’s an outcome of hundredths of years of [selective breeding](https://en.wikipedia.org/wiki/Selective_breeding) with certain factors - like taproot’s texture or color - in mind.

Wouldn’t it be awesome if we could do a similar thing with our neural brains? If we just, like, created a bunch of random birds and selectively bred the ones who seemed the most prominent…​

**hmmm**

As it turns out, we’re not the first to stumble upon this idea - there already exists a widely researched branch of computer science called [evolutionary computation](https://en.wikipedia.org/wiki/Evolutionary_computation) that’s all about solving problems "just the way nature would do".

Out of all the evolutionary algorithms, the concrete subclass we’ll be studying is called [genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm).

>* Similarly as with neural networks, there’s no the genetic algorithm - it’s a variety of different algorithms; so to avoid burning the midnight oil, we’ll take a look at how things work _generally_.

Starting top-bottom, a genetic algorithm starts with a **population**:

![](https://pwy.io/resources/learning-to-fly-pt1/ga-2.png)

A population is built from **individuals** (sometimes called **agents**):

![](https://pwy.io/resources/learning-to-fly-pt1/ga-3.png)

An **individual** (or an **agent**) is a single _possible solution_ to given problem (a population is thus a set of some possible solutions).

In our case, each individual will model a brain (or an entire bird, if you prefer to visualise it this way), but generally it depends on the problem you’re tackling:

* If you were trying to, say, [evolve an antenna](https://en.wikipedia.org/wiki/Evolved_antenna), a single individual would be a single antenna.
* If you were trying to, say, [evolve a query plan](https://www.postgresql.org/docs/8.3/geqo-intro2.html), a single individual would be a single query plan.

>* An individual represents some solution, but not necessarily the best or even a remotely desirable one.

An individual is built from **genes** (collectively named **genome**):

![](https://pwy.io/resources/learning-to-fly-pt1/ga-4.png)

_Figure 7. A genome represented with neural network’s weights; a genome might be a list of numbers, a graph or anything else that is able to model a solution to the problem_

A **gene** is a single parameter that’s being evaluated and tuned by the genetic algorithm.

In our case, each gene will be simply a neural network’s weight, but representing problem’s domain isn’t always this straightforward.

For instance, if you were trying to [help a fellow salesman](https://en.wikipedia.org/wiki/Travelling_salesman_problem), where the underlying problem isn’t based on neural networks at all, a single gene could be a tuple of `(x, y)` coordinates determining a part of a salesman’s journey (consequently, an individual would then describe a salesman’s entire path):

![](https://pwy.io/resources/learning-to-fly-pt1/ga-5.png)

_Figure 8. A hypothetical approach to the travelling salesman problem - each box represents a probable, suggested path for the salesman to travel_

Now, let’s say we’ve got a random population of fifty birds - we pass them to a genetic algorithm, what happens?

Similarly as with selective breeding, genetic algorithm starts by **evaluating** each of the individuals (each of the possible solutions) to see which are the best among the current population.

Biologically, this is an equivalent of taking a stroll to your garden and checking which carrots are the orangest and the yummiest.

Evaluation happens using so-called **fitness function** that returns a **fitness score** quantifying how good a particular individual (so a particular solution) is:

![](https://pwy.io/resources/learning-to-fly-pt1/ga-6.png)

_Figure 9. An example of a fitness function that quantifies carrots by their taproot’s color and radius_

Creating a [usable](https://www.youtube.com/watch?v=7J-DfS52bnI) fitness function is one of the hardest tasks when it comes to genetic algorithms, as usually there are many metrics by which an individual can be measured.

(even our imaginative carrot has at least three metrics: taproot’s color, radius, and taste, that have to be squashed into a single number.)

Fortunately, when it comes to birds, we don’t have much to choose from anyway: we’ll just say that a bird is as good as the amount of food it ate during the course of current **generation**.

A bird who ate `30` foods is better than the one who ate just `20`, simple as that.

>* Negating a fitness function makes a genetic algorithm return the worst solutions instead of the best ones; just an amusing trick to remember for later.

Now, the time has come for the genetic algorithm’s crème de la crème: **reproduction**!

Broadly speaking, reproduction is the process of building a new (hopefully - slightly improved) population starting from the current one.

It’s the mathematical equivalent of choosing the tastiest carrots and planting their seeds.

What happens is that the genetic algorithm chooses two individuals at random (prioritizing the ones with the higher fitness scores) and uses them to produce two new individuals (a so-called **offspring**):

![](https://pwy.io/resources/learning-to-fly-pt1/ga-7.png)

Offspring is produced by taking genomes of both parents and performing [crossover](https://en.wikipedia.org/wiki/Chromosomal_crossover) & [mutation](https://en.wikipedia.org/wiki/Mutation) on them:

![](https://pwy.io/resources/learning-to-fly-pt1/ga-8.png)

>* **Crossover** allows to mix two different gnomes to get an approximate in-between solution, while **mutation** allows to discover new solutions that weren’t present in the initial population.

Both newly-spawned individuals are pushed into the pool of `new population` and the process starts over until the entire new population is built; the current population then gets discarded and the whole simulation starts over on this new (hopefully improved!) population.

As you can see, there’s a lot of **randomness** in the process: we start with a random population, we randomize how the genes are being distributed…​ so…​

this cannot actually work, can it?

## The Code

Let’s end this post with a cliffhanger:

```shell
$ mkdir shorelark
```

Can you guess why I didn’t use `cargo new`?

In the second part we’ll implement a working, bare-bones feed-forward neural network - until then!

## Sources

Here are some of the sources that I’ve personally found useful while learning about topics presented in this article:

**Neural networks:**
* [YouTube, 3Blue1Brown - But what is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk)
* [YouTube, Vsauce - The Stilwell Brain](https://www.youtube.com/watch?v=rA5qnZUXcqo)

**Genetic algorithms:**

* [YouTube, Jeremy Fisher - Genetic Algorithms](https://www.youtube.com/watch?v=7J-DfS52bnI)
* [obitko.com - Genetic Algorithms Tutorial](https://www.obitko.com/tutorials/genetic-algorithms/index.php)
* [Darrell Whitley - A Genetic Algorithm Tutorial](https://ibug.doc.ic.ac.uk/media/uploads/documents/courses/GeneticAlgorithm-tutorial.pdf)
