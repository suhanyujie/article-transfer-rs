>* Rust and CSV parsing 译文（用 Rust 实现 csv 解析-part7）
>* 原文链接：https://pwy.io/en/posts/learning-to-fly-pt1/
>* 原文作者：[Patryk27](https://github.com/Patryk27)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust, simulation,  genetic-algorithm, neural-network, rust, webassembly

系列文章：
* [Learning to Fly: Let's create a simulation in Rust! (pt 1)](https://pwy.io/en/posts/learning-to-fly-pt1/)
* [Learning to Fly: Let's create a simulation in Rust! (pt 2)](https://pwy.io/en/posts/learning-to-fly-pt2/)

In this series we’ll create a simulation of evolution using neural network & genetic algorithm.

I’m going to introduce you to how a basic neural network and genetic algorithm works, then we’ll implement both in Rust and compile our application to WebAssembly to ultimately end up with:

![Figure 1. https://pwy.io/en/projects/shorelark/](https://pwy.io/resources/learning-to-fly-pt1/intro-outcome.png)

This series will be divided into a few posts, roughly:

* 1.Introduction to the domain (what are we going to simulate, how does a neural network & genetic algorithm work),

* 2.Implementing a neural network,

* 3.Implementing a genetic algorithm,

* 4.Implementing eyes, brain, and the simulation itself.

Due diligence: I’ll do my best to explain all the concepts, but if at any point you feel lost, feel free to take a look at this article’s last section - it contains links to external (mostly popular science) sources that might prove to be helpful in understanding the domain.

Curious? Hop on the bus, Gus, and onto the first chapter: [Design](https://pwy.io/en/posts/learning-to-fly-pt1/#design).

## [Design](https://pwy.io/en/posts/learning-to-fly-pt1/#design)

Let’s start by clearly defining our objective: what are we going to simulate, actually?

The overall idea is that we have a two-dimensional board representing a **world**:

![](https://pwy.io/resources/learning-to-fly-pt1/design-1.png)

This world consists of birds (hence the project’s original code name - Shorelark):

![](https://pwy.io/resources/learning-to-fly-pt1/design-2.png)

... and foods (of an abstract kind, rich in protein & fiber):

![](https://pwy.io/resources/learning-to-fly-pt1/design-3.png)

Each bird has their own vision, allowing them to locate the food:

![](https://pwy.io/resources/learning-to-fly-pt1/design-4.png)

... and a brain that controls bird’s body (i.e. speed and rotation).

Our magic touch will lay in the fact that instead of hard-coding our birds to some specific behavior (e.g. "go to the nearest food in your eyesight"), we’ll take a more intriguing route:

We’ll make our birds able to learn and evolve.

## Brain

If you squint your eyes hard enough, you’ll see that a brain is nothing but a function of some inputs to some outputs, e.g.:

![](https://pwy.io/resources/learning-to-fly-pt1/brain-1.png)

>You’re a precious mathematical formula, remember that.

Since our birds will have only one sensory input, their brains can be then approximated as:

![](https://pwy.io/resources/learning-to-fly-pt1/brain-2.png)

Mathematically, we can represent this function’s input (i.e. biological eye) as a list of numbers, with each number (i.e. biological photoreceptor) describing how close the nearest object (i.e. food) is:

![](https://pwy.io/resources/learning-to-fly-pt1/brain-3.png)

_(0.0 - no object in sight, 1.0 - object right in front of us.)_

>Our birds won’t see color, but that’s just for simplicity - you could use e.g. raytracing to make the eyes more realistic.

As for the output, we’ll make our function return a tuple of (Δspeed, Δrotation).

For instance, a brain telling us (0.1, 45) will mean "body, please increase our speed by 0.1 units and rotate us 45 degrees clockwise", while (0.0, 0) will mean "body, please keep our course steady".

>It’s important that we use relative values (so delta speed and delta rotation), as our brain won’t be aware of its own location & rotation respective to the world - passing that information would increase our brain’s complexity for no real benefit.

Finally, let’s address the elephant in the room: so a brain is basically f(eyes), right? But how do we find out what actually follows the equals sign?

```
f(eyes) = what?
```

## Neural network: Introduction

As a fellow human, you are might be aware that brains are made of neurons connected via synapses:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-1.png)

_Figure 2. My attempt at drawing neurons; not to scale_

Synapses carry electric and chemical signals between neurons, while neurons "decide" whether given signal should be propagated further or stopped; eventually this allows for people to recognize letters, eat brussels sprouts, and write mean comments on Twitter.

Due to their inherent complexity, biological neural networks are not among the easiest to simulate (one could argue that neurons are thus not Web Scale), which made some smart people invent a class of mathematical structures called artificial neural networks, which allow to approximate - with a pinch of salt - brain-like behavior using math.

Artificial neural networks (which I’m going to call just neural networks) are prominent at generalizing over datasets (e.g. learning how a cat looks like), so they found their use in face recognition (e.g. for cameras), language translation (e.g. for GNMT), and - in our case - to steer colorful pixels for a handful of reddit karma.

The particular kind of network we’ll be focusing on is called feedforward neural network (FFNN)…​

>Cool bear’s hot tip: FFNNs are sometimes called multilayer perceptrons and they are one of the building blocks of convolutional neural networks, such as DeepDream.

... and it looks like this:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-2.png)

_Figure 3. Example of a multilayer perceptron (MLP), also called FFNN_

This is a layout of an FFNN with five synapses and three neurons, all organized in two layers: the input layer (on the left side) and the output layer (on the right side).

There may also exist layers in-between, in which case they are called hidden layers - they improve the network’s ability to understand the input data (think: the bigger the brain, the "more abstraction" it might understand, to a certain degree).

>A similar process happens inside your own visual cortex, too.

Contrary to biological neural networks (which piggyback on electric signals), FFNNs work by accepting some numbers at their input and propagating (feedforwarding) those numbers layer-by-layer across the entire network; numbers that appear at the last layer determine network’s answer.

For instance, if you fed your network with raw pixels of a picture, you might’ve got a response saying:

* 0.0 - this picture does not contain an orange cat eating lasagna,
* 0.5 - this picture might contain an orange cat eating lasagna,
* 1.0 - this picture certainly contains an orange cat eating lasagna.

It’s also possible for a network to return many values (the number of output values is equal to the number of neurons in the output layer):

* (0.0, 0.5) - this picture does not contain an orange cat, but might contain a lasagna,
* (0.5, 0.0) - this picture might contain an orange cat, but does not contain a lasagna.

The meaning of input and output numbers is up to you - in this case we’ve simply imagined that there exists some neural network behaving this way, but in reality it’s on you to prepare so-called training dataset ("given this picture, you should return 1.0", "given that picture, you should return 0.0").

>You might’ve as well created a network that, say, identifies mature apples - sky’s the limit.

Having the general overview of FFNNs in mind, let’s now take the next major step and learn about the magic allowing for all of this to happen.

## Neural network: Deep dive

FFNNs lean on two building blocks: neurons and synapses.

A neuron (usually represented with a circle) accepts some input values, processes them, and returns some output value; each neuron has at least one input and at most one output:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-3.png)

_Figure 4. A single neuron with three synapses_

Additionally, each neuron has a bias:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-4.png)

_Figure 5. A single neuron with three synapses and annotated bias value_

Bias is like a neuron’s if statement - it allows for a neuron to stay inactive (return an output of zero) unless the input is strong (high) enough. Formally we’d say that bias allows to regulate neuron’s activation threshold.

Imagine you’ve got a neuron with three inputs, with each input determining whether it sees a lasagna (1.0) or not (0.0) - now, if you wanted to create a neuron that’s activated when it sees at least two lasagnas, you’d simply create a neuron with a bias of -1.0; this way your neuron’s "natural" state would be -1.0 (inactive), with one lasagna - 0.0 (still inactive), and with two - 1.0 (active, voilà).

>If my lasagna metaphor doesn’t appeal to you, you might find this math-oriented explanation more helpful.

Apart from neurons, we’ve got synapses - a synapse is like a wire that connects one neuron’s output to another neuron’s input; each synapse is of certain weight:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-5.png)

_Figure 6. A single neuron with three synapses with annotated weights_

A weight is a factor (hence the x before each number, to emphasize its multiplicative nature), so a weight of:

* 0.0 means that a synapse is effectively dead (it doesn’t pass any information from one neuron into the another),
* 0.3 means that if neuron A returns 0.7, neuron B will receive 0.7 * 0.3 ~= 0.2,
* 1.0 means that a synapse is effectively passthrough - if neuron A returns 0.7, neuron B will receive 0.7 * 1.0 = 0.7.

Having all this knowledge in mind, let’s go back to our network and fill-in missing weights & biases with some random numbers:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-6.png)

What a beauty, isn’t it?

Let’s see what it thinks of, say, (0.5, 0.8):

![](https://pwy.io/resources/learning-to-fly-pt1/nn-7.png)

To reiterate, we’re interested in the output value of the rightmost neuron (that’s our output layer) - since it depends on two previous neurons (the ones from the input layer), we’re going to start with them.

Let’s focus on the top-left neuron first - to calculate its output, we start by computing a weighted sum of all its inputs:

```
0.5 * 0.2 = 0.1
```

... then, we add the bias:

```
0.1 - 0.3 = -0.2
```

... and clamp this value through so-called activation function; activation function limits neuron’s output to a predefined range, simulating the if-like behavior.

The simplest activation function is rectified linear unit (ReLU), which is basically f32::max:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-8.png)

>Another popular activation function is tanh - its graph looks slightly different (like an s) and it’s got different properties.

Activation function affects network’s input and output - e.g. tanh forces a network to work on numbers from range <-1.0, 1.0> instead of <0.0, +inf>, as compared to ReLU.
