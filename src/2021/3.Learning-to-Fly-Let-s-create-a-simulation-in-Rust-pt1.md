>* Learning to Fly: Let's simulate evolution in Rust! (pt 1) 译文（学习飞行：用 Rust 模拟种群进化 part1）
>* 原文链接：https://pwy.io/en/posts/learning-to-fly-pt1/
>* 原文作者：[Patryk27](https://github.com/Patryk27)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust, simulation,  genetic-algorithm, neural-network, rust, webassembly

系列文章：
* [The Domain (pt 1)](https://pwy.io/en/posts/learning-to-fly-pt1/)
* [The Neural Network (pt 2)](https://pwy.io/en/posts/learning-to-fly-pt2/)
* [The Genetic Algorithm (pt 3)](https://pwy.io/en/posts/learning-to-fly-pt3/)

在这个系列文章中，我们将使用 **神经网络和遗传算法** 创建一个 **进化** 模拟器。

我会向你介绍一个基础的神经网络和遗传算法是如何工作的，然后使用 Rust 实现它们，并将应用编译到 **WebAssembly**，最后实现如下所示：

![图 1. https://pwy.io/en/projects/shorelark/](https://pwy.io/resources/learning-to-fly-pt1/intro-outcome.png)

>* 这个系列的文章主要面向 **Rust 初学者** - 我假定你已初步了解 Rust，之后有需要时我会向你介绍其他概念（如神经网络）。
>* 不需要熟练掌握花哨的数学或有雄厚的 IT 背景。

这个系列将会分为若干篇文章，大概如下：

* 1.领域说明（我们模拟什么，神经网络和遗传算法如何工作），
* 2.实现一个神经网络
* 3.实现一个遗传算法
* 4.实现眼睛、大脑和模拟器本身。

声明：我会尽我所能解释所有的概念，但如果你在任意时候有疑惑，可以看这篇文章的最后一节 —— 它包含了外部资源（主流科学）的一些链接，可能会帮助你理解对应的领域知识。

好奇吗？快上车吧，伙计，我们进入第一章：[设计](https://pwy.io/en/posts/learning-to-fly-pt1/#design).

## [Design](https://pwy.io/en/posts/learning-to-fly-pt1/#design)

我们先明确我们的目标：我们到底要模拟什么？

总体设想是我们会创造一个二维的**世界**：

![](https://pwy.io/resources/learning-to-fly-pt1/design-1.png)

这个世界由**鸟**构成（因此项目的仓库名用 —— _Shorelark_）：

![](https://pwy.io/resources/learning-to-fly-pt1/design-2.png)

... 以及**食物**（抽象类实体，富含蛋白质和纤维）：

![](https://pwy.io/resources/learning-to-fly-pt1/design-3.png)

每只鸟有它们的**视界**，它们可以自己寻找食物：

![](https://pwy.io/resources/learning-to-fly-pt1/design-4.png)

... 并且由**大脑**控制鸟的身体（比如速度和旋转）。

我们的巧妙之处在于，我们没有将鸟类硬编码为具有特定行为的实体（例如：去定位你视线范围内最近的食物），我们会走一条更有趣的路线：

We’ll make our birds able to **learn** and **evolve**.
>我们要确保鸟实体能够**学习**和**进化**。

## 大脑

如果你换个角度看，你会发现大脑只不过是一个具备输入和输出的**函数**，例如：

![](https://pwy.io/resources/learning-to-fly-pt1/brain-1.png)

>你是一个珍贵的数学公式，记住这点：

由于我们的鸟只有一种感官输入，它们的大脑可以视为下图所示：

![](https://pwy.io/resources/learning-to-fly-pt1/brain-2.png)

数学角度看，我们可以将这个函数的输入（如生物的眼睛）表示为一组数，每个数字（生物感光器）描述周围的物体（如食物）与生物之间的距离：

![](https://pwy.io/resources/learning-to-fly-pt1/brain-3.png)

_(0.0 - 视线范围内没有物体, 1.0 - 在我们的右侧有一个对象.)_

>我们的鸟不能识别颜色，但这是为了简化 —— 你可以使用 [raytracing](https://raytracing.github.io/books/RayTracingInOneWeekend.html) 之类的库使眼睛的实现更接近真实。

至于输出，我们让函数返回一个元组 `(Δspeed, Δrotation)`。

例如，大脑告诉我们 `(0.1, 45)` 则意味着“身体，请给我们的速度增加 `0.1` 个单位，并顺时针旋转 45 度”，而如果大脑接收到的是 `(0.0, 0)`，则意味着“身体，请保持我们的航向一直向前”。 

>* 重要的是我们要使用相对值（即 `delta speed` 和 `delta rotation`），因为我们的大脑不会意识到自己的位置和旋转的角度 —— 传递这些信息只会增加大脑的复杂度而没有其他太大好处。

好了，我们来谈谈[“房间里的大象”](https://www.jianshu.com/p/981ad4a6fdc6)：所以大脑基本上可以表示为 `f(eyes)`，对吧？但我们如何知道下方的等式中等号后到底是什么？

```
f(eyes) = what?
```

## 神经网络：简介

作为一个人类同胞，你可能知道大脑由神经元并通过突触连接而成：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-1.png)

_图 2. 我没有按比例绘制神经元_

突触在神经元之间传递电信号和化学信号，而神经元“决定”已知的信号是应该继续传递还是停止传递；最终，人们可以识别字母，吃球芽甘蓝，以及在 Twitter 发表评论。

由于其固有的[复杂性](https://en.wikipedia.org/wiki/Biological_neuron_model)，我们不太容易去模拟生物神经网络的神经元（可以说没有达到[网络规模](https://www.youtube.com/watch?v=b2F-DItXtZs)），这使得一些聪明的人发明了一种人工神经网络的数学结构，使得可以用数学来近似地表示大脑的行为。

人工神经网络（我称之为神经网络）以**归纳**数据集（如学习一只猫是什么样子）著称，所以它可用于面部识别（如相机），语言翻译（如 [GNMT](https://en.wikipedia.org/wiki/Google_Neural_Machine_Translation)），而在我们的场景中，就是给一些 reddit 社区成员引导彩色像素。

The particular kind of network we’ll be focusing on is called `feedforward neural network` (FFNN)…​
>我们将上面所描述的特殊网络称之为 `feedforward neural network`（“前馈神经网络”）（FFNN）…​

>酷熊的温馨提示：FFNNs 有时被称为[多层感知器](https://en.wikipedia.org/wiki/Multilayer_perceptron)，并且它也是一种能构建[卷积神经网络](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)的模块，例如 [DeepDream](https://en.wikipedia.org/wiki/DeepDream)。

... 它看起来类似于这样:

![](https://pwy.io/resources/learning-to-fly-pt1/nn-2.png)

_图 3. 多层感知器（MLP），也称 FFNN _

这是一个多层感知器的布局结构，有**五个突出**和**三个神经元**，所有组织都在这**两层**：**输入层**（在左侧）和**输出层**（在右侧）。

也有可能存在中间层，在这种情况下，它被称为隐藏层 —— 它可以提高网络输入数据的能力（可以想象一下：大脑越大，在一定程度上，理解抽象的能力更强）。

>[类似的过程](https://www.youtube.com/watch?v=rA5qnZUXcqo)也发生在你的[视觉皮层](https://en.wikipedia.org/wiki/Visual_cortex)中。

与生物神经网络（基于电信号）相反，FFNNs 的工作原理是在输入时接受一些**数字**，然后再整个网络中一层一层地传播这些数字；当它们到达最后一层时，就达成了整个神经网络的目的。

例如，如果你将一张图片的原始像素输入你的网络，你可能得到这样的结果：

* `0.0` - 这张照片里没有在吃千层面的橙色猫，
* `0.5` - 这张照片可能会有一只在吃千层面的橙色猫，
* `1.0` - 这张照片里肯定有一只在吃千层面的橙色猫。

网络也有可能返回 _多个结果值_（输出的值的数量等同于输出层神经元的数量）：

* `(0.0, 0.5)` - 这张照片 _没有_ 橙色的猫，但 _可能_ 有一个千层面，
* `(0.5, 0.0)` - 这张照片 _可能_ 有橙色的猫，但 _没有_ 千层面。

输入数值和输出数值的意义因你而定 —— 在这种情况下我们只能简单地想象，在现实中，存在一种神经网络的行为方式，它依赖于你所准备的**训练数据集**（“给定一张照片，返回 1.0”，“给定另一张照片，你应该返回 0.0”）。

>你也可以创建一个网络，比如，[识别成熟的苹果](https://www.researchgate.net/publication/320662740_Identification_and_counting_of_mature_apple_fruit_based_on_BP_feed_forward_neural_network) - sky’s the limit

大体上对 FFNNs 有了了解，现在我们进入下一个关键步骤，去理解让这些可能性得以发生的魔法。

## 神经网络：深入

FFNNs 依赖于两个模块：神经元和**突触**。

一个**神经元**（通常用圆表示）接受一些输入，处理他们，并返回一些输出值；每个神经元至少一个输入，并且最多一个输出：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-3.png)

_图 4. 有三个突触的单个神经元_

另外，每个神经元都有**偏差**：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-4.png)

_图 5. 一个具有三个突触和一个已经标注出来的偏差值的单个神经元_

偏差类似于神经元的 `if` 语句 —— 它允许神经元保持非活动状态（返回 0 的输出）除非输入足够强（高）。确切地说，偏差可以调节神经元的**激活阈值**。

假如你有一个神经元，它有三个输入，每个输入都能决定它看到的是千层面（`1.0`）还是看不到（`0.0`） —— 现在，假如你创建了一个神经元，当它看到两个以上的千层面时就会被激活，你只需创建一个偏差为 `-1.0` 的神经元，这样一来，神经元的“自然”状态就会是 `-1.0`（不活动），看到一个千层面时 `0.0`（仍然是不活动），当看到两个时 —— `1.0`（活跃，voilà）。

>如果千层面的比喻还不能让你理解，你可以看看这个[面向数学的解释](https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks)，也许对你有帮助。

除了神经元，我们还有突触 —— 突触就像一根电线，连接一个神经元的输出和另一个神经元的输入；每个突触都有一定的**权重**：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-5.png)

_图 6. _有三个突触的神经元，突触上已注明权重_

权重是一种因子（因此每个数字都有 `x`，用于与其相乘）因此权重可以表示为：

* `0.0` 意味着突触实际上形如死亡（它不会将任何信息从一个神经元传递到另一个神经元），
* `0.3` 意味着如果神经元 A 返回 `0.7`，那么神经元 B 将接收到 `0.7 * 0.3 ~= 0.2`，
* `1.0` 表示神经元高效地传递 —— 如果神经元 A 输出 `0.7`，那么神经元 B 将接收到 `0.7 * 1.0 = 0.7`。

有了这些知识，我们回到前面说到的网络，用一些随机数来填补缺失的权重和偏差：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-6.png)

很漂亮，对吧？

我们看看它是怎么“思考”的，比如输入 `(0.5, 0.8)`：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-7.png)

重申一下，我们的重点是最右边的神经元（即输出层） —— 因为它依赖于前面两个神经元（输入层的神经元），我们将从它们开始。

我们先关注左上角的神经元 —— 为了计算它的输出，我们首先计算它所有输入的**加权和**：

```
0.5 * 0.2 = 0.1
```

... 然后，将偏差相加：

```
0.1 - 0.3 = -0.2
```

... 通过所谓的激活函数来控制这个值；激活函数将神经元的输出限制在一个预先所设定的范围内，模拟类似于 `if` 的行为。

最简单的激活函数就是矫正线性单元（`ReLU`），基本上就是 `f32::max`：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-8.png)

>* 另一个流行的激活函数是 `tanh` —— 它的图形看起来有点不同（类似于 `s`），它有[不同的属性](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks)。

>* **激活函数影响网络的输入和输出** —— 比如，与 `ReLU` 相比，`tanh` 强制网络工作在 `<-1.0, 1.0>` 范围内，而非 `<0.0, +inf>`。

如你所见，当加权偏差和小于 0 时，神经元的输出将是 `0.0` —— 这正是当前输出的实际情况：

```
max(-0.2, 0.0) = 0.0
```

太好了；现在让我们来看看左下角的那个：

```
# 权重和：
0.8 * 1.0 = 0.8

# 偏差：
0.8 + 0.0 = 0.8

# 激活函数：
max(0.8, 0.0) = 0.8
```

现在我们已经完成了输入层：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-9.png)

... 现在转向最后一个神经元：

```
# 权重和：
(0.0 * 0.6) + (0.8 * 0.5) = 0.4

# 偏差：
0.4 + 0.2 = 0.6

# 激活函数：
max(0.6, 0.0) = 0.6
```

... 该网络输出等于它本身的值：

```
0.6 * 1.0 = 0.6
```

Voilà - 也就是说输入是 `(0.5, 0.8)` 时，我们的网络就会响应 `0.6`。

_（因为它只是一个完全虚构的网络练习，数字本身没有任何意义 —— 只是一些输出值）_

总的来说，这可能是一种最简单的 FFNNs —— 给定适当的权重，它能够解决 [XOR 问题](https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b)，但可能缺乏控制鸟的计算能力。

复杂一些的 FFNNs，如下所示：

![](https://pwy.io/resources/learning-to-fly-pt1/nn-10.png)

... 工作原理上是类似的：你只需要从左到右，一个神经元接着一个神经元地进行计算输出，直到你从输出层得到所有的数字。

_（在上方的图中，一些突触重叠，但这并没有什么特别的含义：只是在平面上不太好绘制多维图形而已）_

在这一点上，你可能会想到：“等等，我们如何知道网络的权重呢？”，对此，我有个简单的答案：

**直接取随机值吧！❤️️**

如果你已经习惯使用确定性的算法（冒泡算法等等），这可能对你不太直白，但这却是多个神经元网络的运行方式：将你的手指交叉，随机分配一些初始的权重值，并根据得到的值进行使用和工作。

注意我说的初始权重值 —— 有一些地方是非零权重值，有一些特定的算法，你可以应用到你的网络上改进它（所以，本质上就是你训练它）。

FFNNs 的最通用的“训练”方法之一是[反馈传播 （backpropagation）](https://www.youtube.com/watch?v=tIeHLnjs5U8):

你以“一种输入，应该返回合适的输出”的形式向你的神经网络输入大量（考虑一下成百上千个例子）的例子，（如：“输入 dakimakura 图片，你应该返回枕头”），然后 backpropagation 慢慢那调整你的网络权重值，直至得到正确答案。

>* 否则 —— 网络可能陷入[局部最优](https://en.wikipedia.org/wiki/Local_optimum)，然后“就”停止学习。
>* 此外，如果你发现自己在做神经网络的填字游戏，请记住 backpropagation 只是[监督学习](https://en.wikipedia.org/wiki/Supervised_learning)的方案之一而已。

Backpropagation 作为一个很棒的工具的前提，是得有大量的训练数据，这就是为什么它不符合我们最初的假设：

我们不是统计学家，而世界是一个残酷的地方，所以我们得让我们的鸟自己去学习所有的东西（相反地，给它们一些具体地例子，如：“为了这个心愿，向左走”，“为了那个目标，向右走”）。

解决方法呢？

~~生物学~~ 遗传算法和[大数定律](https://en.wikipedia.org/wiki/Law_of_large_numbers)的魔力。

## 遗传算法：介绍

回顾一下，从数学角度看，我们潜在的问题是有一类函数（它[代表](https://en.wikipedia.org/wiki/Universal_approximation_theorem)了神经网络），它的定义中有大量的**参数**：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-1.png)

_（我没有画出所有的权重，但我希望你们知道它有很多）_

如果我们用一个单精度浮点数来表示每个参数，那么仅 3 个神经元和 5 个突触就能定义很多个不同的组合...

```
(3.402 * 10^38) ^ (3 + 5) ~= 1.8 * 10^308
```

_[(浮点数有多少个)](https://jameshoward.us/2015/09/09/how-many-floating-point-numbers-are-there/)_

...二维世界很快就能遭遇它的[最终命运](https://en.wikipedia.org/wiki/Heat_death_of_the_universe)，我们不必逐个照顾它们，而是要让它更加智能！

>* All the possible sets of parameters are called a **search space**.
>* 所有可能的参数集合成为**搜索空间**。

Since iterating through our search space looking for the single best answer is off the table, we can focus on a much simpler task of finding a list of _suboptimal_ answers.
>由于遍历搜索空间寻找单个最佳答案不在大纲中，所以我们可以把重点放在一个简单一点的任务上，也就是寻找 _次优_ 答案列表。

And in order to do that, we must **dig deeper**.
>为了做到这一点，我们必须**深挖**。

## Genetic algorithm: Deep dive

This is a wild carrot together with its domesticated form:
>这是一个野生胡萝卜和它的驯化后的样子：

![](https://pwy.io/resources/learning-to-fly-pt1/carrot.jpg)

This domesticated, widely known form didn’t appear out of blue - it’s an outcome of hundredths of years of [selective breeding](https://en.wikipedia.org/wiki/Selective_breeding) with certain factors - like taproot’s texture or color - in mind.
>这种驯化了的、广为人知的品种不是突然出现的 —— 它是经过很多年的[选择性育种](https://en.wikipedia.org/wiki/Selective_breeding)以及经历了很多因素后（如主根的质地和颜色）的结果。

Wouldn’t it be awesome if we could do a similar thing with our neural brains? If we just, like, created a bunch of random birds and selectively bred the ones who seemed the most prominent…​
>如果我们能对大脑做类似的事情，那岂不是很棒？如果我们只是创造一群鸟，并且它们会选择性地繁殖那些看起来杰出的鸟...

**hmmm**

As it turns out, we’re not the first to stumble upon this idea - there already exists a widely researched branch of computer science called [evolutionary computation](https://en.wikipedia.org/wiki/Evolutionary_computation) that’s all about solving problems "just the way nature would do".
>事实证明，我们不是第一个有这种想法的人 —— 有一个被广泛研究的计算机科学分支，叫[进化计算](https://en.wikipedia.org/wiki/Evolutionary_computation)，它的核心思想是“按照自然选择的方式”解决问题。

Out of all the evolutionary algorithms, the concrete subclass we’ll be studying is called [genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm).
>在所有的进化算法中，我们将要学习的具体子类叫做[遗传算法](https://en.wikipedia.org/wiki/Genetic_algorithm)。

>* Similarly as with neural networks, there’s no the genetic algorithm - it’s a variety of different algorithms; so to avoid burning the midnight oil, we’ll take a look at how things work _generally_.
>* 类似于神经网络，不只是有遗传算法 —— 还有很多不同的其他算法；因此，为了避免午夜开车问题，我们将看看一切是如何 _正常_ 运作的。

Starting top-bottom, a genetic algorithm starts with a **population**:
>从上到下，遗传算法是从一个**种群**开始的：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-2.png)

A population is built from **individuals** (sometimes called **agents**):
>人口都是由**个体**（有时称为 **agents**）组成的：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-3.png)

An **individual** (or an **agent**) is a single _possible solution_ to given problem (a population is thus a set of some possible solutions).
>**个体**（或 **agent**）是一个单一的解决方案（因此，population 则是一些解决方案的集合）。

In our case, each individual will model a brain (or an entire bird, if you prefer to visualise it this way), but generally it depends on the problem you’re tackling:
>在我们的例子中，每个个体都将模拟一个大脑（或者是整只鸟，如果你能这样想的话），但这通常取决于你所处理的问题：

* If you were trying to, say, [evolve an antenna](https://en.wikipedia.org/wiki/Evolved_antenna), a single individual would be a single antenna.
* 比如说，如果你想[进化一根天线](https://en.wikipedia.org/wiki/Evolved_antenna)，那么一个个体就是一个天线。
* If you were trying to, say, [evolve a query plan](https://www.postgresql.org/docs/8.3/geqo-intro2.html), a single individual would be a single query plan.
* 例如，你正在尝试[演进一个查询计划](https://www.postgresql.org/docs/8.3/geqo-intro2.html)，单个个体将成为单个查询计划。

>* An individual represents some solution, but not necessarily the best or even a remotely desirable one.
>* 一个个体代表了某种解决方案，但不一定是最好的，甚至是不理想的。

An individual is built from **genes** (collectively named **genome**):
>个体由**基因**（统称为**基因组**）构成：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-4.png)

_Figure 7. A genome represented with neural network’s weights; a genome might be a list of numbers, a graph or anything else that is able to model a solution to the problem_
>图 7。用神经网络权值表示的基因组；基因组可能是一列数字、一张图表或任意能够为问题的解决方案提供建模的元素。


A **gene** is a single parameter that’s being evaluated and tuned by the genetic algorithm.
>基因是一个由遗传算法评估和调整的单一参数。

In our case, each gene will be simply a neural network’s weight, but representing problem’s domain isn’t always this straightforward.
>在我们的例子中，每个基因只是一个神经网络的权重，但表示问题的领域并不那么简单。

For instance, if you were trying to [help a fellow salesman](https://en.wikipedia.org/wiki/Travelling_salesman_problem), where the underlying problem isn’t based on neural networks at all, a single gene could be a tuple of `(x, y)` coordinates determining a part of a salesman’s journey (consequently, an individual would then describe a salesman’s entire path):
>例如，你正在试图[帮助一个推销员](https://en.wikipedia.org/wiki/Travelling_salesman_problem)，这种情况下，根本的问题不是基于神经网络，一个基因可能是一个 `(x, y)` 的元组坐标确定推销员的一部分路径（因此，整个个体则描述推销员的整个实体路径）：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-5.png)

_Figure 8. A hypothetical approach to the travelling salesman problem - each box represents a probable, suggested path for the salesman to travel_
_图 8. 推销员旅行问题的一个假设方法 —— 每个盒子代表推销员旅行的一个可能路径_

Now, let’s say we’ve got a random population of fifty birds - we pass them to a genetic algorithm, what happens?
>现在，假设我们有随机的 50 只鸟的种群，我们把它们传递给遗传算法，会发生什么？

Similarly as with selective breeding, genetic algorithm starts by **evaluating** each of the individuals (each of the possible solutions) to see which are the best among the current population.
>和选择性育种类似，遗传算法通过**评估**每个个体（每一个可能性）开始，看看当前种群中哪一个是最好的。

Biologically, this is an equivalent of taking a stroll to your garden and checking which carrots are the orangest and the yummiest.
>从生物学角度来说，这就相当于你在花园散步，看看哪种胡萝卜颜色最深，最美味。

Evaluation happens using so-called **fitness function** that returns a **fitness score** quantifying how good a particular individual (so a particular solution) is:
>使用所谓的**适应度函数*进行评估**，返回一个**适应度分数**来量化个体的特征（即一个特定的解决方案）的好坏：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-6.png)

_Figure 9. An example of a fitness function that quantifies carrots by their taproot’s color and radius_
_图 9。一个适应度函数的例子，通过胡萝卜主根的颜色和半径来量化胡萝卜的好坏_

Creating a [usable](https://www.youtube.com/watch?v=7J-DfS52bnI) fitness function is one of the hardest tasks when it comes to genetic algorithms, as usually there are many metrics by which an individual can be measured.
>当涉及到遗传算法时，创建一个[可用的](https://www.youtube.com/watch?v=7J-DfS52bnI)适应度函数是最困难的任务之一，因为通常有许多指标可以衡量一个个体。

(even our imaginative carrot has at least three metrics: taproot’s color, radius, and taste, that have to be squashed into a single number.)
>（即使是我们想象中的胡萝卜也至少有三个参数：主根的颜色、半径和味道，这些都必须压缩成一个数字表示。）

Fortunately, when it comes to birds, we don’t have much to choose from anyway: we’ll just say that a bird is as good as the amount of food it ate during the course of current **generation**.
>幸运的是，当涉及到鸟类时，我们没有太多选择：只能简单地说，一只鸟和它在生存期间所吃的食物数量一样好。

A bird who ate `30` foods is better than the one who ate just `20`, simple as that.
>吃 `30` 种食物的鸟比吃 `20` 种食物的鸟要好，就这么简单。

>* Negating a fitness function makes a genetic algorithm return the worst solutions instead of the best ones; just an amusing trick to remember for later.
>* 否定适应度函数会使遗传算法返回最坏的解而不是最好的解；只是一个有趣的规则，待会细说。

Now, the time has come for the genetic algorithm’s crème de la crème: **reproduction**!
>现在，是时候进入遗传算法 crème de la crème 的实现了：**繁殖**！

Broadly speaking, reproduction is the process of building a new (hopefully - slightly improved) population starting from the current one.
>广义地说，繁殖是在现有地种群基础上繁殖新的（希望 - 慢慢改善）个体的过程。

It’s the mathematical equivalent of choosing the tastiest carrots and planting their seeds.
>这在数学上相当于选择最美味的胡萝卜，然后，把它们的种子种下去。

What happens is that the genetic algorithm chooses two individuals at random (prioritizing the ones with the higher fitness scores) and uses them to produce two new individuals (a so-called **offspring**):
>主要发生的是，遗传算法随机选择两个个体（优先选择适应性得分较高的），并使用它们产生两个新的个体（所谓的**后代**）：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-7.png)

Offspring is produced by taking genomes of both parents and performing [crossover](https://en.wikipedia.org/wiki/Chromosomal_crossover) & [mutation](https://en.wikipedia.org/wiki/Mutation) on them:
>后代的产生是将双亲的基因组进行[交叉](https://en.wikipedia.org/wiki/Chromosomal_crossover)以及[突变](https://en.wikipedia.org/wiki/Mutation)：

![](https://pwy.io/resources/learning-to-fly-pt1/ga-8.png)

>* **Crossover** allows to mix two different gnomes to get an approximate in-between solution, while **mutation** allows to discover new solutions that weren’t present in the initial population.
>* **交叉**可以让两个不同的侏儒获得近似的中间解决方案，而**突变**可以得到种群尚未出现的新基因。

Both newly-spawned individuals are pushed into the pool of `new population` and the process starts over until the entire new population is built; the current population then gets discarded and the whole simulation starts over on this new (hopefully improved!) population.
>两个新产生的个体都会被放到 `new population` 中，然后重复这个过程，直到整个新种群形成；而现有的种群就会被淘汰，整个模拟过程又基于新的种群继续淘汰、生成。

As you can see, there’s a lot of **randomness** in the process: we start with a random population, we randomize how the genes are being distributed…​ so…​
>正如你看到的，在这个过程中有很多的随机性：我们从一个随机的种群开始，我们随机进行基因分布。。。所以。。。

this cannot actually work, can it?
>这实际上行不通，不是吗？

## The Code

Let’s end this post with a cliffhanger:
我们以一个悬念来结束这篇文章：

```shell
$ mkdir shorelark
```

Can you guess why I didn’t use `cargo new`?
>你能猜一猜，我为啥不用 `cargo new`？

In the second part we’ll implement a working, bare-bones feed-forward neural network - until then!
>在第二部分中，我们将实现一个可以工作的，基础的前馈神经网络 —— 到那时你就懂了！

## Sources

Here are some of the sources that I’ve personally found useful while learning about topics presented in this article:
>以下是我个人在学习本文的主题时发现的一些资料：

**神经网络：**
* [YouTube, 3Blue1Brown - 神经网络是什么？](https://www.youtube.com/watch?v=aircAruvnKk)
* [YouTube, Vsauce - Stilwell 大脑](https://www.youtube.com/watch?v=rA5qnZUXcqo)

**遗传算法：**

* [YouTube, Jeremy Fisher - 遗传算法](https://www.youtube.com/watch?v=7J-DfS52bnI)
* [obitko.com - 遗传算法教程](https://www.obitko.com/tutorials/genetic-algorithms/index.php)
* [Darrell Whitley - 一种遗传算法教程](https://ibug.doc.ic.ac.uk/media/uploads/documents/courses/GeneticAlgorithm-tutorial.pdf)
