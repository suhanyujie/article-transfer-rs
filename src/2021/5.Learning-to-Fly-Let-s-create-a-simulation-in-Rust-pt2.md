>* Learning to Fly: Let's simulate evolution in Rust! (pt 2) 译文（学习飞行：用 Rust 模拟种群进化 part2）
>* 原文链接：https://pwy.io/en/posts/learning-to-fly-pt2/
>* 原文作者：[Patryk27](https://github.com/Patryk27)
>* 译文来自：https://github.com/suhanyujie/article-transfer-rs/
>* 译者：[suhanyujie](https://github.com/suhanyujie)
>* 译者博客：[suhanyujie](https://ishenghuo.cnblogs.com/)
>* ps：水平有限，翻译不当之处，还请指正。
>* 标签：Rust, simulation,  genetic-algorithm, neural-network, rust, webassembly

This post is part of the **learning-to-fly** series:
>这篇文章是**学习飞行**系列的一部分：
* [The Domain (pt 1)](https://pwy.io/en/posts/learning-to-fly-pt1/)
* The Neural Network (pt 2)
* [The Genetic Algorithm (pt 3)](https://pwy.io/en/posts/learning-to-fly-pt3/)

This is second part of the **Learning to Fly** series in which we’re coding a simulation of evolution using **neural network** and **genetic algorithm**:
>这是**学习飞行**系列的第二篇，在这篇文章中，我们用代码实现模拟器的**神经网络**和**遗传算法**：

![](https://pwy.io/resources/learning-to-fly-pt1/intro-outcome.png)

图 1. https://pwy.io/en/projects/shorelark/

In this post we’ll lay the foundations for our project and implement a basic feed-forward neural network that’ll later become a brain; we’ll also take a look at many intricacies and idioms you might find in common Rust code, including those inside tests.
>在这篇文章中，我们会给项目做些东西奠定基础，并实现一个基本的前馈神经网络，之后，它会成为“大脑”的一部分；我们还会了解 Rust 代码中包括单元测试在内的一些复杂之处和惯用方法。

Strap your straps, seatbelt your seatbelts, and get ready for some coding!
>系好安全带，系好安全带，准备开始写代码吧！

## Workspaces

Our previous post ended with a cliffhanger:
>我们在上一篇文章以一个悬念结尾了：

Let’s end this post with a cliffhanger:
>这篇文章中我们来揭晓原因：

```
$ mkdir shorelark
```

Instead of launching `cargo new shorelark`, as one usually does, we went with `mkdir` - it’s because we’re going to use a feature of Cargo’s called [workspaces](https://doc.rust-lang.org/cargo/reference/workspaces.html).
>我们没有使用通用方法 `cargo new shorelark` 开始一个项目 ，而是使用 `mkdir` —— 这是因为我们要使用 Cargo 的 [workspaces](https://doc.rust-lang.org/cargo/reference/workspaces.html)。

Workspaces allow to split a single project into multiple, standalone crates (separate "subprojects"), which has many advantages:
>Workspaces 允许将一个项目拆分成多个独立的 crate（库、子项目），这样做有很多优点：

* it makes it easier for humans to reason about project’s structure (as each crate is more or less self-contained),
* 它能让我们更容易推断出项目的结构（因为每个 crate 或多或少都是独立的），
* it’s easy to setup & extend (crates can be kept in the same repository or scattered across different ones, whatever’s more convenient for you),
* 它更容易配置和扩展（crate 可以保存在相同的仓库中，也可以分散在不同的仓库中，无论怎样都会更便利），
* it allows for Cargo to compile project’s code **in parallel**.
* 它可以让 Cargo **并行**编译代码。

Let’s focus on the last point.
>我们看看最后一个优点：

You might’ve noticed that when you do `cargo build`, it sometimes prints crate names inline during the `Building` phase:
>你可能已经注意到，当你运行 `cargo build` 时，在 `Building` 阶段有时会打印很多 crate 的名称：

```
Updating crates.io index
 Downloaded log v0.4.13
 Downloaded serde v1.0.119
 Downloaded thread_local v1.1.0
 Downloaded byteorder v1.4.2
  Compiling libc v0.2.82
  Compiling cfg-if v1.0.0
  Compiling arrayref v0.3.6
  Compiling matches v0.1.8
   Building [>           ] 6/153: byteorder, matches, cc, byte-tools
```

It means that it’s building those crates **in parallel**.
>这意味着它在**并行地**构建 crate

Usually only some parts of the **dependency tree** can be built in parallel - if you have crate `A` that depends on crates `B` + `C`, the latter two can be built at the same time, but `A` has to wait until `B` and `C` have both finished compiling.
>一般情况下，只有部分依赖可以并行构建 —— 如果你的项目依赖于 `B` + `C`，但 `A` 又必须等 `B` 和 `C` 都构建完成才能编译。

Furthermore, it’s pointless trying to simultaneously compile more crates than the amount of CPU cores available, as it would only slow down the process, so Cargo has a tall order figuring it out.
>此外，试图同时编译比 CPU 核数更多的 crate 是没有意义的，这只会减慢过程，所以 Cargo 需要解决这个问题。

On the other side of the spectrum, we’ve got rustc - it’s the actual compiler that Cargo invokes for each crate it has to built, and rustc itself is at the moment [mostly single-threaded](https://pingcap.com/blog/rust-huge-compilation-units).
>另一方面，我们又 rustc —— 它才是构建 crate 时的实际使用的编译器，而  rustc 本身目前是[单线程的](https://pingcap.com/blog/rust-huge-compilation-units)。

It means that, practically, if your application depends on some external crates (e.g. from `crates.io`), those crates will be compiled in parallel, but your application itself (as a single-crate entity) will remain built on a single core.
>这意味着，实际上如果你的应用程序依赖于一些三方的 crate（例如，来自 `crates.io`），这些 crate 将被并行编译，但你的应用程序本身（作为一个单独的 crate）仍然会在这个单核心上编译。

To internalize the potential issues & gains, let’s say we’re working on a 100k LOC application - if compiling our app, excluding its dependencies, takes 5 minutes now, then by splitting it into 5 separate 20k LOC crates, we might reduce this time to as low as 1~2 minutes.
>为了解决这些潜在的问题和目标，假设我们正在处理一个 100k LOC 的应用程序 —— 如果编译我们的应用程序，不包含它的依赖，现在只需 5 分钟，然后我们将它拆分成 5 个单独的 20k LOC crate，我们可以将这个时间减少到 1~2 分钟。

_(due diligence: that’s a good-day scenario, sometimes it might not be possible to split the code, please remember to always consult your doctor before refactoring.)_

_调查显示：这是个很不错的方法，但有时候代码很难拆分，所以重构前记得咨询经验丰富的专家_

Granted - in the grand scheme of things, 3 minutes might not seem like much, but let’s not forget that it applies to the development process, too.
>当然，在大型项目中，3 分钟可能看起来九牛一毛，但不要忘记它也适用于开发过程中。

If you’ve already had the pleasure of working on a gigantic project, you might know the pain of [waiting for the compiler to finish](https://xkcd.com/303/): you’ve changed some error message, wanted to quickly see how it looks in the context and - ｏｈ ｇｏｄ - do you hear this sound? it’s not a military aircraft, it’s your computer’s fans preparing for some hot & long code munching; it’s daunting.
>如果你已经有幸参与过大型项目，你可能知道这种痛[等待编译完成](https://xkcd.com/303/)：你已经修改了一些错误信息，然后想要在上下文中快速查看结果 —— 但是，天哪 —— 你听到了吗？这不是一架军用飞机在响，而是你的电脑伙伴在长时间地高速地编译代码；这很令人敬畏。

When it comes to Rust, one of the ways to alleviate issues around compile times is then to simply split your application into separate crates.
>说到 Rust，有一种减轻编译时间问题的方法是将应用程序简单地分割到多个单独的 crate 中。

One of the bigger - if not the biggest - workspace-based project I know is the almighty [rustc](https://github.com/rust-lang/rust/tree/master/compiler).
>一个适用于更大项目的方法（没有最大） —— 基于 workspace 的项目，我知道 [rustc](https://github.com/rust-lang/rust/tree/master/compiler) 。 

Considering our toy project won’t reach 10k LOC, why am I even talking about all those workspaces and crates?
>考虑到我们的实验项目不会达到 10k LOC，那为啥我还要讨论这些关于 workspaces 和 crate 的问题呢？

[I just think they’re neat.](https://www.youtube.com/watch?v=J2eud_tEIj8)
>[我只是觉得它们很棒。](https://www.youtube.com/watch?v=J2eud_tEIj8)

Also, I consider them to be a **good practice**: workspaces allow to introduce clear-cut boundaries between project’s modules, and - when applied within reason - not only make the code cleaner, but force it to be.
>此外，我认为这是一个**好的实践**：workspaces 可以让项目之间的边界更加清晰，并且合理地使用它时，不必过于约束就会让代码干净整洁。

Having established that workspaces are not elder magic, let’s circle back to our original question: why `mkdir` instead of `cargo new`?
>既然 workspaces 不是魔法，那让我们回到最初的问题：为什么使用 `mkdir` 而非 `cargo new`？

Simply because [Cargo doesn’t support `cargo new --workspace` yet](https://github.com/rust-lang/cargo/issues/8365).
>仅仅是因为 [Cargo 还不支持 `cargo new --workspace`](https://github.com/rust-lang/cargo/issues/8365)。

## Structure

Breath in, breath out, and let’s enter the no man’s land:
>吸气，呼气，我们进入还没涉及的地方：

```
$ cd shorelark
$ ls -al
# total 0
# drwxr-xr-x  2 ppp users  40 01-16 19:14 .
# drwxrwxrwt 22 ppp users 520 01-16 20:27 ..
```

Before we’re able to write our first line of code, we have to decide on our project’s structure.
>在开始写代码之前，我们先确定项目的结构。

There are many approaches for organizing workspace-based projects - I’m personally fond of this one, which separates application-like crates from those library-like ones:
>有很多方法可以组织基于 workspace 项目的目录 —— 我个人喜欢这种，它可以将库分离成多个 crate 应用：

```
project
├─ Cargo.toml
├─ app
│  ├─ Cargo.toml
│  └─ src
│      └─ main.rs
└─ libs
   ├─ subcrate-a
   │  ├─ Cargo.toml
   │  └─ src
   │     └─ lib.rs
   └─ subcrate-b
      ├─ Cargo.toml
      └─ src
         └─ lib.rs
```

Another popular approach is to simply dump all crates into the same directory called e.g. `src` or `crates`.
>还有另一种常用方法是简单地将所有的 crate 存储到同一个目录下，如 `src` 或者 `crates` 目录下。 

Scaffolding such project is as easy as creating a `Cargo.toml` manifest with:
>搭建这样的项目就如创建下面的 `Cargo.toml` 清单一样简单：

```
[workspace]
members = [
    "libs/*", # look má, wildcards!
]
```

Most manifests contain a section called `[package]` that defines crate’s metadata:
>大部分清单都包含一个名为 `[package]` 的部分，它下面定义了一些 crate 的元数据：

```
[package]
name = "brexit-loss-calculator"
version = "0.0.0"
authors = ["B.J."]
edition = "2018"
```

Our `Cargo.toml` does not, as it’s used to merely group all the packages together without being a crate on its own; formally speaking, our `Cargo.toml` is a [virtual manifest](https://doc.rust-lang.org/cargo/reference/workspaces.html#virtual-manifest).
>而我们的 `Cargo.toml` 不是这样，因为它会把多个包放在一起，而非单独的一个 crate；正式的说，我们的 `Cargo.toml` 是一种[虚拟的清单](https://doc.rust-lang.org/cargo/reference/workspaces.html#virtual-manifest)。

... and then proceeding with `cargo new --lib` as usual:
> ... 然后就是像往常一样使用 `cargo new --lib`：

```
$ mkdir libs
$ cd libs
$ cargo new neural-network --lib
```

## Coding: `propagate()`

It’s time to get down to business.
>是时候做点正事了。

We’ll start **top-down**, with a structure modelling the entire network - it will provide sort of an **entry point** to our crate; let’s open `libs/neural-network/src/lib.rs` and write:
>我们将**自上而下**开始，用一个结构建模整个神经网络 - 它将给我们的 crate 提供**入口**；我们先打开 `libs/neural-network/src/lib.rs` 文件开始写代码：

```rust
pub struct Network;
```

A neural network’s most crucial operation is propagating numbers:
>神经网络最关键的操作是传播数字：

![](https://pwy.io/resources/learning-to-fly-pt2/coding-propagate-1.svg)

... 所以:

```rust
impl Network {
    pub fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        todo!()
    }
}
```

While some languages allow to leave "work-in-progress" functions empty:
>虽然有些语言允许 "work-in-progress" 空函数的存在：

```
int get_berry_number() {
    // TODO solve the paradox
}
```

... an equivalent code in Rust does not compile:
>。。。Rust 中写类似的代码则不能编译：

```rust
fn berry_number() -> usize {
    // TODO solve the paradox
}
```

```
error[E0308]: mismatched types
 --> src/lib.rs
  |
1 | fn berry_number() -> usize {
  |    ------------      ^^^^^ expected `usize`, found `()`
  |    |
  |    implicitly returns `()` as its body has no tail or `return`
  |    expression
```

It’s due to the fact that almost everything in Rust is an expression:
>这是因为 Rust 几乎所有的内容都能以表达式的方式存在：

```rust
let value = if condition {
    "computer says yass"
} else {
    "computer says no"
};

let value = loop {
    break 123;
};

let value = {
    // empty block is an expression, too
};
```

... and so the way Rust sees that function is actually:
>... 所以 Rust 中的函数实际上是这样的：

```rust
fn berry_number() -> usize {
    return ();
}
```

... with `()` being called [unit value](https://doc.rust-lang.org/std/primitive.unit.html) (or `unit type`, depending on the context).
>`()` 代表[单元值](https://doc.rust-lang.org/std/primitive.unit.html)（或者 `unit type`，取决于场景）。

To answer the problem of but i really don’t know how this function should look like just yet, Rust provides two macros: `todo!()`, and its older cousin - `unimplemented!()`.
>为了回答这个问题，要回答这个问题，但我真不知道函数应该定义成什么样子，Rust 提供了两个宏 `todo!()`，和它的“表兄” - `unimplemented!()`。

Both macros allow for the code to be compiled and, when encountered during runtime, cause the application to safely crash:
>这两个宏可以通过编译，而当代码运行时，会崩溃。

```
thread 'main' panicked at 'not yet implemented'
```

Similarly to an ocean filled with water droplets, a network is built from layers:
>就像海洋中的水滴一样，一个神经网络是由多个层（layer）组成的：

![](https://pwy.io/resources/learning-to-fly-pt2/coding-propagate-2.svg)

... so:

```rust
pub struct Network {
    layers: Vec<Layer>,
}

struct Layer;
```

Layers are built from neurons:
>各个“层”由神经元构成：

![](https://pwy.io/resources/learning-to-fly-pt2/coding-propagate-3.svg)

... 所有可以将 Layer 进行如下定义:

```rust
struct Layer {
    neurons: Vec<Neuron>,
}
```

Eventually, neurons contain biases and **output** weights:
>最终，神经元包含偏差和**输出**权重，如下所示：

![](https://pwy.io/resources/learning-to-fly-pt2/coding-propagate-4.svg)

... 所以有:

```rust
struct Neuron {
    bias: f32,
    weights: Vec<f32>,
}
```

Let’s see our crude design in its entriety:
>来看看原始设计的入口：

```rust
pub struct Network {
    layers: Vec<Layer>,
}

struct Layer {
    neurons: Vec<Neuron>,
}

struct Neuron {
    bias: f32,
    weights: Vec<f32>,
}

impl Network {
    pub fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        todo!()
    }
}
```

很棒。

If you’re lucky or perceptive, you might’ve noticed that only two of our objects are public: `Network` and `Network::propagate()` - it’s because `Layer` and `Neuron` will remain an **implementation detail**, we won’t expose them outside.
>如果你足够幸运或拥有足够的洞察力，你可能已经注意到只有两个对象是公开的：`Network` 和 `Network::propagate()` - 这是因为 `Layer` 和 `Neuron` 仍然是一个**具体实现**，我们不会将它们暴露出去。

Thanks to this approach, we’ll be able to introduce changes to our implementation without imposing breaking changes on the **downstream** crates (i.e. our library’s users).
>多亏了这种方法，我们将能够在不影响**下游**的情况下修改实现（如库的用户）

For instance, professional neural networks (for performance reasons) are usually implemented using [matrices](https://towardsdatascience.com/diy-ai-an-old-school-matrix-nn-401a00021a55) - if we ever decided to rewrite our network to use matrices, then it wouldn’t be a breaking change: `Network::propagate()`-s signature would remain the same and since users can’t access `Layer` and `Neuron`, they wouldn’t be able to notice these two structs being gone.
>例如，专业的神经网络（由于性能原因）通常使用 [matrices](https://towardsdatascience.com/diy-ai-an-old-school-matrix-nn-401a00021a55) 来实现 —— 如果我们决定使用 matrices 重构我们的网络，那么这不算是一个破坏性的修改：`Network::propagate()` —— 主要函数签名保持不变，并且由于用户无法访问 `Layer` 和 `Neuron`，因而他们不会感觉到这两个结构体的不见了。

Going next - since numbers have to be shoved through each layer, we’ll need to have a `propagate()` in there, too:
>接下来 —— 由于数字必须传递到每一层，同时，我们也需要 `propagate()` 方法：

```rust
impl Layer {
    fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        todo!()
    }
}
```

Having `Layer::propagate()`, we can actually go back and implement `Network::propagate()`:
>有了 `Layer::propagate()`，我们实际上可以返回并实现 `Network::propagate()`：

```rust
impl Network {
    fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        let mut inputs = inputs;

        for layer in &self.layers {
            inputs = layer.propagate(inputs);
        }

        inputs
    }
}
```

This is quite a satisfying, correct piece of code - but it’s also **non-idiomatic**: we can write it better, more **rustic**; let’s see how!
>这是一段令人满意的、正确的代码 —— 但也是**不常见**的方法：我们可以写的更好、更简练；我们来看看！

![](https://pwy.io/resources/learning-to-fly-pt2/coding-propagate-5.svg)

_Figure 2. Ecstasy of Saint Ferris (upon seeing idiomatic code), colorized_
_图 2. Saint Ferris 的狂喜（看到惯用的代码），颜色_

First of all, this is called a **rebinding** (or shadowing):
>首先，这被称为**重新绑定**（或 shadowing）：

```rust
let mut inputs = inputs;
```

... and it’s unnecessary, because we might as well move this `mut` into function’s parameters:
>...可以不必这样写，因为我们可以将这个 `mut` 移到函数的形参中：

```rust
fn propagate(&self, mut inputs: Vec<f32>) -> Vec<f32> {
    for layer in &self.layers {
        inputs = layer.propagate(inputs);
    }

    inputs
}
```

But hey, won’t this force our _callers_ to pass mutable values? Nope!
>但是，这不会强制 _调用者（caller）_ 传递可变的值？不！

```rust
fn process(mut items: Vec<f32>) {
    // do something
}

fn main() {
    let items = vec![1.2, 3.4, 5.6];
    // ^ no `mut` needed here

    process(items);
    //      ^ just works
}
```

[(playground link)](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=945c2c2852ccbeb143ea569747038626)

The reasoning is that the `mut` we’ve just introduced appears in so-called **binding** position:
>原因是 `mut` 出现在名为 **binding** 的位置：

```rust
fn foo_1(items: &[f32]) {
    //   ^^^^^  ------
    //  binding  type
    // (immut.) (immut.)
}

fn foo_2(mut items: &[f32]) {
    //   ^^^^^^^^^  ------
    //    binding    type
    //   (mutable) (immut.)
}

fn foo_3(items: &mut [f32]) {
    //   ^^^^^  ----------
    //  binding    type
    // (immut.)  (mutable)
}

fn foo_4(mut items: &mut [f32]) {
    //   ^^^^^^^^^  ----------
    //    binding      type
    //   (mutable)   (mutable)
}

struct Person {
    name: String,
    eyeball_radius: usize,
}

fn decompose(Person { name, mut eyeball_radius }: Person) {
    //       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  ------
    //                     binding                 type
    // (partially immutable, partially mutable) (immutable)
}
```

... and bindings, contrary to types, are **local** to a function:
>。。。和类型相反，函数中的 bindings 是**局部**的：

```rust
fn foo(items: &mut Vec<usize>) {
    // When a type is mutable, you can modify the thing being
    // referenced:
    items.push(1234);

    // But if the binding remains immutable, you cannot modify
    // *which* thing is referenced:
    items = some_another_vector;
    //    ^ error: cannot assign to immutable argument
}

fn bar(mut items: &Vec<usize>) {
    // On the other hand, when a binding is mutable, you can change
    // *which* thing is referenced:
    items = some_another_vector;

    // But if the type remains immutable, you cannot modify the
    // thing itself:
    items.push(1234);
    //   ^^^^^ error: cannot borrow `*items` as mutable, as it is
    //         behind a `&` reference
}
```

There’s one more refinement we can apply to our code - this very pattern is known as **folding**:
>我们还有另一种方法优化代码 —— 这种模式叫做**折叠**（folding）： 

```rust
for layer in &self.layers {
    inputs = layer.propagate(inputs);
}
```

... and Rust’s standard library provides a dedicated function for it:
>。。。而 Rust 标准库也提供了这个方法：

```rust
fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
    self.layers
        .iter()
        .fold(inputs, |inputs, layer| layer.propagate(inputs))
}
```

_(one could argue whether our final code is actually more readable or less; while I’m personally fond of the built-in combinators such as `.fold()`, if you find them obscure - that’s fine, too! you do you, i ain’t no judge)_
_（有人可能会争论，我们最后的代码是更易读哥还是不易读；虽然我个人也不喜欢内置的 `.fold()` 组合调用，如果你觉得它们有点晦涩难懂——这也没关系！用你自己喜欢的方式，我不会强迫你）_

Voilà - after all, thanks to the closure, we didn’t even need that `mut inputs`; now you can brag about your code being all functional and Haskell-y.
>Voilà - 毕竟，多亏了这个闭包，我们都可以不用 `mut inputs` 了；现在，你可以吹嘘你的代码都是功能性的或者 Haskell-y。 

Let’s move on to neurons - a single neuron accepts many inputs and returns a single output, so:
>我们看看神经元 —— 单个神经元接收多个输入并且有一个输出，如下所示：

```rust
struct Neuron {
    bias: f32,
    weights: Vec<f32>,
}

impl Neuron {
    fn propagate(&self, inputs: Vec<f32>) -> f32 {
        todo!()
    }
}
```

As before, we can backtrack to implement `Layer::propagate()`:
>和之前一样，无码可以通过回溯来实现 `Layer::propagate()`：

```rust
struct Layer {
    neurons: Vec<Neuron>,
}

impl Layer {
    fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        let mut outputs = Vec::new();

        for neuron in &self.neurons {
            let output = neuron.propagate(inputs);
            outputs.push(output);
        }

        outputs
    }
}
```

If we try to compile it, we get our first borrow-checker failure:
>如果你试着编译它，会得到借用检查器返回的错误：

```
error[E0382]: use of moved value: `inputs`
  --> src/lib.rs
   |
   |     fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
   |                         ------ move occurs because `inputs` has
   |                                type `Vec<f32>`, which does not
   |                                implement the `Copy` trait
...
   |             let output = neuron.propagate(inputs);
   |                                           ^^^^^^
   |                                value moved here, in previous
   |                                iteration of loop
```

Obviously, the compiler is right: after invoking `neuron.propagate(inputs)`, we lose ownership of `inputs`, so we can’t possibly use it inside loop’s consecutive iterations.
>很明显，编译器总是对的：在调用 `neuron.propagate(inputs)` 之后，我们在当前作用域内就失去了 `inputs` 的所有权，所以我们不可能在循环中进行连续迭代调用。

Fortunately, the fix is rather easy and boils down to making `Neuron::propagate()` work on **borrowed** values:

```rust
impl Layer {
    fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        /* ... */

        for neuron in &self.neurons {
            let output = neuron.propagate(&inputs);
            //                            ^
        }

        /* ... */
    }
}

impl Neuron {
    fn propagate(&self, inputs: &[f32]) -> f32 {
        //                      ^^^^^^
        /* ... */
    }
}
```

To reiterate, the code we have at the moment is:
>重申一下，目前我们的代码如下所示：

```rust
impl Layer {
    fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
        let mut outputs = Vec::new();

        for neuron in &self.neurons {
            let output = neuron.propagate(&inputs);
            outputs.push(output);
        }

        outputs
    }
}
```

The way we wrote our algorithm is correct, but inefficient - since we know how many output values we’ll have, we can use this information to **preallocate** our vector:
>我们写的算法是正确的，但效率低下 —— 因为我们知道有多少输出值，我们可以使用这个信息把 vector 进行**预分配**：

```rust
fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
    let mut outputs = Vec::with_capacity(self.neurons.len());

    /* ... */
}
```

In order to understand preallocation, we’ve gotta go one abstraction layer below and take a look at how `Vec` works.
>为了理解预分配，我们深入到下一个抽象层面，看看 `Vec` 是如何工作的。

Since `Vec` doesn’t know how many elements it will contain, it starts empty and then every other invocation of `.push()` causes it to **grow** larger and larger. Growing is a "relatively slow" operation, because it requires for the vector’s entire memory to be moved into another place in RAM that contains enough space.
>由于 `Vec` 不知道它将又多少个元素，它一开始是空的，然后每次调用 `.push()` 会导致它“增长”。虽然增长是一个“相对缓慢”的操作，因为它需要将 vector 的整个内存移动到内存中的另一个区域。 

If we know - or we can estimate - a vector’s size up-front, we might then create it using `Vec::with_capacity()`, which accepts a single argument determining how big the returned vector should be; e.g. `Vec::with_capacity(10)` means that you’ll be able to use `.push()` at least 10 times without causing the returned vector to grow.
>如果我们知道 —— 或者可以估计 —— vector 的大小，我们可以使用 `Vec::with_capacity()` 来创建数组，它接受一个参数来确定返回的 vector 应该多大；例如：`Vec::with_capacity(10)` 表示你可以调用 `.push()` 至少 10 次而不会导致数组的扩容。

>`Vec::with_capacity()` can be a great low-hanging fruit if your application allocates lots of large vectors, but using it is not always worth the hassle; as usually when it comes to performance, a benchmark’s your best friend.

>如果你的程序中用了很多大的数组，那么多使用 `Vec::with_capacity()` 会是一个很好的优化目标，但它也不是能解决所有这类问题，在性能方面，多使用基准测试，它会是你的好朋友。

Using with_capacity() might be awkward at times and so Rust, fulfilling its promise of zero-cost abstractions, allows to invoke it somewhat transparently:
>使用 with_capacity() 可能有时候会尴尬，因此 Rust 实现了其零成本抽象的承诺，这样可以在一定程度上更容易使用。

```rust
fn propagate(&self, inputs: Vec<f32>) -> Vec<f32> {
    self.neurons
        .iter()
        .map(|neuron| neuron.propagate(&inputs))
        .collect()
}
```

There’s no explicit `Vec::with_capacity()` and yet both codes do essentially the same (including preallocation!) - how come?
>没有显式的调用 `Vec::with_capacity()`，但两种代码本质上是一样的（包括预分配） —— 为什么？

Well, iterators contain a method called `Iterator::size_hint()` - it returns an iterator’s length (or `None`, if the length’s not known). When you do `vec.iter()`, it simply creates an iterator that knows its length and then `.collect()` uses that information to automatically create a vector that’s large enough; no magic!
>迭代器包含一个方法 `Iterator::size_hint()` —— 它返回迭代器的长度（如果长度未知，则返回 `None`）。当你使用 `vec.iter()` 时，它只是创建一个已知其长度的迭代器，然后调用 `.collect()` 自动创建一个足够大的 vector；没有黑魔法！

As you can see, even though our refactored code is technically more complex (we’re using an anonymous function and iterators, after all), it’s at least equally performant and way more readable; writing optimized Rust code frequently cuts down to using high-level structures instead of trying to outsmart the compiler with fancy, hand-written loops.
>正如你看到的，尽管我们的代码重构在技术上变复杂了（毕竟使用了匿名函数和迭代器），但它至少具备了同样的性能，而且可读性更强；编写优化的 Rust
 代码常常是使用高级结构，而不是试图用奇特的、手写循环来征服编译器。

Currently we’ve got nowhere else to go, but to complete `Neuron::propagate()` - as before, let’s start with a crude, [superfund](https://en.wikipedia.org/wiki/Superfund)-ish version:
>目前，我们除了完成 `Neuron::propagate()` 之外，也没有其他可做的了。和以前一样，我们先从一个简略的[超级基金](https://en.wikipedia.org/wiki/Superfund) 开始 —— ish 版本。

```rust
impl Neuron {
    fn propagate(&self, inputs: &[f32]) -> f32 {
        let mut output = 0.0;

        for i in 0..inputs.len() {
            output += inputs[i] * self.weights[i];
        }

        output += self.bias;

        if output > 0.0 {
            output
        } else {
            0.0
        }
    }
}
```

This snippet contains two unidiomatic constructs and one potential bug - let’s start with the latter.
>这个代码片段包含两个非惯用结构和一个潜在的错误 —— 我们先从后者开始。

Since we’re iterating through `self.weights` using length of `inputs`, there are three edge cases we have to consider:
>因为我们根据 `inputs` 的长度迭代 `self.weights`，有三种边界情况必须考虑：
* 1.考虑 `inputs.len() < self.weights.len()`,
* 2.考虑 `inputs.len() == self.weights.len()`,
* 3.考虑 `inputs.len() > self.weights.len()`.

Our code lays on the assumption that #2 is **always true**, but it’s a **silent** assumption: we don’t enforce it anywhere! If we mistakenly passed less or more inputs, we’d get either an invalid result or a crash.
>我们的代码建立在 #2 **是正确**的基础上，但这是一个**单方面**的假设：我们不会在任何地方强制执行它！如果错误地传递了更少或更多的输入，我们会得到一个无效的结果，程序也有可能崩溃。

There are at least two ways we could go around improving it:
>至少有两种方法可以改进它：

* 1.We could change `Neuron::propagate()` to return an error message:
>* 1.我们可以调整 `Neuron::propagate()` 来返回一个错误消息：

```rust
fn propagate(&self, inputs: &[f32]) -> Result<f32, String> {
    if inputs.len() != self.weights.len() {
        return Err(format!(
            "got {} inputs, but {} inputs were expected",
            inputs.len(),
            self.weights.len(),
        ));
    }

    /* ... */
}
```

... or, using one of the crates I love the most - [thiserror](https://github.com/dtolnay/thiserror):
>。。。或者，使用我最喜欢的 crate ——  [thiserror](https://github.com/dtolnay/thiserror)：

```rust
pub type Result<T> = std::result::Result<T, Error>;

#[derive(Debug, Error)]
pub enum Error {
    #[error(
        "got {got} inputs, but {expected} inputs were expected"
    )]
    MismatchedInputSize {
        got: usize,
        expected: usize,
    },
}

/* ... */

fn propagate(&self, inputs: &[f32]) -> Result<f32> {
    if inputs.len() != self.weights.len() {
        return Err(Error::MismatchedInputSize {
            got: inputs.len(),
            expected: self.weights.len(),
        });
    }

    /* ... */
}
```

* 2.We could use the `assert_eq!()` / `panic!()` macros:
>* 2.我们可以使用 `assert_eq!()` / `panic!()` 宏：

```rust
fn propagate(&self, inputs: &[f32]) -> f32 {
    assert_eq!(inputs.len(), self.weights.len());

    /* ... */
}
```

In most cases, the first variant is better, because it allows for the caller to **catch** the error and **handle** it - in our case though, the error reporting is simply not worth it, because:
>在大多数情况下，第一个变体更好，因为它允许调用者**捕获**错误并且**处理**它 —— 尽管在我们的情况下，报错可能不太合适，因为：

* 1.If this assertion ever fails, it means that our implementation is most likely wrong and there’s nothing users could do on their side to mitigate it.
>* 1.如果这个断言失败了，那就意味者我们的实现很可能是错误的，用户无法采取任何措施来避免它。
* 2.This is a toy project, we’ve already got like fifty other ideas hanging in the air tonight, no need to waste our time.
>* 2.这是一个玩具项目，今晚我们已经大概有其他 50 个想法还未实现，没有必要再浪费时间了。

所以：

```rust
fn propagate(&self, inputs: &[f32]) -> f32 {
    assert_eq!(inputs.len(), self.weights.len());

    let mut output = 0.0;

    for i in 0..inputs.len() {
        output += inputs[i] * self.weights[i];
    }

    output += self.bias;

    if output > 0.0 {
        output
    } else {
        0.0
    }
}
```

As for the idioms - this one:
>对于这个惯用法：

```rust
if output > 0.0 {
    output
} else {
    0.0
}
```

... is [`f32::max()`](https://doc.rust-lang.org/stable/std/primitive.f32.html#method.max) in disguise:
>。。。就是隐式地调用 [`f32::max()`](https://doc.rust-lang.org/stable/std/primitive.f32.html#method.max)：

```
output.max(0.0)
```

While this one:
>当我们这样写：

```rust
let mut output = 0.0;

for i in 0..inputs.len() {
    output += inputs[i] * self.weights[i];
}
```

... can be simplified first with `.zip()`:
>。。。用 `.zip()` 可以简化很多：

```rust
let mut output = 0.0;

for (&input, &weight) in inputs.iter().zip(&self.weights) {
    output += input * weight;
}
```

Array-indexing operations (such as `inputs[i]`) always perform a so-called **bounds check** - it’s a piece of code that ensures index lays within array bounds, panicking when it’s too big:
>数组索引操作（比如 `inputs[i]`）总是会进行 **bounds check** —— 这样能确保索引值总是在合法的边界内，如果过大，则会发生 panic：

```rust
fn main() {
    let numbers = vec![1];
    println!("{}", numbers[123]);
}
```

```
thread 'main' panicked at 'index out of bounds: the len is 1 but
the index is 123'
```

When instead of indexing, you use combinators such as `.zip()` or `.map()`, you make it easier for the compiler to remove overzealous bound checks, making your code a bit faster.
>如果不进行索引，而是使用 `.zip()` 或者 `.map()` 这样的组合，编译器则能更容易地去除 bound check，从而使性能提升。

Another point for higher-level code!
>另一点就是高阶代码！

... and then using `.map()` + `.sum()`:
>。。。然后使用 `.map()` + `.sum()`：

```rust
let output = input
    .iter()
    .zip(&self.weights)
    .map(|(input, weight)| input * weight)
    .sum::<f32>();
```

>The `::<>` syntax used in the last line is called [turbofish](https://techblog.tonsser.com/posts/what-is-rusts-turbofish) - it allows to provide explicit generic arguments when the compiler has troubles inferring them.

>在最后一行中使用的 `::<>` 语法叫做 [turbofish](https://techblog.tonsser.com/posts/what-is-rusts-turbofish) —— 它可以在编译器推断时提供显式的泛型参数。

也就是：

```rust
impl Neuron {
    fn propagate(&self, inputs: &[f32]) -> f32 {
        let output = inputs
            .iter()
            .zip(&self.weights)
            .map(|(input, weight)| input * weight)
            .sum::<f32>();

        (self.bias + output).max(0.0)
    }
}
```

It’s unquestionably beautiful - but **does it work**? Can it recognize a cat? Can we use it to predict future Dogecoin prices?
>毫无疑问，这很简洁 —— 但代码**真的有用吗**？可以用它识别出猫吗？它是否可以用来预测未来狗狗币的价格呢？

## Coding: `new()`
Up to this point we were focused so much on the algorithm that we gave little to no thought to **contructors** - but how could we ever play with a network we cannot create?

Our first approach for creating a constructor could be a plain, no-op(no-operation, i.e. doing nothing) function of:

```rust
pub struct Network {
    layers: Vec<Layer>,
}

impl Network {
    pub fn new(layers: Vec<Layer>) -> Self {
        Self { layers }
    }
}
```

... which won’t do in this case, because - as we’ve already established - we’d like to keep `Layer` and `Neuron` outside the public interface.

If you recall our previous post, you might remember that we were talking a lot about random numbers - so if there’s one thing I’m certain, it’s that we’ll need something in the lines of:

```rust
impl Network {
    pub fn random() -> Self {
        todo!()
    }
}
```

In order to randomize a network, we’ll need to know the number of its layers and number of neurons per each layer - they all can be described with a single vector:

```rust
pub fn random(neurons_per_layer: Vec<usize>) -> Self {
    todo!()
}
```

... or, in a bit more elegant way:

```rust
pub struct LayerTopology {
    pub neurons: usize,
}

/* ... */

pub fn random(layers: Vec<LayerTopology>) -> Self {
    todo!()
}

// By the way, notice how creating a separate type allowed us to
// untangle argument's name to be just `layers`.
//
// Initially we went with `neurons_per_layer`, because `Vec<usize>`
// doesn't provide enough information to tell what this `usize`
// represents - using a separate type makes the intention explicit.
```

Now, if you look real close at a neural network’s layer:

![](https://pwy.io/resources/learning-to-fly-pt2/coding-new-1.svg)

... perhaps you’ll notice that it’s actually defined by **two** numbers: its input and _output_ size; does it mean our single-field `LayerTopology` is wrong? Au contraire!

What we’ve done is, as I like to call it, **exploiting domain knowledge**.

Inside a FFNN, all layers are connected consecutively, back-to-back:

![](https://pwy.io/resources/learning-to-fly-pt2/coding-new-2.svg)

... because layer A’s output is layer B’s input, **if** we went with:

```rust
pub struct LayerTopology {
    pub input_neurons: usize,
    pub output_neurons: usize,
}
```

... not only would we make our interface unwieldy, but - what’s even more gruesome - we’d have to implement an additional validation ensuring that `layer[0].output_neurons == layer[1].input_neurons`, and so on, are met; pure nonsense.

Noting this simple fact that consecutive layers must have matching inputs & outputs allows us to simplify the code before it’s been even written!

As for the implementation, a naïve, unidiomatic approach could be:

```rust
pub fn random(layers: Vec<LayerTopology>) -> Self {
    let mut built_layers = Vec::new();

    for i in 0..(layers.len() - 1) {
        let input_neurons = layers[i].neurons;
        let output_neurons = layers[i + 1].neurons;

        built_layers.push(Layer::random(
            input_neurons,
            output_neurons,
        ));
    }

    Self { layers: built_layers }
}
```

Now, let’s rustify it! Care to guess what happens when you call `Network::random(vec![])`?

```rust
pub fn random(layers: Vec<LayerTopology>) -> Self {
    // Network with just one layer is technically doable, but doesn't
    // make much sense:
    assert!(layers.len() > 1);

    /* ... */
}
```

There, better.

As for the `for` loop - iterating by adjacent items is another pattern covered by the Rust’s standard library, via function called [`.windows()`](https://doc.rust-lang.org/stable/std/primitive.slice.html#method.windows):

```rust
pub fn random(layers: Vec<LayerTopology>) -> Self {
    /* ... */

    for adjacent_layers in layers.windows(2) {
        let input_neurons = adjacent_layers[0].neurons;
        let output_neurons = adjacent_layers[1].neurons;

        built_layers.push(Layer::random(
            input_neurons,
            output_neurons,
        ));
    }

    /* ... */
}
```

If you know a thing or two about [destructuring](https://doc.rust-lang.org/book/ch18-03-pattern-syntax.html#destructuring-to-break-apart-values), you might’ve thought of rewriting this loop even further:

```
for [fst, snd] in layers.windows(2) {
    built_layers.push(Layer::random(fst.neurons, snd.neurons));
}
```

_(`fst` and `snd` are typical to the functional world where they mean `first` and `second`.)_

Regrettably, computer says no:

```
error[E0005]: refutable pattern in `for` loop binding: `&[]`,
              `&[_]` and `&[_, _, _, ..]` not covered
 --> src/lib.rs
  |
  |     for [fst, snd] in layers.windows(2) {
  |         ^^^^^^^^^^ patterns `&[]`, `&[_]` and `&[_, _, _, ..]`
  |                    not covered
  |
  = note: the matched value is of type `&[LayerTopology]`
```

Compiler doesn’t understand that `.windows(2)` returns arrays of exactly two elements - for all it knows, `.windows(2)` might return arrays of random sizes that don’t necessarily match our pattern.

_(by the way, that’s what **refutable pattern** means: it’s a pattern that doesn’t match all the possible cases; the antonym is **irrefutable pattern** and only those are allowed in Rust.)_

Nightly Rust, having parts of **const generics** stabilized, offers a solution - a peachy function called [`.array_windows()`](https://doc.rust-lang.org/stable/std/primitive.slice.html#method.array_windows):

```rust
#![feature(array_windows)]

for [fst, snd] in layers.array_windows() {
    built_layers.push(Layer::random(fst.neurons, snd.neurons));
}
```

For simplicity, we’ll stay away from const generics and continue with the previous version.

In this case, switching to iterators is a no-brainer for me:

```rust
pub fn random(layers: Vec<LayerTopology>) -> Self {
    /* ... */

    let layers = layers
        .windows(2)
        .map(|layers| {
            Layer::random(layers[0].neurons, layers[1].neurons)
        })
        .collect();

    Self { layers }
}
```

And one final touch - when it doesn’t make the code awkward, it’s a good practice to accept **borrowed** values instead of owned:

```rust
pub fn random(layers: &[LayerTopology]) -> Self {
    /* ... */
}
```

More often than not, accepting borrowed values doesn’t change much _inside_ the function, but makes it more versatile - i.e. with a borrowed array one can now do:

```rust
let network = Network::random(&[
    LayerTopology { neurons: 8 },
    LayerTopology { neurons: 15 },
    LayerTopology { neurons: 2 },
]);
```

... and:

```rust
let layers = vec![
    LayerTopology { neurons: 8 },
    LayerTopology { neurons: 15 },
    LayerTopology { neurons: 2 },
];

let network_a = Network::random(&layers);
let network_b = Network::random(&layers);
//                              ^ no need to .clone()
```

What’s next, what’s next…​ checks notes…​ ah, `Layer::random()`!

```rust
impl Layer {
    pub fn random(
        input_neurons: usize,
        output_neurons: usize,
    ) -> Self {
        let mut neurons = Vec::new();

        for _ in 0..output_neurons {
            neurons.push(Neuron::random(input_neurons));
        }

        Self { neurons }
    }
}
```

Let’s skip the pleasantries:

```rust
pub fn random(input_neurons: usize, output_neurons: usize) -> Self {
    let neurons = (0..output_neurons)
        .map(|_| Neuron::random(input_neurons))
        .collect();

    Self { neurons }
}
```

`|_|`, also known as [toilet closure](https://www.reddit.com/r/rustjerk/comments/8udbth/a_new_war_begins_choose_your_side/), is a function that accepts an argument it doesn’t care about.

We might’ve written as well:

.map(|output_neuron_id| Neuron::random(input))
... but since we don’t have to read this `output_neuron_id` anywhere, it’s more idiomatic to name the argument `_` (or at least `_output_neuron_id`), to annotate the fact that it’s not being used.

Also, the `_` itself is called a [placeholder](https://doc.rust-lang.org/reference/patterns.html#destructuring) and it can be used in a few different contexts:

```rust
// As a binding:
fn ignore_some_arguments(_: usize, b: usize, _: usize) {
    //                   ^                   ^
}

// ... but not as a name:
fn _() {
// ^ error: expected identifier, found reserved identifier `_`
}

// As a type:
fn load_files(paths: &[&Path]) -> Vec<String> {
    paths
        .iter()
        .map(std::fs::read_to_string)
        .collect::<Result<_, _>>()
    //                    ^  ^
        .unwrap()
}

// ... but only inside expressions:
fn what_am_i(foo: _) {
    //            ^ error: the type placeholder `_` is not allowed
    //              within types on item signatures
}
```

Finally, the last piece of our chain - `Neuron::random()`:

```rust
impl Neuron {
    pub fn random(output_size: usize) -> Self {
        let bias = todo!();

        let weights = (0..output_size)
            .map(|_| todo!())
            .collect();

        Self { bias, weights }
    }
}
```

Contrary to C++'s or Python’s standard libraries, the Rust’s one doesn’t provide any pseudo-random number generator (PRNG) - do you know what it means?

**it’s crate time!**

Which crate should we choose? Well, let’s see:

[视频](https://pwy.io/resources/learning-to-fly-pt2/rand.webm)

When it comes to PRNGs, [`rand`](https://crates.io/crates/rand) is the **de facto standard**, [extremely versatile](https://rust-lang-nursery.github.io/rust-cookbook/algorithms/randomness.html) crate that allows to generate not only pseudo-random numbers, but also other types such as strings.

In order to fetch `rand`, we have to add it to our `libs/neural-network/Cargo.toml`:

```
# ...

[dependencies]
rand = "0.8"
```

... and then:

```rust
pub fn random(output_size: usize) -> Self {
    let mut rng = rand::thread_rng();

    let bias = rng.gen_range(-1.0..=1.0);

    let weights = (0..output_size)
        .map(|_| rng.gen_range(-1.0..=1.0))
        .collect();

    Self { bias, weights }
}
```

>* `0..3` is a half-open interval that matches `0`, `1` and `2`.

>* `0..=3` is a closed interval that matches `3`, too.

Neat.

Certainly, `rng.gen_range(-1.0..=1.0)` predicts Dogecoin prices quite accurately - but is there a way we could ensure our entire network works as intended?

## Testing

A [pure function](https://en.wikipedia.org/wiki/Pure_function) is a function whose given the same arguments, always returns the same value.

For instance, this is a pure function:

```rust
pub fn add(x: usize, y: usize) -> usize {
    x + y
}
```

... while this one is not:

```rust
pub fn read(path: impl AsRef<Path>) -> String {
    std::fs::read_to_string(path).unwrap()
}
```

_(hint: `add(1, 2)` will always return `3`, while `read("file.txt")` will return different strings depending on what given file happens to contain at the moment.)_

Pure functions are nice, because they can be easily tested in isolation:

```
// This test always succeeds
// (i.e this test is *deterministic*)
#[test]
fn test_add() {
    assert_eq!(add(1, 2), 3);
}

// This test might succeed or it might fail, hard to anticipate
// (i.e. this test is *indeterministic*)
#[test]
fn test_read() {
    assert_eq!(
        read("serials-to-watch.txt"),
        "killing eve",
    );
}
```

Unfortunately, the way we randomize numbers inside our `Neuron::random()` makes it impure, which can be easily proven with:

```rust
#[test]
fn random_is_pure() {
    let neuron_a = Neuron::random(4);
    let neuron_b = Neuron::random(4);

    // If `Neuron::random()` was pure, then both neurons would always
    // have to be the same:
    assert_eq!(neuron_a, neuron_b);
}
```

Testing unpure functions is hard, because there’s not much we can assert **reliably**:

```rust
struct Neuron {
    bias: f32,
    weights: Vec<f32>,
}

impl Neuron {
    pub fn random(output_size: usize) -> Self {
        /* ... */
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    mod random {
        use super::*;

        #[test]
        fn test() {
            let neuron = Neuron::random(4);

            assert!(/* what? */);
        }
    }
}
```

We might try:

```rust
#[test]
fn test() {
    let neuron = Neuron::random(4);

    assert_eq!(neuron.weights.len(), 4);
}
```

... but that’s a development counterpart of a [false friend](https://en.wikipedia.org/wiki/False_friend) - though it’s better than no test at all, it doesn’t check much.

On the other hand, making `Neuron::random()` a pure-pure function seems…​ preposterous? What’s the point of randomizing, if the outcome would always remain the same?

Well, the way I usually reconcile both worlds is by looking at the origin of impurity - in our case, it’s `rand::thread_rng()`:

```rust
pub fn random(output_size: usize) -> Self {
    let mut rng = rand::thread_rng();

    /* ... */
}
```

If instead of invoking `thread_rng()`, we accepted a parameter with the randomizer:

```rust
pub fn random(
    rng: &mut dyn rand::RngCore,
    output_size: usize,
) -> Self {
    /* ... */
}
```

... then we could use a fake, **predictable** PRNG in our tests, while users would simply pass an actual PRNG of their choosing.

You can use a similar pattern to test your application’s output; if instead of:

```rust
fn do_something() {
    println!("Doing something...");
    println!("... done!");
}
```

... you do:

```rust
fn do_something(stdout: &mut dyn Write) {
    writeln!(stdout, "Doing something...").unwrap();
    writeln!(stdout, "... done!").unwrap();
}
```

... then you’ll be able to test its output quite easily:

```rust
#[test]
fn ensure_something_happens() {
    let mut stdout = String::new();
    do_something(&mut stdout);

    assert_eq!(stdout, "Doing something...\n... done!\n");
}
```

Side note: I’ve done it [in the past](https://github.com/Patryk27/lxd-snapper/blob/9b096962122988abb3677a69ced244ea7cec2fa2/src/cmds/backup.rs#L159) and it’s proven to be convenient.

Due diligence, for all the purists out there: both `do_something()`-s and `random()`-s technically are not pure functions as they all lack a property called [referential transparency](https://en.wikipedia.org/wiki/Referential_transparency). Though, if one’s insistent, there’s always:

```rust
fn do_something<W: Write>(stdout: W) -> W {
    /* ... */
}
```

Because the `rand` crate doesn’t provide a predictable or seedable PRNG, we have to make use of another crate - I like `rand_chacha` (easy to remember, you’ve probably already memorized it):

```
# ...

[dev-dependencies]
rand_chacha = "0.3"
```

... which allows us to do:

```rust
use rand::SeedableRng;
use rand_chacha::ChaCha8Rng;

#[test]
fn test() {
    // Because we always use the same seed, our `rng` in here will
    // always return the same set of values
    let mut rng = ChaCha8Rng::from_seed(Default::default());
    let neuron = Neuron::random(&mut rng, 4);

    assert_eq!(neuron.bias, /* ... */);
    assert_eq!(neuron.weights, &[/* ... */]);
}
```

We don’t know which numbers will be returned just yet, but finding out is pretty easy: we’ll just start with zeros and then copy-paste numbers from test’s output:

```rust
#[test]
fn test() {
    /* ... */

    assert_eq!(neuron.bias, 0.0);
    assert_eq!(neuron.weights, &[0.0, 0.0, 0.0, 0.0]);
}
```

First `cargo test` gives us:

```
thread '...' panicked at 'assertion failed: `(left == right)`
  left: `-0.6255188`,
 right: `0.0`
```

... so:

```rust
#[test]
fn test() {
    /* ... */

    assert_eq!(neuron.bias, -0.6255188);

    /* ... */
}
```

Another `cargo test`:

```
thread '...' panicked at 'assertion failed: `(left == right)`
  left: `[0.67383957, 0.8181262, 0.26284897, 0.5238807]`,
 right: `[0.0, 0.0, 0.0, 0.0]`', src/lib.rs:29:5
```

... and we end up with:

```rust
#[test]
fn test() {
    /* ... */

    assert_eq!(neuron.weights, &[
        0.67383957,
        0.8181262,
        0.26284897,
        0.5238807,
    ]);
}
```

Notice the numbers are different and that’s alright - they are allowed to be different as long as each `cargo test` consistently works on the same **set** of numbers (and it does, because we used a PRNG with a constant seed).

Before moving on to another test, there’s one touch we really should apply here - it stems from **floating-point inaccuracies**.

The type we’re using, `f32`, models a 32-bit floating-point number that can represent values between `~1.2*10^-38` and `~3.4*10^38` - alas, it cannot represent all of those numbers, just some.

For instance, with `f32` you cannot encode exactly `0.15` - it’ll always be off by a bit:

```rust
fn main() {
    println!("{:.10}", 0.15f32);
    // prints: 0.1500000060
}
```

... or `0.45`:

```rust
fn main() {
   println!("{:.10}", 0.45f32);
   // prints: 0.4499999881
}
```

Usually it doesn’t matter, because floating-point numbers were never made to be exact (only fast) - but when it does come up, it hits one like a brick falling from the sky:

```rust
#[test]
fn test() {
    assert_eq!(0.45f32, 0.15 + 0.15 + 0.15);
}
```

```
thread 'test' panicked at 'assertion failed: `(left == right)`
  left: `0.45`,
 right: `0.45000002`'
```

To avoid reinventing the wheel, I’ll just drop this link:[ What Every Programmer Should Know About Floating-Point Arithmetic](https://floating-point-gui.de/) - if you haven’t read about floating-point numbers yet, I encourage you to give it a shot!

So, if we shouldn’t compare numbers exactly, what can we do? Compare them **approximately**!

```rust
#[test]
fn test() {
    let actual: f32 = 0.1 + 0.2;
    let expected = 0.3;

    assert!((actual - expected).abs() < f32::EPSILON);
}
```

This is the standard way to compare floats across all programming languages that implement IEEE 754 (so, like, basically all the languages): instead of fishing for an **exact** result, you simply compare both numbers with some **margin of error** (also called **tolerance**).

Because comparing numbers this way is awkward, it’s more cushy to either do it via a macro:

```rust
macro_rules! assert_almost_eq {
    ($left:expr, $right:expr) => {
        let left: f32 = $left;
        let right: f32 = $right;

        assert!((left - right).abs() < f32::EPSILON);
    }
}

#[test]
fn test() {
    assert_almost_eq!(0.45f32, 0.15 + 0.15 + 0.15);
}
```

... or - which is the best approach - using a crate such as [approx](https://docs.rs/approx/0.4.0/approx/):

```rust
#[test]
fn test() {
    approx::assert_relative_eq!(0.45f32, 0.15 + 0.15 + 0.15);
}
```

I personally like `approx`, so let’s add it to our neural network’s `Cargo.toml`:

```
# ...

[dev-dependencies]
approx = "0.4"
```

... and then adjust the tests:

```rust
#[test]
fn test() {
    let mut rng = ChaCha8Rng::from_seed(Default::default());
    let neuron = Neuron::random(&mut rng, 4);

    assert_relative_eq!(neuron.bias, -0.6255188);

    assert_relative_eq!(neuron.weights.as_slice(), [
        0.67383957,
        0.8181262,
        0.26284897,
        0.5238807,
    ].as_ref());
}
```

This covers half of neuron’s functions - thankfully, knowing what we know now, writing a test for `Neuron::propagate()` should go easy:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    mod random {
        use super::*;

        #[test]
        fn test() {
            /* ... */
        }
    }

    mod propagate {
        use super::*;

        #[test]
        fn test() {
            todo!()
        }
    }
}
```

You might’ve heard that instead of naming a test `test`, you should strive to describe what given test **does** and what are its **preconditions**.

Usually that’s true - if we were writing a shop that sells Monsteras, it’d be wise to structure tests as such:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    mod cart {
        use super::*;

        mod when_user_adds_a_flower_to_their_cart {
            use super::*;

            #[test]
            fn user_can_see_this_flower_in_their_cart() {
                /* ... */
            }

            #[test]
            fn user_can_remove_this_flower_from_their_cart() {
                /* ... */
            }

            mod and_submits_order {
                /* ... */
            }

            mod and_abandons_cart {
                /* ... */
            }
        }
    }
}
```

The sitch is that our `Neuron` isn’t typical "business code" and lots of "business code patterns" don’t quite work with mathematical code.

If we had some **edge cases** to consider, say:

```rust
fn propagate(...) {
    if ... {
        do_something()
    } else {
        do_something_else()
    }
}
```

... then it’d make sense to create two separate tests like so:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    mod propagate {
        use super::*;

        mod given_neuron_with_foo {
            use super::*;

            #[test]
            fn does_something() {
                /* ... */
            }
        }

        mod given_neuron_thats_bar {
            use super::*;

            #[test]
            fn does_something_else() {
                /* ... */
            }
        }
    }
}
```

But having the code we have - we’ll be better off with simple `fn test()`.

How can we ensure `propagate()` works correctly? By computing the expected response manually:

```rust
#[test]
fn test() {
    let neuron = Neuron {
        bias: 0.5,
        weights: vec![-0.3, 0.8],
    };

    // Ensures `.max()` (our ReLU) works:
    approx::assert_relative_eq!(
        neuron.propagate(&[-10.0, -10.0]),
        0.0,
    );

    // `0.5` and `1.0` chosen by a fair dice roll:
    approx::assert_relative_eq!(
        neuron.propagate(&[0.5, 1.0]),
        (-0.3 * 0.5) + (0.8 * 1.0) + 0.5,
    );

    // We could've written `1.15` right away, but showing the entire
    // formula makes our intentions clearer
}
```

From this point, implementing tests for `Layer` and `Network` gets pretty straightforward and thus has been left as an exercise for the reader :-)

## Closing thoughts

### What have we created, exactly?
It might seem that what we’ve implemented has nothing to do with learning or simulating:

* what about the eyes?
* where’s the code responsible for movement?
* how did you create that greenish, Fallout-style terminal?

... but that’s only because the neural network itself, while being a relatively complex piece of our codebase, doesn’t do much on its own; thou shall not worry though, as in the end all the pieces will fit together.

In the meantime, feel free to checkout the **entire** source code at [my GitHub repository](https://github.com/Patryk27/shorelark/tree/main/libs/neural-network).

### What about rustfmt?
This might come off like an advertisement, but let’s give it a shot anyway:

Code formatting is important - doesn’t matter if your project’s big or small, [rustfmt](https://github.com/rust-lang/rustfmt) is the way to go!

### What about TDD?
Test-driven development is a programming methodology in which you first write tests and only then start to work on the implementation; I use it more often than not, but while writing this article, I’ve decided that starting with implementation will be more educational than the adventure TDD would take us on.

So if you’re wondering whether TDD is worth pursuing in Rust - it totally is! Though, as always - not always :-)

### Why is our design inflated?
When you gogoduck for `python neural network from scratch`, you’ll see lots of articles that encapsulate FFNNs in a handful lines of Python code - compared to them, our design seems bean-to-the-square-inflated; why is that so?

It’s because we could learn more this way - we could’ve coded our network in 1/10th of its current size by using [nalgebra](https://nalgebra.org/), we could’ve used one of the [already-existing crates](https://www.arewelearningyet.com/neural-networks/), but it’s not the destination that matters, it’s the journey.

### What’s next?
To avoid closing our closing thoughts on some cheesy waltz, let’s establish what’s coming next.

At the moment we’ve got a working, bare-bones neural network - in the upcoming article, we’ll `cargo new genetic-algorithm --lib` and we’ll see what our current implementation is **missing** in order to make it compatible with genetic algorithms.

The last, fourth post, will be about WebAssembly-ing all our crates together to end up with our opus magnum: flying birds.

**Until then!**
